{
  "hash": "cd0f6db7ab9a00102ce85bbed65fcdc6",
  "result": {
    "markdown": "---\ntitle: \"GEE on aggregated data?\"\ndate: \"2023-03-20\"\ncategories: [R, GLM, GEE]\ncode-fold: false\nreference-location: margin\nimage: cubic_runtime.png\n---\n\n\nTL;DR: The geepack R package doesn't do what it doesn't claim to do\n\n# Introduction\n\nRunning many _generalized estimating equation_ (GEE) models can be quite time consuming when at least one of the clusters has a lot of subjects, as the [time complexity](https://en.wikipedia.org/wiki/Big_O_notation) of the GEE model is $O(n^3)$[^max_cluster_size] due to the full [matrix multiplication](https://en.wikipedia.org/wiki/Computational_complexity_of_matrix_multiplication) required for computing the correlation matrix.\n\n[^max_cluster_size]: More like $O(m^3)$ where $m$ is the size of largest cluster when the clusters vary in terms of size.\n\nFor relatively simple models -- where there are a few categorical predictors, the continuous variables are coarsened, and the response variable is binary -- there is a computational trick that can be employed while fitting logistic regression models where the raw data are aggregated and fed into the model. An example of this approach can be found [here](https://predictivehacks.com/how-to-run-logistic-regression-on-aggregate-data-in-r/).\n\nDoes this approach work -- in terms of providing the same point estimates and standard errors -- for GEE models as well? Based on an example dataset as well as a small simulation study, the answer seems to be 'it depends'.\n\n# Real dataset\n\nThe first comparison is based on the `ohio` dataset from the `{geepack}` R package. This kind of setting where there are very many small clusters (537 clusters with 4 observations per cluster) is where GEEs usually shine.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nlibrary(furrr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: future\n```\n:::\n\n```{.r .cell-code}\nlibrary(geepack)\n\ntheme_set(theme_bw())\n\ndata(\"ohio\")\n\nohio <- as_tibble(ohio)\n\nglimpse(ohio)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 2,148\nColumns: 4\n$ resp  <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ id    <int> 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5…\n$ age   <int> -2, -1, 0, 1, -2, -1, 0, 1, -2, -1, 0, 1, -2, -1, 0, 1, -2, -1, …\n$ smoke <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n```\n:::\n:::\n\n\nFitting a model to the full dataset results in the following output\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod1 <- geeglm(\n  formula = resp ~ smoke, data = ohio, family = \"binomial\",\n  id = id, corstr = \"exchangeable\"\n)\n\nsummary(mod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\ngeeglm(formula = resp ~ smoke, family = \"binomial\", data = ohio, \n    id = id, corstr = \"exchangeable\")\n\n Coefficients:\n            Estimate Std.err    Wald Pr(>|W|)    \n(Intercept)  -1.8212  0.1099 274.527   <2e-16 ***\nsmoke         0.2716  0.1776   2.338    0.126    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = exchangeable \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)        1  0.1103\n  Link = identity \n\nEstimated Correlation Parameters:\n      Estimate Std.err\nalpha   0.3513 0.06163\nNumber of clusters:   537  Maximum cluster size: 4 \n```\n:::\n:::\n\n\nFitting the same model to an aggregated version of the same dataset results in identical estimates\n\n\n::: {.cell}\n\n```{.r .cell-code}\nagg_df <- ohio %>%\n  group_by(id, smoke) %>%\n  summarize(\n    n = n(),\n    resp = sum(resp),\n    .groups = \"drop\"\n  ) %>%\n  mutate(resp_p = resp / n)\n\nmod2 <- geeglm(\n  formula = resp_p ~ smoke,\n  weights = n, data = agg_df,\n  family = \"binomial\", id = id, corstr = \"exchangeable\"\n)\n\nsummary(mod2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\ngeeglm(formula = resp_p ~ smoke, family = \"binomial\", data = agg_df, \n    weights = n, id = id, corstr = \"exchangeable\")\n\n Coefficients:\n            Estimate Std.err   Wald Pr(>|W|)    \n(Intercept)   -1.821   0.110 274.53   <2e-16 ***\nsmoke          0.272   0.178   2.34     0.13    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = exchangeable \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)    0.513  0.0532\n  Link = identity \n\nEstimated Correlation Parameters:\n      Estimate Std.err\nalpha        0       0\nNumber of clusters:   537  Maximum cluster size: 1 \n```\n:::\n:::\n\n\nSo the estimated scale, correlation, and the maximum cluster size statistics are wrong in the second case, but the parameter estimates for the intercept and slope coefficients as well as the corresponding standard errors are nearly identical, which can be compared more easily in this data frame that combines the estimates from both models\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbind_rows(\n  broom::tidy(mod1) %>% mutate(data = \"raw data\"),\n  broom::tidy(mod2) %>% mutate(data = \"aggregated data\")\n) %>%\n  arrange(term)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 6\n  term        estimate std.error statistic p.value data           \n  <chr>          <dbl>     <dbl>     <dbl>   <dbl> <chr>          \n1 (Intercept)   -1.82      0.110    275.     0     raw data       \n2 (Intercept)   -1.82      0.110    275.     0     aggregated data\n3 smoke          0.272     0.178      2.34   0.126 raw data       \n4 smoke          0.272     0.178      2.34   0.126 aggregated data\n```\n:::\n:::\n\n\nBut does this also work in settings where there are a small number of large clusters, which is where the GEE calculations take a long time to run?\n\n# Simulations\n\n## Model\n\nThe code below simulates data from the following mixed-effects model[^rethinking] with random-intercept terms where person $j$ is nested within cluster $i$. Each cluster has a different proportion of treatment uptake $p_{treated,j}$ varying between 40-60% where $X_{ij}$ indicates whether person $j$ in cluster $i$ received the treatment or not.\n\n[^rethinking]: The model syntax is inspired by the statistical rethinking book\n\n\n$$\n\\begin{gather}\nY_{ij} \\sim \\text{Bernoulli}(p_{ij}) \\\\\n\\text{logit}(p_{ij}) = -1.4 + 0.3 \\times X_{ij} + \\alpha_i \\\\\n\\alpha_i \\sim \\text{Normal}(0, 1) \\\\\nX_{ij} \\sim \\text{Bernoulli}(p_{treated,i}) \\\\\np_{treated,i} \\sim \\text{Uniform(0.4, 0.6)}\n\\end{gather}\n$$\n\n\nThe time taken to train the model on the raw as well as the aggregate data, the point estimates, and standard errors for the coefficients are stored for analysis.\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulate_data_and_get_estimates <- function(n, n_clus, seed) {\n  set.seed(seed)\n  # cluster random intercept\n  rand_intercept <- rnorm(n_clus, mean = 0, sd = 1)\n\n  set.seed(seed)\n  sim_data <- map_dfr(.x = 1:n_clus, .f = ~ {\n    tibble(\n      id = .x,\n      x = rbinom(round(n / n_clus), size = 1, prob = runif(1, 0.4, 0.6)),\n      y = rbinom(round(n / n_clus), size = 1, prob = plogis(-1.4 + 0.3 * x + rand_intercept[[.x]]))\n    )\n  })\n\n  # fit model to raw data\n  t0 <- Sys.time()\n  mod1_sim <- geeglm(\n    y ~ x,\n    data = sim_data,\n    family = \"binomial\", id = id, corstr = \"exchangeable\"\n  )\n  t1 <- Sys.time()\n  t1 <- as.numeric(difftime(t1, t0, units = \"secs\"))\n\n  # fit GLM model to raw data\n  mod1_sim_glm <- glm(y ~ factor(id) + x - 1,\n                      data = sim_data, family = \"binomial\")\n\n  # fit model to aggregated data\n  agg_data <- sim_data %>%\n    group_by(id, x) %>%\n    summarize(n = n(), y = sum(y), .groups = \"drop\") %>%\n    mutate(y_prob = y / n)\n\n  t2 <- Sys.time()\n  mod2_sim <- geeglm(\n    y_prob ~ x,\n    data = agg_data, weights = n,\n    family = \"binomial\", id = id, corstr = \"exchangeable\"\n  )\n  t3 <- Sys.time()\n  t3 <- as.numeric(difftime(t3, t2, units = \"secs\"))\n\n  # fit GLM model to aggregated data\n  mod2_sim_glm <- glm(y_prob ~ factor(id) + x - 1, data = agg_data,\n                      weights = n, family = \"binomial\")\n\n  results <- bind_rows(\n    # GEE results\n    broom::tidy(mod1_sim) %>%\n      mutate(data = 'raw data', time_secs = t1, estimator = \"GEE\"),\n    broom::tidy(mod2_sim) %>%\n      mutate(data = 'aggregated data', time_secs = t3, estimator = \"GEE\"),\n    # GLM results\n    broom::tidy(mod1_sim_glm) %>%\n      mutate(data = 'raw data', time_secs = NA_real_, estimator = \"GLM\"),\n    broom::tidy(mod2_sim_glm) %>%\n      mutate(data = 'aggregated data', time_secs = NA_real_, estimator = \"GLM\")\n  ) %>%\n    mutate(n = n, n_clus = n_clus, seed = seed) %>%\n    filter(!stringr::str_detect(term, pattern = \"id\"))\n\n  return(results)\n}\n```\n:::\n\n\nHere's what the output from this function looks like:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulate_data_and_get_estimates(n = 100, n_clus = 5, seed = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 11\n  term       estim…¹ std.e…² stati…³ p.value data  time_s…⁴ estim…⁵     n n_clus\n  <chr>        <dbl>   <dbl>   <dbl>   <dbl> <chr>    <dbl> <chr>   <dbl>  <dbl>\n1 (Intercep…  -1.59    0.409 15.0    1.07e-4 raw …  0.00748 GEE       100      5\n2 x           -0.144   0.383  0.141  7.07e-1 raw …  0.00748 GEE       100      5\n3 (Intercep…  -1.73    0.395 19.1    1.27e-5 aggr…  0.00326 GEE       100      5\n4 x           -0.107   0.402  0.0702 7.91e-1 aggr…  0.00326 GEE       100      5\n5 x           -0.266   0.596 -0.446  6.55e-1 raw … NA       GLM       100      5\n6 x           -0.266   0.596 -0.446  6.55e-1 aggr… NA       GLM       100      5\n# … with 1 more variable: seed <dbl>, and abbreviated variable names ¹​estimate,\n#   ²​std.error, ³​statistic, ⁴​time_secs, ⁵​estimator\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulation_parameters <- expand_grid(\n  n = c(100, 500, 1000, 2500, 5000, 7500, 10000),\n  n_clus = c(5, 50, 250),\n  seed = 1:20\n) %>% \n  # remove runs where number of clusters is larger than total sample size\n  filter(n_clus < n)\n\n# set up multicore processing\nplan(multisession, workers = 15)\n\n# parallelize purrr::pmap_dfr by using the {furrr} package\nsimulation_results <- future_pmap_dfr(\n  .l = simulation_parameters,\n  # have to pass args as ..1 or ..2, else it fails\n  .f = ~ simulate_data_and_get_estimates(n = ..1, n_clus = ..2, seed = ..3),\n  .options = furrr_options(seed = NULL)\n)\n\nplan(sequential) # turn off multicore\n```\n:::\n\n\nThis chunk can take a while to run for some of the parameter combinations, so pre-computed results are loaded and analyzed further.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulation_results <- read_csv(file = \"gee_glm_sim.csv\", show_col_types = FALSE) %>% \n  mutate(\n    n_clus_raw = n_clus,\n    n_clus = factor(paste0(\"# clusters: \", n_clus),\n                    levels = paste0(\"# clusters: \", c(5, 50, 250))),\n    term = case_when(\n      term == \"(Intercept)\" ~ \"Intercept\",\n      term == \"x\" ~ \"Slope\", \n      TRUE ~ term\n  ))\n\nglimpse(simulation_results)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 2,400\nColumns: 12\n$ term       <chr> \"Intercept\", \"Slope\", \"Intercept\", \"Slope\", \"Slope\", \"Slope…\n$ estimate   <dbl> -7.17e-01, -7.38e-02, -5.35e-01, -1.14e-01, -5.92e-02, -5.9…\n$ std.error  <dbl> 4.69e-01, 1.75e-01, 4.09e-01, 1.53e-01, 4.86e-01, 4.86e-01,…\n$ statistic  <dbl> 2.3402, 0.1772, 1.7056, 0.5518, -0.1216, -0.1216, 7.1290, 4…\n$ p.value    <dbl> 1.26e-01, 6.74e-01, 1.92e-01, 4.58e-01, 9.03e-01, 9.03e-01,…\n$ data       <chr> \"raw data\", \"raw data\", \"aggregated data\", \"aggregated data…\n$ time_secs  <dbl> 0.01389, 0.01389, 0.00420, 0.00420, NA, NA, 0.00928, 0.0092…\n$ estimator  <chr> \"GEE\", \"GEE\", \"GEE\", \"GEE\", \"GLM\", \"GLM\", \"GEE\", \"GEE\", \"GE…\n$ n          <dbl> 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,…\n$ n_clus     <fct> # clusters: 5, # clusters: 5, # clusters: 5, # clusters: 5,…\n$ seed       <dbl> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4,…\n$ n_clus_raw <dbl> 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,…\n```\n:::\n:::\n\n\n# Analysis\n\n## Computation time\n\nFirst, the time taken to fit the model to the raw dataset is shown as a function of total sample size $n$ where there are $n / n_{clus}$ observations per cluster. Each panel has a different y-axis to allow reading values directly from the plot.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulation_results %>%\n  filter(data == \"raw data\", estimator == \"GEE\") %>%\n  # distinct here since the data frame contains a row for\n  # each of the intercept and slope terms but the runtimes are the same\n  # for both these terms\n  distinct(seed, time_secs, n, n_clus) %>%\n  ggplot(aes(x = n, y = time_secs, group = n_clus)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, degree = 3)) +\n  geom_smooth(method = \"lm\", formula = y ~ I(x ^ 3), color = \"forestgreen\") +\n  stat_summary(aes(group = interaction(n_clus, n)), geom = \"point\", \n               fun = mean, color = \"darkorange\", size = 2) + \n  xlab(\"Total sample size (n)\") +\n  ylab(\"Runtime (in seconds)\") +\n  facet_wrap(~ n_clus, scales = \"free\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nThe blue line fits a cubic polynomial $$time = \\beta_0 + \\beta_1 n + \\beta_2 n^2 + \\beta_3 n^3 + \\varepsilon$$ to the run times as a function of sample size. The green line fits the same model but without the linear and quadratic terms, i.e, $time = \\alpha_0 + \\alpha_1 n^3 + \\varepsilon$. The yellow points are the mean run times for each level of $n$ within each panel. \n\nWhen the number of clusters is very small, an increase in the sample size within the largest cluster leads to a cubic increase in expected run times. The closeness of the blue and green lines in the leftmost panel indicates that the cubic term in the execution time model dominates the lower order terms. In the second and third panels, the $O(n^3)$ limit hasn't hit yet, as the green and the blue lines are in disagreement. \n\nFor 10000 samples split into 2000 samples in each of the five clusters, it takes approximately **15 minutes** per run. The same total sample size split into 250 samples in each of the 40 clusters, each model takes about **7 seconds** to run, and even less time when there are 250 clusters. This is a massive difference in time between the different settings.\n\n## Convergence issues\n\nHowever, unfortunately some of the models run into convergence issues, where the point estimates and the standard errors explode\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulation_results %>% \n  filter(estimator == \"GEE\") %>% \n  arrange(desc(std.error)) %>% \n  head(n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 12\n   term      estimate std.e…¹ stati…² p.value data  time_…³ estim…⁴     n n_clus\n   <chr>        <dbl>   <dbl>   <dbl>   <dbl> <chr>   <dbl> <chr>   <dbl> <fct> \n 1 Intercept  4.24e16 1.22e16  12.1   5.12e-4 aggr… 0.00516 GEE     10000 # clu…\n 2 Intercept  1.13e17 8.91e15 161.    0       aggr… 0.00621 GEE      7500 # clu…\n 3 Intercept -1.99e17 7.88e15 641.    0       aggr… 0.0175  GEE      1000 # clu…\n 4 Intercept  2.32e15 7.25e15   0.102 7.49e-1 aggr… 0.00667 GEE      7500 # clu…\n 5 Intercept  5.32e15 6.59e15   0.650 4.20e-1 aggr… 0.00582 GEE       100 # clu…\n 6 Slope     -1.69e15 2.25e15   0.562 4.53e-1 aggr… 0.0110  GEE      2500 # clu…\n 7 Intercept  9.69e14 2.12e15   0.210 6.47e-1 aggr… 0.00558 GEE     10000 # clu…\n 8 Slope     -1.03e15 2.09e15   0.241 6.23e-1 aggr… 0.00763 GEE      7500 # clu…\n 9 Slope     -1.94e15 2.05e15   0.896 3.44e-1 aggr… 0.00503 GEE     10000 # clu…\n10 Slope      3.82e15 1.88e15   4.13  4.23e-2 aggr… 0.00817 GEE      5000 # clu…\n# … with 2 more variables: seed <dbl>, n_clus_raw <dbl>, and abbreviated\n#   variable names ¹​std.error, ²​statistic, ³​time_secs, ⁴​estimator\n```\n:::\n:::\n\n\nThis seems to be a problem when training GEE models on aggregated data when the number of clusters is low irrespective of the total sample size, which leads to about 21% of the estimates from the aggregated data being convergence failures. An estimate is flagged as convergence failure when the stdandard error of the coefficients > 5 on the logit scale.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulation_results <- simulation_results %>%\n  mutate(high_se = as.numeric(std.error > 5)) \n\nsimulation_results %>%\n  filter(estimator == \"GEE\") %>% \n  select(-estimate, -std.error, -statistic, -p.value, -time_secs) %>%\n  # put intercept and slope estimates in one row\n  pivot_wider(everything(), names_from = term, values_from = high_se) %>%\n  # if at least one of the intercept or slope terms have a very high se\n  mutate(high_se = pmin(Intercept + Slope, 1)) %>%\n  group_by(data, n_clus, n) %>%\n  summarize(n_total = n(), n_failed = sum(high_se), .groups = \"drop_last\") %>%\n  #print(n = Inf) %>%\n  summarize(n_total = sum(n_total), n_failed = sum(n_failed), .groups = \"drop\") %>%\n  mutate(percent_failed = 100 * n_failed / n_total)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 5\n  data            n_clus          n_total n_failed percent_failed\n  <chr>           <fct>             <int>    <dbl>          <dbl>\n1 aggregated data # clusters: 5       140       29           20.7\n2 aggregated data # clusters: 50      140        0            0  \n3 aggregated data # clusters: 250     120        0            0  \n4 raw data        # clusters: 5       140        0            0  \n5 raw data        # clusters: 50      140        0            0  \n6 raw data        # clusters: 250     120        0            0  \n```\n:::\n:::\n\n\n## Raw vs aggregated data estimates\n\nThese rows with convergence failures can be removed and the agreement between the estimates from the raw vs the aggregate datasets can be assessed visually\n\n\n::: {.cell}\n\n```{.r .cell-code}\nslope_plot_data <- simulation_results %>%\n  filter(term == \"Slope\", high_se == 0) %>%\n  select(seed, term, data, estimate, n_clus, n, estimator) %>%\n  tidyr::pivot_wider(id_cols = c(seed, term, n_clus, n, estimator),\n                     names_from = data, values_from = estimate) %>%\n  mutate(`Total sample size` = factor(n), \n         id = interaction(estimator, n_clus, sep = \", \", lex.order = TRUE)) \n\nslope_plot_data %>% \n  filter(estimator == \"GEE\") %>% \n  ggplot(aes(x = `raw data`, y = `aggregated data`, color = `Total sample size`)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  # geom_point(data = tibble(x = 0.3, y = 0.3), \n  #            aes(x = x, y = y), \n  #            color = \"black\", size = 3, inherit.aes = FALSE) +\n  xlab(\"Slope coefficient from the full dataset\") +\n  ylab(\"Slope coefficient from the aggregated dataset\") +\n  theme(legend.position = \"bottom\") +\n  guides(color = guide_legend(nrow = 1)) + \n  facet_wrap(~ id, ncol = 3, scales = \"fixed\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 29 rows containing missing values (geom_point).\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nThis plot compares the estimated slope coefficient (true value 0.3) from the GEE model on aggregated data vs the estimated slope coefficient from the model on the raw data while varying the number of clusters as well as the total sample size. The agreement between estimates increases as the number of clusters increases (going from the top left panel to the top right panel). \n\nOn the other hand, the estimates from running GLMs on the same aggregated and raw datasets are identical, as indicated by the points lying precisely on the black line in the following plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nslope_plot_data %>% \n  filter(estimator == \"GLM\") %>% \n  ggplot(aes(x = `raw data`, y = `aggregated data`, color = `Total sample size`)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  # geom_point(data = tibble(x = 0.3, y = 0.3), \n  #            aes(x = x, y = y), \n  #            color = \"black\", size = 3, inherit.aes = FALSE) +\n  xlab(\"Slope coefficient from the full dataset\") +\n  ylab(\"Slope coefficient from the aggregated dataset\") +\n  theme(legend.position = \"bottom\") +\n  guides(color = guide_legend(nrow = 1)) + \n  facet_wrap(~ id, ncol = 3, scales = \"fixed\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nAs expected, the estimates for $n = 10,000$ are tightly clustered around the true value compared to $n = 100$ in both sets of plots.\n\nOk so the estimates aren't identical for the GEE models unfortunately, but are they approximately similar across the raw and aggregated datasets? This is assessed visually via box plots below for the case of 5 clusters in the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndist_plot_data <- simulation_results %>% \n  mutate(\n    ci_lower = estimate - (qnorm(0.975) * std.error),\n    ci_upper = estimate + (qnorm(0.975) * std.error), \n    ci_width = ci_upper - ci_lower, \n    ci_upper_half_width = ci_upper - estimate\n  ) %>% \n  filter(term == \"Slope\", high_se == 0, estimator == \"GEE\") %>% \n  select(\n    Estimate = estimate, \n    `Std. Error` = std.error, \n    `95% CI LL` = ci_lower, \n    `95% CI UL` = ci_upper,\n    `95% CI Width` = ci_width,\n    `95% CI Upper HW` = ci_upper_half_width,\n    n, n_clus_raw, n_clus, data, seed) %>% \n  tidyr::pivot_longer(cols = Estimate:`95% CI Upper HW`, \n                      names_to = \"statistic\", \n                      values_to = \"values\") %>% \n  mutate(\n    statistic = factor(statistic,\n                       levels = c(\"Estimate\", \"Std. Error\", \n                                  \"95% CI LL\", \"95% CI UL\", \n                                  \"95% CI Width\", \"95% CI Upper HW\")), \n    n = factor(n, ordered = TRUE), \n    data = stringr::str_to_title(data)\n  )\n\nglimpse(dist_plot_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 4,626\nColumns: 7\n$ n          <ord> 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,…\n$ n_clus_raw <dbl> 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,…\n$ n_clus     <fct> # clusters: 5, # clusters: 5, # clusters: 5, # clusters: 5,…\n$ data       <chr> \"Raw Data\", \"Raw Data\", \"Raw Data\", \"Raw Data\", \"Raw Data\",…\n$ seed       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3,…\n$ statistic  <fct> Estimate, Std. Error, 95% CI LL, 95% CI UL, 95% CI Width, 9…\n$ values     <dbl> -0.0738, 0.1753, -0.4174, 0.2698, 0.6871, 0.3436, -0.1137, …\n```\n:::\n:::\n\n::: {.cell fig.dpi='300'}\n\n```{.r .cell-code}\ndist_plot_data %>% \n  filter(n_clus_raw == 5) %>% \n  ggplot(aes(x = n, y = values, color = data)) + \n  #geom_point(position = position_dodge(width = 0.2)) +\n  geom_boxplot(position = position_dodge(width = 1)) +\n  xlab(\"Total sample size (n)\") + \n  ylab(\"\") +\n  theme(legend.position = \"bottom\", legend.title = element_blank()) +\n  facet_wrap(~ statistic, ncol = 2, scales = \"free\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=720}\n:::\n:::\n\n\nSo based on these box plots, it seems like most of the sampling distributions for these statistics -- point estimate, standard errors, CI width, etc. -- are pretty comparable but not identical.\n\n# Conclusion\n\nSo to conclude, this strategy isn't really going to be useful when fitting a single GEE model to a real dataset using the R package `{geepack}`, but it can still be pretty decent when fitting many GEE models to simulated datasets to calculate some statistics. Additionally, all (?) matrix operations performed by GEE eventually boil down to summing some random variables, so it should be possible to have an implementation that works on aggregated data.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}