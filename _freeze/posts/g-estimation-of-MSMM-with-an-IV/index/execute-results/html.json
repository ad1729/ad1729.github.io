{
  "hash": "79537354c15c7ca0c93463795600b33b",
  "result": {
    "markdown": "---\ntitle: \"Using an obscure causal inference method to estimate treatment effects with the help of another less obscure causal inference method\"\ndate: \"2024-02-09\"\ncategories: [Causal Inference, Instrumental Variables, G-estimation, G-computation, GEE, R]\ncode-fold: true\ntoc-expand: true\nreference-location: margin\nimage: \"image-MSMM-IV.png\"\n---\n\n\n## Introduction\n\nIn a [previous post](../instrumental-variable-in-RCT/index.qmd), I used the *ratio estimator* and the method of *instrumental variables* (IV) to estimate the effect of showing an ad on sales from a fictitious ad campaign.\n\nThis post uses the lesser-known method of *g-estimation*[^1] to estimate the effect of a continuous exposure variable in a *multiplicative structural mean model* (MSMM) by using the randomization indicator as an instrumental variable to obtain valid treatment effect estimates in the presence of unmeasured confounding.\n\n[^1]: less popular compared to IPTW and PSM, hence the clickbait-y title\n\nAs mentioned towards the end of the previous post, analyzing the treated individuals by collapsing them into a single 'treated' group was a simplification. The observed treatment variable would in reality be the number of impressions of the ad --- naturally varying between individuals in the treated group, but zero among the individuals assigned to the control group and among the *never-takers*[^2].\n\n[^2]: i.e., people who would not take the treatment if assigned to the treatment group. *Defiers* and *always-takers* aren't possible as individuals in the control group cannot see an ad, because compliance in the control arm is ensured by design.\n\n## Parameter of interest\n\nIf $U$ indicates the (possibly multivalued) set of unmeasured confounders, $Z$ the binary randomization variable indicating group assignment (treatment or control), $A$ the integral exposure variable indicating observed treatment level $a$ in $\\{0, 1, 2, … \\}$, then an estimand or parameter of interest is the marginal *causal risk ratio* (CRR)\n\n$$\n\\text{ATE} = \\frac{\\text{Pr}[Y^{a + 1} = 1]}{\\text{Pr}[Y^{a} = 1]}\n$$\\\nThis is usually the target of inference in an experiment with perfect compliance, and corresponds to setting the treatment level to $A = a + 1$ vs $A = a$ for the full population ($Y^a$ denotes the potential outcome under treatment level $a$).\n\nAnother estimand of interest may be the *average treatment effect in the treated* (ATT) or the *effect of the treatment on the treated* (ETT). This compares the treated individuals to the *counterfactual scenario had they not been treated*. This corresponds to $$\n\\text{ATT} = \\frac{\\text{Pr}[Y^a = 1 | A = a]}{\\text{Pr}[Y^{a = 0} = 1 | A = a]}\n$$\n\nIn a setting with noncompliance (possibly due to unmeasured confounding), the estimand can be further conditioned on the IV $Z$\n\n$$\n\\text{ATT}_{IV} = \\frac{\\text{Pr}[Y^a = 1 | A = a, Z]}{\\text{Pr}[Y^{a = 0} = 1 | A = a, Z]}\n$$\n\nThe main MSMM used in this post estimates the ATE if the unmeasured confounders $U$ are *not effect-measure modifiers* (i.e., the impact of treatment $A$ on the ratio scale is the same on $Y$ at all levels of $U$). If $U$ is an effect modifier, but $Z$ is not, then the MSMM estimate can be interpreted as the $\\text{ATT}_{IV}$.\n\nPages 2-3 of [this paper](https://projecteuclid.org/journals/statistical-science/volume-26/issue-3/On-Instrumental-Variables-Estimation-of-Causal-Odds-Ratios/10.1214/11-STS360.full) provide a concise yet illuminating discussion of the different effect measures that can be of interest.\n\nSince risk ratios are *collapsible* (see [this excellent paper](https://onlinelibrary.wiley.com/doi/full/10.1002/bimj.201900297)), the (confounder-adjusted) marginal and conditional estimands are identical[^3].\n\n[^3]: which is only the case for risk differences and risk ratios.\n\nBefore writing any code, the main packages used in this post are attached.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code  code-fold=\"show\"}\nlibrary(broom, include.only = \"tidy\")\n\n# functions from the following packages are called via package::fun()\n# to reduce namespace conflicts\n# library(geeM)\n# library(mgcv)\n# library(ivtools)\n# library(marginaleffects)\n# library(glue)\n# library(gridExtra)\n\ntheme_set(theme_bw())\n```\n:::\n\n\n## G-estimation in a nutshell\n\nThe first time I read the chapter on g-estimation in the what-if book, it went over my head completely[^4]. Conceptually, it seemed harder than the more popular (g-)methods of *g-computation* and *inverse probability of treatment weighting* (IPTW). However, its superiority to g-computation in terms of not being prone to bias due to extrapolation, superiority to IPTW[^5] in terms of having less variability (and bias), and relative ease of handling continuous exposures (and continuous instruments) piqued my curiosity[^6].\n\n[^4]: May have had something to do with the fact that I was attempting this at 3 AM in between sleep cycles.\n\n[^5]: I think this isn't an issue if *overlap* (ATO) weights are used instead of the usual ATE weights, as g-estimation gives higher weight to strata with greater overlap, and empty strata don't contribute to the final estimate.\n\n[^6]: I'm basing this on the Dukes, Vansteelandt paper.\n\nAnother advantage is that there's no need to correctly model the relationship between the confounders $U$ and the outcome $Y$ for the correct estimation of the treatment effect. This would not be the case when using (*log-)binomial* or *poisson* regression, where misspecification of the $U-Y$ relationship can bias the estimate for $A$.\n\nThe essence of g-estimation is simple[^7] -- once the true effect of the treatment $\\psi$ is shaved off from the response variable $Y$, the residuals $H(\\psi) = Y - \\psi A = Y^{a = 0}$ should be uncorrelated with the treatment $A$ in the confounder-adjusted propensity model, i.e., $\\text{Cov}(A, H(\\psi) | U) = 0$[^8]. This is the same as picking the value of $\\psi$ that leads to $\\alpha_1 = 0$ in $\\mathbb{E}[A | Y^{a=0}, U] = \\alpha_0 + \\alpha_1 H(\\psi) + \\sum_{j=2}^k \\alpha_j U_{j-1}$[^9]. For MSMMs, $H(\\psi) = Y \\text{exp}(- \\psi A)$ is used where $\\psi$ is the risk ratio on the log scale.\n\n[^7]: after having grasped it that is\n\n[^8]: Cov denotes *covariance.*\n\n[^9]: For a binary exposure variable, the $\\mathbb{E}[A]$ is replaced by $\\text{logit(Pr[A = 1])}$, where $\\text{logit}(p) = \\text{log}\\Big(\\frac{p}{1-p}\\Big)$ and $p$ is the probability $\\text{Pr}[A = 1]$.\n\nThis works because of the *conditional mean independence* assumption --- that the exposed and unexposed individuals are exchangeable within levels of $U$ (i.e., $Y^{a = 0} \\perp\\!\\!\\!\\perp A|U$) as would be the case for a conditionally randomized experiment. In a marginally randomized experiment, the treatment assigned and received is independent of the potential outcomes, which would not be the case if people with (say) higher levels of $U$ were more likely to take the treatment ($A > 0$) and have a positive outcome $Y = 1$. In this scenario, it wouldn't be possible to say whether it was $A$ or $U$ causing better outcomes. This *lack-of-identification* is due to confounding between the effect of $U$ on $Y$ and the effect of $A$ on $Y$.\n\nSuppose the following dataset is available (with a true CRR value of 1.02, 70% treatment-control split, and 40% non-compliance (never-takers))\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulate_data <- function(seed = 24, n = 1e5) {\n  \n  confounder_values <- seq(0, 1e5, 50) / 1e4\n  \n  set.seed(seed)\n  tibble(\n    id = 1:n,\n    # randomization indicator / instrument, indicates group assignment\n    Z = rbinom(n, 1, prob = 0.7),\n    # simulate continuous confounder value\n    U = sample(x = confounder_values, size = n, replace = TRUE),\n    # simulate (conditional) compliance indicator\n    prob_C = plogis(2 - 0.5 * U),\n    C = rbinom(n, 1, prob_C),\n    # simulate observed treatment\n    # potential continuous exposure value is simulated \n    # for each individual on [1, 100]\n    # but for those that have Z = 0 (control) or C = 0 (never-takers), A = 0\n    A = Z * C * pmin(pmax(round(rgamma(n, shape = 5, scale = 4)), 1), 100),\n    # response variable simulated with risk ratios specified\n    # baseline log probabilities\n    logpY0 = log(0.002) + log(1.4) * U,\n    # impact of treatment\n    logpY1 = logpY0 + log(1.02) * A,\n    # simulated binary responses from log-binomial model\n    Y = rbinom(n, 1, exp(logpY1))\n  )\n}\n\ndf_large <- simulate_data() %>%\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 100,000\nColumns: 9\n$ id     <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, …\n$ Z      <int> 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, …\n$ U      <dbl> 2.795, 5.120, 4.930, 1.090, 3.675, 7.735, 8.770, 8.085, 4.780, …\n$ prob_C <dbl> 0.64622806, 0.36354746, 0.38580036, 0.81076675, 0.54053584, 0.1…\n$ C      <int> 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, …\n$ A      <dbl> 23, 0, 0, 21, 20, 0, 0, 0, 0, 24, 0, 24, 0, 0, 0, 0, 10, 0, 21,…\n$ logpY0 <dbl> -5.274168, -4.491870, -4.555800, -5.847853, -4.978073, -3.61199…\n$ logpY1 <dbl> -4.818708, -4.491870, -4.555800, -5.431998, -4.582020, -3.61199…\n$ Y      <int> 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n```\n:::\n:::\n\n\nFor exploring g-estimation with no-unmeasured confounding (since $U$ is measured) in the simple model represented by the *directed acyclic graph* (DAG) $A \\leftarrow U \\rightarrow Y$ and $A \\rightarrow Y$, one way of estimating the treatment effect $\\psi$ is using *grid search* which visually looks like this when the estimated coefficient for $\\alpha_1$ is plotted on the Y-axis\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid_search_coefficient <- seq(-1, 1, 0.05) %>%\n  # get the coefficient from the correct and incorrect propensity models\n  map_dfr(.f = ~ {\n\n    temp_df <- df_large %>%\n      mutate(H = Y * exp(-.x * A))\n\n    list(`No unmeasured confounding` = \"A ~ H + U\", \n         `Unmeasured confounding` = \"A ~ H\") %>%\n      map_dfc(.f = ~ {\n        temp_df %>%\n          lm(formula(.x), data = .) %>%\n          tidy() %>%\n          filter(term == \"H\") %>%\n          pull(estimate)\n      }) %>%\n      mutate(psi = .x, .before = `No unmeasured confounding`)\n  }) \n\ngrid_search_coefficient %>%\n  pivot_longer(-psi) %>%\n  ggplot(aes(x = exp(psi), y = value, color = name)) +\n  geom_point() +\n  geom_line() +\n  geom_vline(xintercept = 1.02, linetype = \"dotdash\") +\n  geom_hline(yintercept = 0, linetype = \"dotdash\") +\n  geom_hline(yintercept = -2.5, linetype = \"dotdash\") +\n  xlab(\"Risk ratio (true value: 1.02)\") +\n  ylab(\n    glue::glue(\"Estimated coefficient for H(\\U1D713)\",\n               \" \\nfrom the propensity model\")\n  ) +\n  theme(legend.position = \"bottom\", legend.title = element_blank()) +\n  coord_cartesian(xlim = c(0, 3), ylim = c(-6, 4))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nor like this when the $p$-value is plotted on the Y-axis (on a narrower grid)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid_search_pvalue <- seq(-0.05, 0.05, 0.001) %>%\n  # get the coefficient from the correct and incorrect propensity models\n  map_dfr(.f = ~ {\n\n    temp_df <- df_large %>%\n      mutate(H = Y * exp(-.x * A))\n\n    list(`No unmeasured confounding` = \"A ~ H + U\", \n         `Unmeasured confounding` = \"A ~ H\") %>%\n      map_dfc(.f = ~ {\n        temp_df %>%\n          lm(formula(.x), data = .) %>%\n          tidy() %>%\n          filter(term == \"H\") %>%\n          pull(p.value)\n      }) %>%\n      mutate(psi = .x, .before = `No unmeasured confounding`)\n  }) \n\ngrid_search_pvalue %>%\n  pivot_longer(-c(psi)) %>%\n  ggplot(aes(x = exp(psi), y = value, color = name)) +\n  geom_point() +\n  geom_line() +\n  geom_vline(xintercept = 1.02, linetype = \"dotdash\") +\n  geom_hline(yintercept = 0, linetype = \"dotdash\") +\n  xlab(\"Risk ratio (true value: 1.02)\") +\n  ylab(\"P-value for the test of alpha1 = 0\") +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nFrom both the graphs, it's evident that the estimate from the correctly specified propensity model is much closer to the true value of 1.02 (or 2% increase when going from $A = a$ to $A = a + 1$) compared to the estimate from the propensity model without $U$. Recovering the true effect in the presence of unmeasured confounding would require knowing which non-zero value of $\\alpha_1$ (here about -2.5) corresponds to the true value of $\\psi$.\n\nGrid search can be kinda tedious[^10] and computationally inefficient when there are multiple treatment parameters[^11], but [this paper](https://academic.oup.com/aje/article/187/5/1079/4930819) shows a neat trick using *log-link* *Gamma Generalized Estimating Equations (GEE)* to estimate risk ratios using regression adjustment for the propensity score\n\n[^10]: It was annoying to use grid-search with p-values for this setting - if the grid was too coarse so there weren't any points close to the true value, then the p-values were very close to zero, which explains the fine grid used here. Calling `optimize(gest_function, interval = c(-5, 5), maximum = TRUE)` where gest_function takes $\\psi$ as an input and returns the p-value as the output failed to find the correct value, until the interval was narrowed to (0, 2). The coefficient estimate function wouldn't work too well either, since risk ratio values less than 1 lead to estimates of $\\alpha_1$ to be very close to 0.\n\n[^11]: to account for effect-measure modification or heterogeneity of treatment effect\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\npropensity_scores <- mgcv::gam(A ~ s(U, k = 10), data = df_large) %>%\n  fitted()\n\npropensity_scores %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.625   2.061   5.345   5.847   9.565  12.438 \n```\n:::\n\n```{.r .cell-code  code-fold=\"false\"}\ngest_confounder <- df_large %>%\n  mutate(PS = propensity_scores) %>%\n  geeM::geem(Y ~ PS + A, data = ., family = Gamma(link = \"log\"),\n             corstr = \"independence\", sandwich = TRUE)\n\nsummary(gest_confounder)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Estimates Model SE Robust SE    wald     p\n(Intercept)  -3.02200 0.061950  0.041350 -73.080 0e+00\nPS           -0.25020 0.009526  0.011600 -21.580 0e+00\nA             0.01937 0.003600  0.003923   4.936 8e-07\n\n Estimated Correlation Parameter:  0 \n Correlation Structure:  independence \n Est. Scale Parameter:  117.9 \n\n Number of GEE iterations: 2 \n Number of Clusters:  100000    Maximum Cluster Size:  1 \n Number of observations with nonzero weight:  100000 \n```\n:::\n:::\n\n\nUnfortunately there's no *tidier* for objects of class `geem` in the `broom` package, but it's easy enough to write one to extract information from the fitted model as a data frame --- see the following code block\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy.geem <- function(x, conf.int = FALSE, \n                      exponentiate = FALSE, \n                      conf.level = 0.95, \n                      robust = TRUE, ...) {\n  # works only when broom is attached\n  # as it's added as an S3 method for broom::tidy(x, ...)\n  # could also do library(broom, include.only = \"tidy\")\n  #\n  # arguments are the same as broom::tidy.geeglm()\n  stopifnot(is.logical(robust))\n  s <- summary(x)\n  ret <- c(\"term\" = \"coefnames\", \"estimate\" = \"beta\",\n           \"std.error\" = if (robust) \"se.robust\" else \"se.model\",\n           \"statistic\" = \"wald.test\", \"p.value\" = \"p\") %>%\n    map(.x = ., .f = ~ pluck(s, .x)) %>%\n    as_tibble()\n\n  if (conf.int) {\n    p <- (1 + conf.level) / 2\n    ret <- ret %>%\n      mutate(\n        conf.low = estimate - (qnorm(p = p) * std.error),\n        conf.high = estimate + (qnorm(p = p) * std.error),\n      )\n  }\n\n  if (exponentiate) {\n    # exponentiate the point estimate and the CI endpoints (if present)\n    ret <- ret %>%\n      mutate(\n        across(\n          .cols = -c(term, std.error, statistic, p.value),\n          .fns = exp\n        )\n      )\n  }\n\n  return(ret)\n}\n\ngest_confounder %>%\n  tidy(exponentiate = TRUE, conf.int = TRUE, robust = TRUE) %>%\n  filter(term == \"A\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 7\n  term  estimate std.error statistic   p.value conf.low conf.high\n  <chr>    <dbl>     <dbl>     <dbl>     <dbl>    <dbl>     <dbl>\n1 A         1.02   0.00392      4.94 0.0000008     1.01      1.03\n```\n:::\n:::\n\n\nThis can also be compared with the usual regression estimate\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nglm_model <- glm(Y ~ U + A, data = df_large, family = binomial(link = \"log\"))\n\nglm_model %>% \n  tidy(exponentiate = TRUE, conf.int = TRUE) %>% \n  mutate(across(.cols = where(is.numeric), .fns = ~ round(.x, 4)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 7\n  term        estimate std.error statistic p.value conf.low conf.high\n  <chr>          <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n1 (Intercept)   0.0022    0.0833    -73.3        0   0.0019    0.0026\n2 U             1.38      0.0104     31.1        0   1.36      1.41  \n3 A             1.02      0.0025      8.52       0   1.02      1.03  \n```\n:::\n:::\n\n\nBut what if $U$ is unmeasured?\n\n## G-estimation with an IV\n\nIn a randomized trial with perfect compliance, $A$ and $Z$ will be identical so a simple analysis using either one of these will result in an unbiased estimate of the average treatment effect. On the other hand, in the presence of imperfect compliance due to unmeasured confounding, an unadjusted analysis of $A - Y$ will lead to biased estimates of the effect of treatment, and an unadjusted analysis of $Z - Y$ will lead to an estimate of assigning treatment[^12] instead of receiving the treatment. Analyzing only $A-Y$, the estimated treatment effect concentrates around 0.98 on average instead of 1.02\n\n[^12]: i.e., the *intention-to-treat* effect (ITT)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# specify the seed\nseq(1, 100, 1) %>% \n  map_dbl(.f = ~ {\n    .x %>% \n      simulate_data(seed = ., n = 1e4) %>% \n      glm(Y ~ A, data = ., family = binomial(link = \"log\")) %>%\n      tidy(exponentiate = TRUE) %>%\n      filter(term == \"A\") %>% \n      pull(estimate)\n  }) %>% \n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.9578  0.9741  0.9815  0.9810  0.9864  1.0035 \n```\n:::\n:::\n\n\nIf the DAG with relationships $A \\leftarrow U \\rightarrow Y$ and $Z \\rightarrow A \\rightarrow Y$ holds but only $(Z, A, Y)$ are observed, and $Z$ is a variable that meets the IV conditions[^13], the effect of $A$ ($\\text{ATE}$ or $\\text{ATT}_{IV}$) can be estimated under some additional assumptions.\n\n[^13]: Associated with $A$ (relevance), not associated with any variables in the set $U$ (ignorability), and no direct effect on $Y$ (exclusion restriction)\n\nThe key idea is captured by this (estimating) equation\n\n$$\n\\sum_{i = 1}^n (z_i - \\bar{z})\\ y_i\\ \\text{exp}(-\\psi\\ a_i) = 0\n$$\n\nwhere $\\bar{z}$ denotes the proportion of individuals assigned to the treatment arm.\n\nSince $Z$ is randomly assigned, it should be balanced with respect to all measured and unmeasured confounders $U$. But $A$ may not be. So the correct estimate of $\\psi$ is the one that leads to zero covariance between the residuals $Y^{a = 0}$ (or $H(\\psi)$) and $Z$[^14]. Pretty magical, if you ask me.\n\n[^14]: If $(a_i - \\bar{a})$ were to be used instead of $(z_i - \\bar{z})$, then the estimate would be the same one as from the $A- Y$ analysis.\n\nThis equation can be coded up as a function which visually looks like this\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMSNMM_function <- function(psi, data = df_large, positive = TRUE) {\n  result <- data %>%\n    mutate(\n      Zbar = mean(Z),\n      s = (Z - Zbar) * Y * exp(-psi * A)\n    ) %>%\n    pull(s) %>%\n    sum()\n\n  if (positive) result <- abs(result)\n\n  return(result)\n}\n\nIV_grid <- seq(-0.05, 0.5, 0.01) %>%\n  tibble(psi = .) %>%\n  rowwise() %>%\n  mutate(\n    `Raw value` = MSNMM_function(psi, positive = FALSE),\n    `Absolute value` = abs(`Raw value`)\n  ) %>%\n  ungroup() %>%\n  pivot_longer(-psi) %>%\n  mutate(name = fct_rev(factor(name))) \n\nIV_grid %>%\n  ggplot(aes(x = exp(psi), y = value, color = name)) +\n  geom_point() + geom_line() +\n  geom_hline(yintercept = 0, linetype = \"dotdash\") +\n  geom_vline(xintercept = 1.02, linetype = \"dotdash\") +\n  theme(legend.position = \"bottom\", legend.title = element_blank()) +\n  scale_x_continuous(n.breaks = 10) +\n  xlab(\"Risk ratio (true value: 1.02)\") +\n  ylab(\"Covariance between Z and H(\\U1D713)\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nInstead of using grid search, the `optimize()` function can be used with the absolute value of the covariance to pick the value of $\\psi$ that leads to 0 covariance[^15]\n\n[^15]: if the function is flat in the specified interval, the optimization step would return incorrect results (passing \\`interval = c(3, 5)\\` returns the value of 3 and an objective function value of 83.8 which is far away from 0)\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\noptimize(f = MSNMM_function, interval = c(-2, 2), maximum = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$minimum\n[1] 0.01308194\n\n$objective\n[1] 0.03266255\n```\n:::\n:::\n\n\nThis is a slight underestimate (1.013 vs 1.02) --- but it seems to be a sampling artifact as the median of 100 simulated values concentrates around 1.02\n\n\n::: {.cell}\n\n```{.r .cell-code}\nIV_estimates <- map_dbl(\n  .x = 1:100,\n  .f = ~ {\n    .x %>%\n      simulate_data(seed = .) %>%\n      optimize(\n        f = MSNMM_function, interval = c(-2, 2), \n        maximum = FALSE, data = .\n      ) %>%\n      pluck(\"minimum\")\n  })\n\nIV_estimates %>% exp() %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.9966  1.0136  1.0206  1.0219  1.0304  1.0536 \n```\n:::\n:::\n\n\nIt might just be simpler to use the `ivglm()` function from the `ivtools` package (see [this paper](https://www.degruyter.com/document/doi/10.1515/em-2018-0024/html)) to accomplish the same thing though[^16]\n\n[^16]: which has other advantages like handling multiple instruments and different effect measures\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nIV_model <- glm(Z ~ 1, family = binomial(link = \"logit\"), data = df_large)\n\nIV_gest <- df_large %>%\n  # need to cast tibble as a data frame to avoid cryptic errors\n  as.data.frame() %>%\n  ivtools::ivglm(estmethod = \"g\",\n                 X = \"A\", Y = \"Y\",\n                 fitZ.L = IV_model,\n                 link = \"log\", data = .)\n\nIV_gest %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:  \nivtools::ivglm(estmethod = \"g\", X = \"A\", Y = \"Y\", fitZ.L = IV_model, \n    data = ., link = \"log\")\n\nCoefficients: \n  Estimate Std. Error z value Pr(>|z|)\nA  0.01310    0.01065    1.23    0.219\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# get the coefficient and CI\nglue::glue(\n  \"Mean: {round(exp(c(summary(IV_gest)$coefficients[1, 1])), 4)}\", \n  \" with 95% CI: ({round(exp(confint(IV_gest))[1], 4)},\", \n  \" {round(exp(confint(IV_gest))[2], 4)})\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMean: 1.0132 with 95% CI: (0.9923, 1.0346)\n```\n:::\n:::\n\n\nwhere it produces nearly the same estimate as above and additionally has the option of plotting the shape of the estimating equations in a neighborhood of the estimate\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# can use ggplot on the output from estfun()\n# ivtools::estfun(IV_gest, lower = -0.1, upper = 0.1, step = 0.01) %>% \n#   pluck(\"f\") %>%  \n#   pluck(\"A\") %>% \n#   data.frame() %>% \n#   ggplot(aes(x = exp(psi), y = Hsum)) + \n#   geom_point() +\n#   geom_line() \n\nplot(ivtools::estfun(IV_gest, lower = -0.1, upper = 0.1, step = 0.01))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nA caveat is that this approach can sometimes fail when this function has a weird shape in the presence of weak instruments (see [this paper](https://academic.oup.com/aje/article/180/1/111/2739174)).\n\n## Estimating probabilities\n\nIf we had the model which included $U$ as a covariate, conditional probabilities $\\text{Pr}[Y = 1 | A = a, U = u]$ as well as marginal probabilities $\\text{Pr}[Y = 1 | A = a]$ (averaged over levels of $U$) could be generated using the amazing *marginaleffects* package to perform *g-computation* with the resulting *dose-response curves* visualized*.*\n\nThe following plot with conditional dose-response curves at quartiles of $U$ shows that the effect of the treatment with increasing $A$ is increasing across levels of $U$ --- which makes sense because the treatment effect is a multiplicative (percent) change relative to the previous level[^17]\n\n[^17]: the effects of $A$ and $U$ are linear on the log scale but not on the transformed probability scale\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get predicted probabilities from the model at quartiles of U\nglm_model %>%\n  marginaleffects::plot_predictions(condition = list(\"A\", \"U\" = \"fivenum\")) +\n  xlab(\"A\") +\n  ylab(\"Predicted probability of Y = 1\") + \n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nWhen $U$ is unmeasured, only the marginal dose-response curve can be estimated, and the following plot compares g-computation and g-estimation estimates and their CIs, with the true curve plotted for comparison\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulate 100 datasets and take the mean of probabilities under A = 0\nbaseline_conversion_probability <- map_dbl(\n  .x = 1:100,\n  .f = ~ {\n    simulate_data(seed = .x, n = 1e5) %>%\n      pull(logpY0) %>%\n      exp() %>%\n      mean()\n    }) %>%\n  mean()\n\n# true dose-response curve\ntrue_dose_response_curve <- tibble(\n  A = 0:73,\n  estimate = baseline_conversion_probability * exp(log(1.02) * A)\n)\n\n# g-computation by creating counterfactual predictions\n# by setting A = a and averaging the predicted probabilities\n# doing this over a coarser grid to get faster run times\ng_computation_dose_response_extrapolated_levels <- glm_model %>%\n  marginaleffects::predictions(\n    by = \"A\", type = \"response\",\n    newdata = marginaleffects::datagrid(\n      A = c(0, seq(5, 70, 5), 73), grid_type = \"counterfactual\"\n    )\n  ) %>%\n  select(A, estimate, conf.low, conf.high) %>%\n  as_tibble() %>% \n  mutate(type = \"G-computation\")\n\n# get estimates of Pr[Y = 1 | A = 0]\n# by shaving off the effect of the treatment\n# using the point estimate and CI endpoints from ivglm\ng_estimation_pY0 <- c(\n  IV_gest %>% pluck(\"est\") %>% unname(),\n  IV_gest %>% confint() %>% unname()\n) %>%\n  set_names(nm = c(\"estimate\", \"conf.low\", \"conf.high\")) %>%\n  map_dfr(\n    .f = ~ {\n      df_large %>%\n        mutate(H = Y * exp(-.x * A)) %>%\n        pull(H) %>%\n        mean() %>%\n        tibble(logRR = .x, pY0 = .)\n    }, \n    .id = \"name\"\n  )\n\n# using logRR estimate + CI and Pr[Y = 1 | A = 0]\ng_estimation_dose_response <- g_estimation_pY0 %>%\n  expand_grid(., A = 0:73) %>%\n  # get P[Y = 1 | A = a]\n  mutate(pY = pY0 * exp(logRR * A)) %>%\n  select(-pY0, -logRR) %>%\n  pivot_wider(id_cols = A, names_from = \"name\", values_from = \"pY\") %>%\n  mutate(type  = \"G-estimation (using an IV)\")\n\nbind_rows(\n  g_computation_dose_response_extrapolated_levels,\n  g_estimation_dose_response\n) %>%\n  ggplot(aes(x = A, y = estimate, color = type)) +\n  geom_line() +\n  # plot the true curve\n  geom_line(\n    data = true_dose_response_curve, \n    aes(x = A, y = estimate), \n    color = \"gray20\", linewidth = 1.2,, linetype = \"dotdash\",\n    inherit.aes = FALSE\n  ) + \n  geom_ribbon(\n    aes(ymin = conf.low, ymax = conf.high, fill = type), alpha = 0.2\n  ) +\n  scale_y_continuous(breaks = seq(0, 0.25, 0.05)) +\n  scale_x_continuous(breaks = seq(0, 80, 10)) +\n  theme(legend.position = \"bottom\", legend.title = element_blank()) +\n  ylab(\"Predicted probability of Y = 1\") + \n  xlab(\"A (true curve in gray)\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nAssuming no-effect modification by $U$, the point estimate and the CI endpoints from `ivglm` are used to first estimate $\\text{Pr}[Y = 1 | A = 0]$ (which is the same as $\\text{Pr}[Y^{a = 0} = 1]$[^18]) by using the following relation\n\n[^18]: assuming consistency\n\n$$\n\\text{Pr}[Y^{a = 0} = 1] = \\text{Pr}[Y = 1 | A = 0] = \\text{E}[Y\\ \\text{exp}(\\psi A)]\n$$\n\nand then using these to get the dose response curves and the following CIs\n\n$$\n\\text{Pr}[Y = 1 | A] = \\text{Pr}[Y = 1 | A = 0]\\ \\text{exp}[\\psi A]\n$$\n\nThe g-computation estimate is far narrower as the model has access to the information provided by $U$, compared to the MSMM. The MSMM estimate for this sample underestimates the true value, which shows up as a large difference between the true and the MSMM curves at values of $A$ higher than 60.\n\nThese probabilities can be mapped to total sales / profit given the number of individuals within each treatment level. Whether these numbers can be *transported* or extrapolated to future campaigns or other populations depends on how similar the distribution of $U$ is across these groups. In that sense, these marginal estimates are actually conditional on the distribution of confounders and effect modifiers. I came across [this paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5784860/) which would be interesting to read in the future.\n\n## References\n\nThis post is based on the following references\n\n-   [Hernán, Robins](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/) - Causal Inference: What If? - Chapters 14 (g-estimation), and 16 (instrumental variables)\n\n-   [Vansteelandt et al. 2011](https://projecteuclid.org/journals/statistical-science/volume-26/issue-3/On-Instrumental-Variables-Estimation-of-Causal-Odds-Ratios/10.1214/11-STS360.full) - On Instrumental Variables Estimation of Causal Odds Ratios\n\n-   [Palmer et al. 2011](https://academic.oup.com/aje/article/173/12/1392/205870) - Instrumental Variable Estimation of Causal Risk Ratios and Causal Odds Ratios in Mendelian Randomization Analyses\n\n-   [Dukes, Vansteelandt 2018](https://academic.oup.com/aje/article/187/5/1079/4930819) - A Note on G-Estimation of Causal Risk Ratios\n\n-   [Burgess et al. 2014](https://academic.oup.com/aje/article/180/1/111/2739174) - Lack of Identification in Semiparametric Instrumental Variable Models With Binary Outcomes\n\n-   [Sjolander, Martinussen 2019](https://www.degruyter.com/document/doi/10.1515/em-2018-0024/html) - Instrumental Variable Estimation with the R Package ivtools\n\n## Simulated data\n\nThe four figures --- going clockwise from top left --- show 1) the probability of compliance as a function of the confounder $U$ (where $\\text{Pr}[C = 1 | U] = 1 / (1 + \\text{exp}(-2 + 0.5)) u,\\ u \\in [0, 10]$), 2) the realized distribution of the treatment levels among those who received the treatment[^19] simulated from the truncated *Gamma* distribution $x_i \\sim \\text{max}(1, \\text{min}(\\Gamma(\\text{shape} = 5,\\ \\text{scale} = 4), 100))$, 3) balance of $U$ across levels of $Z$ (which is balanced because of randomization), and 4) balance of $U$ across levels of $A$ (which is *not* balanced because of confounding by $U$)\n\n[^19]: a value is sampled for each individual, but is realized only if $Z = 1$ and $C = 1$ (where $C$ is the compliance indicator)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# probability of compliance as a function of the confounder\np_compliance <- df_large %>%\n  ggplot(aes(x = U, y = prob_C)) +\n  geom_line() + \n  ylab(\"Compliance probability\") +\n  coord_cartesian(y = c(0, 1))\n\n# observed distribution of exposure levels\nA_dist <- df_large %>%\n  filter(A > 0) %>%\n  ggplot(aes(x = A)) +\n  geom_bar() +\n  scale_x_continuous(breaks = seq(0, 100, 10), \n                     labels = seq(0, 100, 10))\n\n# check balance of U across Z\n# balanced as expected, because Z is a randomization indicator\nUZ_plot <- df_large %>%\n  mutate(Z = factor(Z, levels = c(1, 0), \n                    labels = c(\"Treatment\", \"Control\"))) %>%\n  ggplot(aes(x = U, color = Z)) +\n  geom_density() +\n  theme(legend.position = \"bottom\")\n\n# check balance across (dichotomized version of) A\n# not balanced because U and A are associated\nUA_plot <- df_large %>%\n  mutate(\n    `A (binary)` = factor(as.numeric(A > 0), \n                          levels = c(1, 0), \n                          labels = c(\"Treated\", \"Control\"))) %>%\n  ggplot(aes(x = U, color = `A (binary)`)) +\n  geom_density() +\n  theme(legend.position = \"bottom\")\n\ngridExtra::grid.arrange(p_compliance, A_dist, \n                        UZ_plot, UA_plot, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}