[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m a data scientist / statistician / autodidact currently living in the magical city of Gent, Belgium. I have degrees in mathematics and statistics, as well as more than six years of experience working as a data scientist across multiple industries – advertising, marketing, telecommunications, and vaccine epidemiology.\nMy professional interests revolve around statistics / machine learning, programming, distributed computing, writing clean code, and using models to make real-world decisions.\nIn my free time, I like to read, cook, cycle, play tennis, and learn languages.\nThe primary reason for starting this (mostly) technical blog is to work through some (technical) concepts or challenges I encounter. Additional reasons include having my R / Python code in a clean and easy-to-navigate format, and to share recipes once in a while. I’ve been talking about wanting to have a blog since 2012, so I’m glad that I finally got around to having one in 2022.\nYou can reach out to me via LinkedIn or via email (first name [dot] last name [at] gmail)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Akshat Dwivedi",
    "section": "",
    "text": "Specifying an offset in a Tweedie model with identity link\n\n\n\n\n\n\n\nR\n\n\nTweedie\n\n\nOffset\n\n\n\n\n\n\n\n\n\n\n\nJul 30, 2023\n\n\n\n\n\n\n  \n\n\n\n\nOne reason why a (g)lm coefficient is NA\n\n\n\n\n\n\n\nR\n\n\nGLM\n\n\nMulticollinearity\n\n\n\n\n\n\n\n\n\n\n\nMar 31, 2023\n\n\n\n\n\n\n  \n\n\n\n\nGEE on aggregated data?\n\n\n\n\n\n\n\nR\n\n\nGLM\n\n\nGEE\n\n\n\n\n\n\n\n\n\n\n\nMar 20, 2023\n\n\n\n\n\n\n  \n\n\n\n\nDetermining the volume of my (cocktail) jigger\n\n\n\n\n\n\n\nMiscellaneous\n\n\nMeasurement\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJan 9, 2023\n\n\n\n\n\n\n  \n\n\n\n\nHow Many Five-Star Ratings Do I Need?\n\n\n\n\n\n\n\nAnalysis\n\n\nSimulation\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nAug 16, 2022\n\n\n\n\n\n\n  \n\n\n\n\nHello, World!\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 1, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/gee-on-aggregated-data/index.html",
    "href": "posts/gee-on-aggregated-data/index.html",
    "title": "GEE on aggregated data?",
    "section": "",
    "text": "TL;DR: The geepack R package doesn’t do what it doesn’t claim to do"
  },
  {
    "objectID": "posts/gee-on-aggregated-data/index.html#model",
    "href": "posts/gee-on-aggregated-data/index.html#model",
    "title": "GEE on aggregated data?",
    "section": "Model",
    "text": "Model\nThe code below simulates data from the following mixed-effects model2 with random-intercept terms where person \\(j\\) is nested within cluster \\(i\\). Each cluster has a different proportion of treatment uptake \\(p_{treated,j}\\) varying between 40-60% where \\(X_{ij}\\) indicates whether person \\(j\\) in cluster \\(i\\) received the treatment or not.2 The model syntax is inspired by the statistical rethinking book\n\\[\n\\begin{gather}\nY_{ij} \\sim \\text{Bernoulli}(p_{ij}) \\\\\n\\text{logit}(p_{ij}) = -1.4 + 0.3 \\times X_{ij} + \\alpha_i \\\\\n\\alpha_i \\sim \\text{Normal}(0, 1) \\\\\nX_{ij} \\sim \\text{Bernoulli}(p_{treated,i}) \\\\\np_{treated,i} \\sim \\text{Uniform(0.4, 0.6)}\n\\end{gather}\n\\]\nThe time taken to train the model on the raw as well as the aggregate data, the point estimates, and standard errors for the coefficients are stored for analysis."
  },
  {
    "objectID": "posts/gee-on-aggregated-data/index.html#code",
    "href": "posts/gee-on-aggregated-data/index.html#code",
    "title": "GEE on aggregated data?",
    "section": "Code",
    "text": "Code\n\nsimulate_data_and_get_estimates &lt;- function(n, n_clus, seed) {\n  set.seed(seed)\n  # cluster random intercept\n  rand_intercept &lt;- rnorm(n_clus, mean = 0, sd = 1)\n\n  set.seed(seed)\n  sim_data &lt;- map_dfr(.x = 1:n_clus, .f = ~ {\n    tibble(\n      id = .x,\n      x = rbinom(round(n / n_clus), size = 1, prob = runif(1, 0.4, 0.6)),\n      y = rbinom(round(n / n_clus), size = 1, prob = plogis(-1.4 + 0.3 * x + rand_intercept[[.x]]))\n    )\n  })\n\n  # fit model to raw data\n  t0 &lt;- Sys.time()\n  mod1_sim &lt;- geeglm(\n    y ~ x,\n    data = sim_data,\n    family = \"binomial\", id = id, corstr = \"exchangeable\"\n  )\n  t1 &lt;- Sys.time()\n  t1 &lt;- as.numeric(difftime(t1, t0, units = \"secs\"))\n\n  # fit GLM model to raw data\n  mod1_sim_glm &lt;- glm(y ~ factor(id) + x - 1,\n                      data = sim_data, family = \"binomial\")\n\n  # fit model to aggregated data\n  agg_data &lt;- sim_data %&gt;%\n    group_by(id, x) %&gt;%\n    summarize(n = n(), y = sum(y), .groups = \"drop\") %&gt;%\n    mutate(y_prob = y / n)\n\n  t2 &lt;- Sys.time()\n  mod2_sim &lt;- geeglm(\n    y_prob ~ x,\n    data = agg_data, weights = n,\n    family = \"binomial\", id = id, corstr = \"exchangeable\"\n  )\n  t3 &lt;- Sys.time()\n  t3 &lt;- as.numeric(difftime(t3, t2, units = \"secs\"))\n\n  # fit GLM model to aggregated data\n  mod2_sim_glm &lt;- glm(y_prob ~ factor(id) + x - 1, data = agg_data,\n                      weights = n, family = \"binomial\")\n\n  results &lt;- bind_rows(\n    # GEE results\n    broom::tidy(mod1_sim) %&gt;%\n      mutate(data = 'raw data', time_secs = t1, estimator = \"GEE\"),\n    broom::tidy(mod2_sim) %&gt;%\n      mutate(data = 'aggregated data', time_secs = t3, estimator = \"GEE\"),\n    # GLM results\n    broom::tidy(mod1_sim_glm) %&gt;%\n      mutate(data = 'raw data', time_secs = NA_real_, estimator = \"GLM\"),\n    broom::tidy(mod2_sim_glm) %&gt;%\n      mutate(data = 'aggregated data', time_secs = NA_real_, estimator = \"GLM\")\n  ) %&gt;%\n    mutate(n = n, n_clus = n_clus, seed = seed) %&gt;%\n    filter(!stringr::str_detect(term, pattern = \"id\"))\n\n  return(results)\n}\n\nHere’s what the output from this function looks like:\n\nsimulate_data_and_get_estimates(n = 100, n_clus = 5, seed = 3)\n\n# A tibble: 6 × 11\n  term       estim…¹ std.e…² stati…³ p.value data  time_s…⁴ estim…⁵     n n_clus\n  &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 (Intercep…  -1.59    0.409 15.0    1.07e-4 raw …  0.00748 GEE       100      5\n2 x           -0.144   0.383  0.141  7.07e-1 raw …  0.00748 GEE       100      5\n3 (Intercep…  -1.73    0.395 19.1    1.27e-5 aggr…  0.00326 GEE       100      5\n4 x           -0.107   0.402  0.0702 7.91e-1 aggr…  0.00326 GEE       100      5\n5 x           -0.266   0.596 -0.446  6.55e-1 raw … NA       GLM       100      5\n6 x           -0.266   0.596 -0.446  6.55e-1 aggr… NA       GLM       100      5\n# … with 1 more variable: seed &lt;dbl&gt;, and abbreviated variable names ¹​estimate,\n#   ²​std.error, ³​statistic, ⁴​time_secs, ⁵​estimator\n\n\n\nsimulation_parameters &lt;- expand_grid(\n  n = c(100, 500, 1000, 2500, 5000, 7500, 10000),\n  n_clus = c(5, 50, 250),\n  seed = 1:20\n) %&gt;% \n  # remove runs where number of clusters is larger than total sample size\n  filter(n_clus &lt; n)\n\n# set up multicore processing\nplan(multisession, workers = 15)\n\n# parallelize purrr::pmap_dfr by using the {furrr} package\nsimulation_results &lt;- future_pmap_dfr(\n  .l = simulation_parameters,\n  # have to pass args as ..1 or ..2, else it fails\n  .f = ~ simulate_data_and_get_estimates(n = ..1, n_clus = ..2, seed = ..3),\n  .options = furrr_options(seed = NULL)\n)\n\nplan(sequential) # turn off multicore\n\nThis chunk can take a while to run for some of the parameter combinations, so pre-computed results are loaded and analyzed further.\n\nsimulation_results &lt;- read_csv(file = \"gee_glm_sim.csv\", show_col_types = FALSE) %&gt;% \n  mutate(\n    n_clus_raw = n_clus,\n    n_clus = factor(paste0(\"# clusters: \", n_clus),\n                    levels = paste0(\"# clusters: \", c(5, 50, 250))),\n    term = case_when(\n      term == \"(Intercept)\" ~ \"Intercept\",\n      term == \"x\" ~ \"Slope\", \n      TRUE ~ term\n  ))\n\nglimpse(simulation_results)\n\nRows: 2,400\nColumns: 12\n$ term       &lt;chr&gt; \"Intercept\", \"Slope\", \"Intercept\", \"Slope\", \"Slope\", \"Slope…\n$ estimate   &lt;dbl&gt; -7.17e-01, -7.38e-02, -5.35e-01, -1.14e-01, -5.92e-02, -5.9…\n$ std.error  &lt;dbl&gt; 4.69e-01, 1.75e-01, 4.09e-01, 1.53e-01, 4.86e-01, 4.86e-01,…\n$ statistic  &lt;dbl&gt; 2.3402, 0.1772, 1.7056, 0.5518, -0.1216, -0.1216, 7.1290, 4…\n$ p.value    &lt;dbl&gt; 1.26e-01, 6.74e-01, 1.92e-01, 4.58e-01, 9.03e-01, 9.03e-01,…\n$ data       &lt;chr&gt; \"raw data\", \"raw data\", \"aggregated data\", \"aggregated data…\n$ time_secs  &lt;dbl&gt; 0.01389, 0.01389, 0.00420, 0.00420, NA, NA, 0.00928, 0.0092…\n$ estimator  &lt;chr&gt; \"GEE\", \"GEE\", \"GEE\", \"GEE\", \"GLM\", \"GLM\", \"GEE\", \"GEE\", \"GE…\n$ n          &lt;dbl&gt; 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,…\n$ n_clus     &lt;fct&gt; # clusters: 5, # clusters: 5, # clusters: 5, # clusters: 5,…\n$ seed       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4,…\n$ n_clus_raw &lt;dbl&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,…"
  },
  {
    "objectID": "posts/gee-on-aggregated-data/index.html#computation-time",
    "href": "posts/gee-on-aggregated-data/index.html#computation-time",
    "title": "GEE on aggregated data?",
    "section": "Computation time",
    "text": "Computation time\nFirst, the time taken to fit the model to the raw dataset is shown as a function of total sample size \\(n\\) where there are \\(n / n_{clus}\\) observations per cluster. Each panel has a different y-axis to allow reading values directly from the plot.\n\nsimulation_results %&gt;%\n  filter(data == \"raw data\", estimator == \"GEE\") %&gt;%\n  # distinct here since the data frame contains a row for\n  # each of the intercept and slope terms but the runtimes are the same\n  # for both these terms\n  distinct(seed, time_secs, n, n_clus) %&gt;%\n  ggplot(aes(x = n, y = time_secs, group = n_clus)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, degree = 3)) +\n  geom_smooth(method = \"lm\", formula = y ~ I(x ^ 3), color = \"forestgreen\") +\n  stat_summary(aes(group = interaction(n_clus, n)), geom = \"point\", \n               fun = mean, color = \"darkorange\", size = 2) + \n  xlab(\"Total sample size (n)\") +\n  ylab(\"Runtime (in seconds)\") +\n  facet_wrap(~ n_clus, scales = \"free\")\n\n\n\n\nThe blue line fits a cubic polynomial \\[time = \\beta_0 + \\beta_1 n + \\beta_2 n^2 + \\beta_3 n^3 + \\varepsilon\\] to the run times as a function of sample size. The green line fits the same model but without the linear and quadratic terms, i.e, \\(time = \\alpha_0 + \\alpha_1 n^3 + \\varepsilon\\). The yellow points are the mean run times for each level of \\(n\\) within each panel.\nWhen the number of clusters is very small, an increase in the sample size within the largest cluster leads to a cubic increase in expected run times. The closeness of the blue and green lines in the leftmost panel indicates that the cubic term in the execution time model dominates the lower order terms. In the second and third panels, the \\(O(n^3)\\) limit hasn’t hit yet, as the green and the blue lines are in disagreement.\nFor 10000 samples split into 2000 samples in each of the five clusters, it takes approximately 15 minutes per run. The same total sample size split into 250 samples in each of the 40 clusters, each model takes about 7 seconds to run, and even less time when there are 250 clusters. This is a massive difference in time between the different settings."
  },
  {
    "objectID": "posts/gee-on-aggregated-data/index.html#convergence-issues",
    "href": "posts/gee-on-aggregated-data/index.html#convergence-issues",
    "title": "GEE on aggregated data?",
    "section": "Convergence issues",
    "text": "Convergence issues\nHowever, unfortunately some of the models run into convergence issues, where the point estimates and the standard errors explode\n\nsimulation_results %&gt;% \n  filter(estimator == \"GEE\") %&gt;% \n  arrange(desc(std.error)) %&gt;% \n  head(n = 10)\n\n# A tibble: 10 × 12\n   term      estimate std.e…¹ stati…² p.value data  time_…³ estim…⁴     n n_clus\n   &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;fct&gt; \n 1 Intercept  4.24e16 1.22e16  12.1   5.12e-4 aggr… 0.00516 GEE     10000 # clu…\n 2 Intercept  1.13e17 8.91e15 161.    0       aggr… 0.00621 GEE      7500 # clu…\n 3 Intercept -1.99e17 7.88e15 641.    0       aggr… 0.0175  GEE      1000 # clu…\n 4 Intercept  2.32e15 7.25e15   0.102 7.49e-1 aggr… 0.00667 GEE      7500 # clu…\n 5 Intercept  5.32e15 6.59e15   0.650 4.20e-1 aggr… 0.00582 GEE       100 # clu…\n 6 Slope     -1.69e15 2.25e15   0.562 4.53e-1 aggr… 0.0110  GEE      2500 # clu…\n 7 Intercept  9.69e14 2.12e15   0.210 6.47e-1 aggr… 0.00558 GEE     10000 # clu…\n 8 Slope     -1.03e15 2.09e15   0.241 6.23e-1 aggr… 0.00763 GEE      7500 # clu…\n 9 Slope     -1.94e15 2.05e15   0.896 3.44e-1 aggr… 0.00503 GEE     10000 # clu…\n10 Slope      3.82e15 1.88e15   4.13  4.23e-2 aggr… 0.00817 GEE      5000 # clu…\n# … with 2 more variables: seed &lt;dbl&gt;, n_clus_raw &lt;dbl&gt;, and abbreviated\n#   variable names ¹​std.error, ²​statistic, ³​time_secs, ⁴​estimator\n\n\nThis seems to be a problem when training GEE models on aggregated data when the number of clusters is low irrespective of the total sample size, which leads to about 21% of the estimates from the aggregated data being convergence failures. An estimate is flagged as convergence failure when the stdandard error of the coefficients &gt; 5 on the logit scale.\n\nsimulation_results &lt;- simulation_results %&gt;%\n  mutate(high_se = as.numeric(std.error &gt; 5)) \n\nsimulation_results %&gt;%\n  filter(estimator == \"GEE\") %&gt;% \n  select(-estimate, -std.error, -statistic, -p.value, -time_secs) %&gt;%\n  # put intercept and slope estimates in one row\n  pivot_wider(everything(), names_from = term, values_from = high_se) %&gt;%\n  # if at least one of the intercept or slope terms have a very high se\n  mutate(high_se = pmin(Intercept + Slope, 1)) %&gt;%\n  group_by(data, n_clus, n) %&gt;%\n  summarize(n_total = n(), n_failed = sum(high_se), .groups = \"drop_last\") %&gt;%\n  #print(n = Inf) %&gt;%\n  summarize(n_total = sum(n_total), n_failed = sum(n_failed), .groups = \"drop\") %&gt;%\n  mutate(percent_failed = 100 * n_failed / n_total)\n\n# A tibble: 6 × 5\n  data            n_clus          n_total n_failed percent_failed\n  &lt;chr&gt;           &lt;fct&gt;             &lt;int&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n1 aggregated data # clusters: 5       140       29           20.7\n2 aggregated data # clusters: 50      140        0            0  \n3 aggregated data # clusters: 250     120        0            0  \n4 raw data        # clusters: 5       140        0            0  \n5 raw data        # clusters: 50      140        0            0  \n6 raw data        # clusters: 250     120        0            0"
  },
  {
    "objectID": "posts/gee-on-aggregated-data/index.html#raw-vs-aggregated-data-estimates",
    "href": "posts/gee-on-aggregated-data/index.html#raw-vs-aggregated-data-estimates",
    "title": "GEE on aggregated data?",
    "section": "Raw vs aggregated data estimates",
    "text": "Raw vs aggregated data estimates\nThese rows with convergence failures can be removed and the agreement between the estimates from the raw vs the aggregate datasets can be assessed visually\n\nslope_plot_data &lt;- simulation_results %&gt;%\n  filter(term == \"Slope\", high_se == 0) %&gt;%\n  select(seed, term, data, estimate, n_clus, n, estimator) %&gt;%\n  tidyr::pivot_wider(id_cols = c(seed, term, n_clus, n, estimator),\n                     names_from = data, values_from = estimate) %&gt;%\n  mutate(`Total sample size` = factor(n), \n         id = interaction(estimator, n_clus, sep = \", \", lex.order = TRUE)) \n\nslope_plot_data %&gt;% \n  filter(estimator == \"GEE\") %&gt;% \n  ggplot(aes(x = `raw data`, y = `aggregated data`, color = `Total sample size`)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  # geom_point(data = tibble(x = 0.3, y = 0.3), \n  #            aes(x = x, y = y), \n  #            color = \"black\", size = 3, inherit.aes = FALSE) +\n  xlab(\"Slope coefficient from the full dataset\") +\n  ylab(\"Slope coefficient from the aggregated dataset\") +\n  theme(legend.position = \"bottom\") +\n  guides(color = guide_legend(nrow = 1)) + \n  facet_wrap(~ id, ncol = 3, scales = \"fixed\")\n\nWarning: Removed 29 rows containing missing values (geom_point).\n\n\n\n\n\nThis plot compares the estimated slope coefficient (true value 0.3) from the GEE model on aggregated data vs the estimated slope coefficient from the model on the raw data while varying the number of clusters as well as the total sample size. The agreement between estimates increases as the number of clusters increases (going from the top left panel to the top right panel).\nOn the other hand, the estimates from running GLMs on the same aggregated and raw datasets are identical, as indicated by the points lying precisely on the black line in the following plot\n\nslope_plot_data %&gt;% \n  filter(estimator == \"GLM\") %&gt;% \n  ggplot(aes(x = `raw data`, y = `aggregated data`, color = `Total sample size`)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  # geom_point(data = tibble(x = 0.3, y = 0.3), \n  #            aes(x = x, y = y), \n  #            color = \"black\", size = 3, inherit.aes = FALSE) +\n  xlab(\"Slope coefficient from the full dataset\") +\n  ylab(\"Slope coefficient from the aggregated dataset\") +\n  theme(legend.position = \"bottom\") +\n  guides(color = guide_legend(nrow = 1)) + \n  facet_wrap(~ id, ncol = 3, scales = \"fixed\")\n\n\n\n\nAs expected, the estimates for \\(n = 10,000\\) are tightly clustered around the true value compared to \\(n = 100\\) in both sets of plots.\nOk so the estimates aren’t identical for the GEE models unfortunately, but are they approximately similar across the raw and aggregated datasets? This is assessed visually via box plots below for the case of 5 clusters in the data\n\ndist_plot_data &lt;- simulation_results %&gt;% \n  mutate(\n    ci_lower = estimate - (qnorm(0.975) * std.error),\n    ci_upper = estimate + (qnorm(0.975) * std.error), \n    ci_width = ci_upper - ci_lower, \n    ci_upper_half_width = ci_upper - estimate\n  ) %&gt;% \n  filter(term == \"Slope\", high_se == 0, estimator == \"GEE\") %&gt;% \n  select(\n    Estimate = estimate, \n    `Std. Error` = std.error, \n    `95% CI LL` = ci_lower, \n    `95% CI UL` = ci_upper,\n    `95% CI Width` = ci_width,\n    `95% CI Upper HW` = ci_upper_half_width,\n    n, n_clus_raw, n_clus, data, seed) %&gt;% \n  tidyr::pivot_longer(cols = Estimate:`95% CI Upper HW`, \n                      names_to = \"statistic\", \n                      values_to = \"values\") %&gt;% \n  mutate(\n    statistic = factor(statistic,\n                       levels = c(\"Estimate\", \"Std. Error\", \n                                  \"95% CI LL\", \"95% CI UL\", \n                                  \"95% CI Width\", \"95% CI Upper HW\")), \n    n = factor(n, ordered = TRUE), \n    data = stringr::str_to_title(data)\n  )\n\nglimpse(dist_plot_data)\n\nRows: 4,626\nColumns: 7\n$ n          &lt;ord&gt; 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,…\n$ n_clus_raw &lt;dbl&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,…\n$ n_clus     &lt;fct&gt; # clusters: 5, # clusters: 5, # clusters: 5, # clusters: 5,…\n$ data       &lt;chr&gt; \"Raw Data\", \"Raw Data\", \"Raw Data\", \"Raw Data\", \"Raw Data\",…\n$ seed       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3,…\n$ statistic  &lt;fct&gt; Estimate, Std. Error, 95% CI LL, 95% CI UL, 95% CI Width, 9…\n$ values     &lt;dbl&gt; -0.0738, 0.1753, -0.4174, 0.2698, 0.6871, 0.3436, -0.1137, …\n\n\n\ndist_plot_data %&gt;% \n  filter(n_clus_raw == 5) %&gt;% \n  ggplot(aes(x = n, y = values, color = data)) + \n  #geom_point(position = position_dodge(width = 0.2)) +\n  geom_boxplot(position = position_dodge(width = 1)) +\n  xlab(\"Total sample size (n)\") + \n  ylab(\"\") +\n  theme(legend.position = \"bottom\", legend.title = element_blank()) +\n  facet_wrap(~ statistic, ncol = 2, scales = \"free\")\n\n\n\n\nSo based on these box plots, it seems like most of the sampling distributions for these statistics – point estimate, standard errors, CI width, etc. – are pretty comparable but not identical."
  },
  {
    "objectID": "posts/hello-world/index.html",
    "href": "posts/hello-world/index.html",
    "title": "Hello, World!",
    "section": "",
    "text": "This first post is to check whether the features I want for this blog work as desired.\nThese can be summarized in a non-exhaustive list as:"
  },
  {
    "objectID": "posts/hello-world/index.html#math",
    "href": "posts/hello-world/index.html#math",
    "title": "Hello, World!",
    "section": "Math",
    "text": "Math\nThe OLS estimator is given by the equation \\(\\hat\\beta_\\text{OLS} = (X^\\mathsf{T} X)^{-1} X^\\mathsf{T} y\\).\nOn the other hand, the ridge estimator is given by the following formula\n\\[\\hat\\beta_\\text{ridge} = (X^\\mathsf{T} X + \\lambda I)^{-1} X^\\mathsf{T} y\\]\nwhere \\(\\lambda \\in [0, \\infty)\\) controls the amount of shrinkage applied to the coefficients."
  },
  {
    "objectID": "posts/hello-world/index.html#r-code",
    "href": "posts/hello-world/index.html#r-code",
    "title": "Hello, World!",
    "section": "R code",
    "text": "R code\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\np &lt;- iris %&gt;% \n  ggplot(aes(x = Petal.Length, y = Petal.Width, color = Species)) + \n  geom_point() + \n  theme_classic()\n\nvanilla ggplot\n\nplot(p)\n\n\n\n\nplotly plot\n\nplotly::ggplotly(p)"
  },
  {
    "objectID": "posts/how-many-ratings-do-i-need/index.html",
    "href": "posts/how-many-ratings-do-i-need/index.html",
    "title": "How Many Five-Star Ratings Do I Need?",
    "section": "",
    "text": "In the Fall of 2021, a friend who runs her own business sent me this picture with the accompanying question:\n\nThe screenshot indicates an average1 rating of 4.5 stars out of a total of \\(n = 363\\) reviews, and additionally lists the percent of time a rating between 1-5 was given.1 Unweighted, I assume.\nIt seemed like an easy enough problem – perfect to explore on a rainy, gray Saturday in November – so I decided to have a crack at it.\nAfter doing some trivial algebra, somewhat successfully writing a for-loop, and adequately pleased with the solution, I posted the write-up for my initial approach on RPubs and sent off the answer2 to my friend.2 Spoiler: she needed between 47-50 5-star ratings to pull up the average rating to 4.6. Apologies if you were eagerly waiting for the end to find out what the answer was.\nHowever, while going through this document to clean it up for the blog (in 2022), I realized there’s a simpler way of solving this problem. Before I describe it further, I’m going to load some R packages and extract the data from the image into R objects.\n\nlibrary(purrr)\nlibrary(tidyr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nn &lt;- 363\n\n# percent ratings scaled to [0,1]\np &lt;- c(0.06, 0.01, 0.02, 0.12, 0.79) %&gt;%\n  set_names(nm = 1:5) %&gt;% \n  print()\n\n   1    2    3    4    5 \n0.06 0.01 0.02 0.12 0.79 \n\n\nWhat made me rethink my approach was that I previously ended up with the wrong ratings vector after converting the (rounded) percentages into counts3.3 Although I mostly worked around it afterwards via simulation.\nSo for example, 79% out of 363 ratings were 5-star ratings, which translates to 286.77 and rounded to the nearest integer becomes 287. But this isn’t the only integer that rounds to 79% when divided by 363. Any integer \\(k\\) when divided by 363 that ends up in the (open) interval (78.5%, 79.5%) would be a possible candidate.\n\nseq(284, 289, 1) %&gt;% \n  set_names(nm = ~ .x) %&gt;% \n  map_dbl(.f = ~ round(100 * .x / 363))\n\n284 285 286 287 288 289 \n 78  79  79  79  79  80 \n\n\nSo any one of 285-288 5-star ratings are compatible with the information in the screenshot. We can get the same range for the other ratings (i.e., 1-4).\n\nplausible_counts_per_rating &lt;- p %&gt;% map(.f = function(prop) {\n  approx_val &lt;- round(prop * n)\n  possible_vals &lt;- seq(from = approx_val - 10, to = approx_val + 10, by = 1) %&gt;% \n    set_names(nm = ~ .x) %&gt;% \n    map_dbl(.f = ~ round(.x / n, 2)) %&gt;% \n    keep(.p = ~ .x == prop) %&gt;% \n    names()\n}) %&gt;% \n  as_tibble(.name_repair = ~ paste('x', .x, sep = \"\"))\n\nplausible_counts_per_rating\n\n# A tibble: 4 × 5\n  x1    x2    x3    x4    x5   \n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 20    2     6     42    285  \n2 21    3     7     43    286  \n3 22    4     8     44    287  \n4 23    5     9     45    288  \n\n\nEach column shows the plausible values for the number of times a rating was provided. We can create all possible combinations of these values to identify the subset of \\(4 ^ 5 = 1024\\) possible combinations that are compatible with the information in the screenshot, i.e., a mean of 4.5 when rounded to 1 decimal place and a total of 363 ratings.\n\nrating_combinations &lt;- plausible_counts_per_rating %&gt;%\n  # create all combinations of all values in all columns\n  expand(crossing(x1, x2, x3, x4, x5)) %&gt;%\n  mutate(across(.fns = as.integer), \n         total_ratings = x1 + x2 + x3 + x4 + x5, \n         sum_ratings = x1 + (2 * x2) + (3 * x3) + (4 * x4) + (5 * x5), \n         mean_rating = round(sum_ratings / 363, 1)) %&gt;% \n  print(n = 10)\n\n# A tibble: 1,024 × 8\n      x1    x2    x3    x4    x5 total_ratings sum_ratings mean_rating\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;         &lt;int&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1    20     2     6    42   285           355        1635         4.5\n 2    20     2     6    42   286           356        1640         4.5\n 3    20     2     6    42   287           357        1645         4.5\n 4    20     2     6    42   288           358        1650         4.5\n 5    20     2     6    43   285           356        1639         4.5\n 6    20     2     6    43   286           357        1644         4.5\n 7    20     2     6    43   287           358        1649         4.5\n 8    20     2     6    43   288           359        1654         4.6\n 9    20     2     6    44   285           357        1643         4.5\n10    20     2     6    44   286           358        1648         4.5\n# … with 1,014 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\npossible_ratings &lt;- rating_combinations %&gt;% \n  filter(total_ratings == 363, mean_rating == 4.5) %&gt;% \n  print(n = Inf)\n\n# A tibble: 3 × 8\n     x1    x2    x3    x4    x5 total_ratings sum_ratings mean_rating\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;         &lt;int&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1    23     4     9    42   285           363        1651         4.5\n2    23     5     7    43   285           363        1651         4.5\n3    23     5     8    42   285           363        1650         4.5\n\n\nSo one of these three possible vectors is used to produce the statistics shown in the screenshot.\nThe formula for computing the (arithmetic) mean can be rearranged to easily calculate the required number of five-star ratings to bring the mean from 4.5 to 4.6.\nLet \\(n_1\\) denote the number of additional five-star ratings, \\(y\\) the (weighted) sum of the rating counts, and \\(n\\) the current number of ratings (i.e., 363) in the following equation:\n\\[\\frac{y + (n_1 \\times 5)}{n + n_1} = 4.6\\]\nThis can be rewritten as\n\\[5n_1 = 4.6 \\times (n + n_1) - y\\]\nand simplified to yield\n\\[n_1 = \\frac{(4.6 \\times n) - y}{0.4}\\]\nand coded up as an R function\n\nnum_five_star &lt;- function(sum_ratings, total_ratings) {\n  ((4.6 * total_ratings) - sum_ratings) / 0.4\n}\n\nApplying this function to the possible ratings vector leads to\n\npossible_ratings %&gt;% \n  mutate(extra_5_stars = ceiling(num_five_star(sum_ratings, total_ratings))) %&gt;% \n  select(-total_ratings, -mean_rating)\n\n# A tibble: 3 × 7\n     x1    x2    x3    x4    x5 sum_ratings extra_5_stars\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;       &lt;dbl&gt;         &lt;dbl&gt;\n1    23     4     9    42   285        1651            47\n2    23     5     7    43   285        1651            47\n3    23     5     8    42   285        1650            50\n\n\nso 47-50 additional 5-star ratings are needed to pull up the average4 to 4.6, assuming that the future ratings are all five-star ratings.4 exact average, not an average resulting from rounding 4.57 (say) to 4.6. In the latter case, fewer than 47 five-star ratings would be required."
  },
  {
    "objectID": "posts/jigger-volume-estimation/index.html",
    "href": "posts/jigger-volume-estimation/index.html",
    "title": "Determining the volume of my (cocktail) jigger",
    "section": "",
    "text": "In the fall of 2022, I was gifted a cocktail mixing set for my birthday1 which included a cocktail jigger. A jigger is an essential tool for mixing cocktails as it makes it relatively easy to measure the quantity of drinks that go into a cocktail (e.g., 40 ml of vodka, 10 ml of sugar syrup, etc.).1 It was put to use immediately and some delicious whiskey sours were made.\nAfter a couple of months of not having to use my cocktail set due to travelling, I couldn’t remember the volume of either side (i.e., basin) of the jigger, nor could I find the remains of the packaging material for reference. Googling showed that jiggers come in different sizes, so I decided to measure the volume myself."
  },
  {
    "objectID": "posts/jigger-volume-estimation/index.html#method-1-weight-based",
    "href": "posts/jigger-volume-estimation/index.html#method-1-weight-based",
    "title": "Determining the volume of my (cocktail) jigger",
    "section": "Method 1: Weight-based",
    "text": "Method 1: Weight-based\nThe digital kitchen scale I own has this nifty feature where it can account for and automatically subtract the weight of the container so that only the weight of the object of interest is shown.\nThe scale measures weight in grams (g), but I was interested in the volume in milliliters (ml). Quick Googling reminded me of the nifty fact I learned and forgot a long time ago, that the weight of 1 g of water is approximately equal to the volume occupied by 1 ml of water.\nPlacing the jigger on the scale and ensuring that the scale read zero g, I filled up the larger basin to the top with tap water. The scale showed 51g, which was odd as I was expecting it to show a number that would be a multiple of five (i.e., a number ending with a 0 or a 5)3.3 although some jigger images online show possible measurements like 22.5 ml (which is 0.75 oz)\nSo obviously4 the next logical step was to take multiple measurements. After making sure to drain the jigger, clean the scale of any spilled water droplets, and ensuring the scale read zero, I took the next measurement which read 48 g. Excellent. I love consistent results.4 obvious to a Statistician or a Data Scientist\nSo I took another 8 measurements, and repeated this process for the smaller basin of the jigger as well. These measurements are visualized below.\nEach time I filled it to what I perceived to be the top but I got different measurements. I don’t think that this variability is necessarily due to the variability of the digital scale itself but most likely due to the variability in my perception of what counts as ‘filled to the brim’.\n\n\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\n\nvol_big &lt;- c(51, 48, 48, 52, 49, 50, 51, 52, 50, 50)\nvol_small &lt;- c(31, 28, 32, 30, 30, 29, 32, 32, 31, 31)\n\ntibble(\n  Basin = c(rep(\"Smaller basin\", 10), rep(\"Larger basin\", 10)),\n  `Volume (in ml)` = c(vol_small, vol_big)\n) %&gt;%\n  mutate(Basin = forcats::fct_rev(Basin)) %&gt;% \n  ggplot(aes(x = `Volume (in ml)`, fill = Basin, color = Basin)) +\n  geom_dotplot(binwidth = 1, stroke = 2, dotsize = 0.7) +\n  theme_classic() +\n  theme(legend.position = \"none\", \n        axis.title.x = element_text(size = 16), \n        axis.text.x = element_text(size = 16), \n        strip.text = element_text(size = 16)) + \n  scale_y_continuous(NULL, breaks = NULL) + \n  scale_fill_manual(values = c(\"#E69F00\", \"darkgreen\")) + \n  scale_color_manual(values = c(\"#E69F00\", \"darkgreen\")) + \n  facet_wrap(~ Basin, scales = 'free')\n\n\n\n\n\nAveraging these measurements gave me a volume of 50.1 ml for the big basin and 30.6 ml for the smaller basin.\nInterestingly5, it also indicates6 that I usually put anywhere between 48-52 (or 28-32) ml of a drink when I’m supposed to add 50 (or 30) ml.5 to me and literally nobody else6 assuming the digital scale is not causing this variability"
  },
  {
    "objectID": "posts/jigger-volume-estimation/index.html#method-2-dimension-based",
    "href": "posts/jigger-volume-estimation/index.html#method-2-dimension-based",
    "title": "Determining the volume of my (cocktail) jigger",
    "section": "Method 2: Dimension-based",
    "text": "Method 2: Dimension-based\nThe shape of a jigger reminded me of a (partial) cone, so I measured7 the height \\(h\\) from the mouth of each basin to the point where it joins the other basin, and the diameter \\(2R\\) of the mouth of each basin.7 using a pair of digital calipers I totally had lying around the house and did not use this exercise as an excuse to buy\nFor the smaller basin, the height \\(h_s\\) was measured as 3.48 cm, and a diameter of 3.9 cm (so a radius \\(R_s\\) of 1.95 cm).\nFor the larger basin, the height \\(h_l\\) was measured as 5.28 cm, and a diameter of 4.18 cm (so a radius \\(R_l\\) of 2.09 cm).\nThe radius \\(r\\) of the base where the two basins are attached to each other is \\(2.78 / 2 = 1.39\\).\nPlugging these into the formula for a partial cone88 here’s a derivation (and another) of the volume of a cone using calculus, which I’ve probably derived in school or university and long since forgotten\n\\[V = \\frac{1}{3} \\times \\pi \\times h \\times \\Big(R^2 + Rr + r^2\\Big)\\]\n\n\nCode\ncone &lt;- function(h, r, R) {\n  (pi * h * (R^2 + (R * r) + r^2)) / 3\n}\n\n\ngave a volume9 of 30.8 ml for the smaller basin and 50.9 for the larger basin which was very similar to the numbers from the other method, but not exactly equal to 30 and 50 ml due to (human) measurement error.9 using the conversion factor of 1 cm3 to 1 ml for volume of water\nA few days after doing all these measurements, I came across a similar (in spirit?) post on a blog I frequent, which inspired me to write this up."
  },
  {
    "objectID": "posts/one-reason-why-a-glm-coefficient-is-NA/index.html",
    "href": "posts/one-reason-why-a-glm-coefficient-is-NA/index.html",
    "title": "One reason why a (g)lm coefficient is NA",
    "section": "",
    "text": "TL;DR: Use the alias function in R to check if you have nested factors (predictors) in your data\nRecently while fitting a logistic regression model, some of the coefficients estimated by the model were NA. Initially I thought it was due to separation1, as that’s the most common issue I usually face when fitting unregularized models on data.1 see this Wikipedia article, or this stats.stackexchange.com thread (and the associated links in the sidebar)\nHowever, googling2 threw up many threads on multicollinearity and anyway, separation usually leads to nonsensical estimates like \\(1.5 \\times 10^8\\) instead of NA.2 in this day and age of ChatGPT, I know\nAfter combing through many stackexchange threads, I discovered the alias function in R from this thread, which was pretty handy at identifying the problematic column(s).\nIt’s interesting that the alias documentation doesn’t mention anything about GLMs (glm()) but this does work on glm(..., family = \"binomial\") model objects3.3 possibly since the class of a glm object is c(\"glm\", \"lm\")\nThe rest of this post explores this issue and its resolution using aggregated test data, where the city variable is intentionally nested within the country variable.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nsimulated_data &lt;- tribble(\n  ~age, ~city, ~country, ~y, ~N,\n  \"&lt; 30\", \"Paris\", \"France\", 30, 100,\n  \"&lt; 30\", \"Nice\", \"France\", 20, 100,\n  \"&lt; 30\", \"Berlin\", \"Germany\", 23, 100,\n  \"30+\", \"Paris\", \"France\", 12, 100,\n  \"30+\", \"Nice\", \"France\", 11, 100,\n  \"30+\", \"Berlin\", \"Germany\", 27, 100\n) %&gt;% \n  mutate(y = y / N)\n\nmodel &lt;- glm(y ~ age + city + country, weights = N, data = simulated_data, family = \"binomial\")\n\nsummary(model)\n\n\nCall:\nglm(formula = y ~ age + city + country, family = \"binomial\", \n    data = simulated_data, weights = N)\n\nDeviance Residuals: \n      1        2        3        4        5        6  \n 1.1459   0.3555  -1.4512  -1.4069  -0.4309   1.5443  \n\nCoefficients: (1 not defined because of singularities)\n               Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     -0.8733     0.1876  -4.656 3.23e-06 ***\nage30+          -0.4794     0.2062  -2.325   0.0201 *  \ncityNice        -0.6027     0.2558  -2.356   0.0185 *  \ncityParis       -0.2286     0.2395  -0.954   0.3399    \ncountryGermany       NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 19.2591  on 5  degrees of freedom\nResidual deviance:  8.0953  on 2  degrees of freedom\nAIC: 43.492\n\nNumber of Fisher Scoring iterations: 4\n\n\nThe estimate for Germany is NA. Calling the alias function on this GLM model shows that the dummy variable of Germany is linearly dependent on (a subset of) the other columns.\n\nalias(model)\n\nModel :\ny ~ age + city + country\n\nComplete :\n               (Intercept) age30+ cityNice cityParis\ncountryGermany  1           0     -1       -1       \n\n\nThis means that the column for Germany is redundant in this design matrix (or the model matrix), as the values of Germany (the pattern of 0s and 1s) can be perfectly predicted / recreated by combining the Intercept, Nice, and Paris columns using the coefficients from the output of alias(). This is why the perfect multicollinearity in this case leads to an NA coefficient.\n\n# countryGermany and Germany are identical\nmodel.matrix(~ ., data = simulated_data) %&gt;% \n  as_tibble() %&gt;% \n  select(-y, -N, -`age30+`) %&gt;% \n  mutate(Germany = `(Intercept)` - cityNice - cityParis)\n\n# A tibble: 6 × 5\n  `(Intercept)` cityNice cityParis countryGermany Germany\n          &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;   &lt;dbl&gt;\n1             1        0         1              0       0\n2             1        1         0              0       0\n3             1        0         0              1       1\n4             1        0         1              0       0\n5             1        1         0              0       0\n6             1        0         0              1       1\n\n\nAnother interesting observation is that changing the order of the variables\n\n# here country comes before city\nglm(y ~ age + country + city, weights = N, data = simulated_data, family = \"binomial\") %&gt;% \n  alias()\n\nModel :\ny ~ age + country + city\n\nComplete :\n          (Intercept) age30+ countryGermany cityNice\ncityParis  1           0     -1             -1      \n\n\nleads to different estimates being NA, i.e., the estimate for Paris is now NA and is linearly dependent on the Intercept, country (Germany), and another city (Nice).\nThe simplest solution here is to drop one of the city or country columns, or to build two separate models – one without country, and one without city.\nIf the goal is to estimate coefficients for both the city and country variables, then a mixed model with nested effects might be the right rabbit hole to go down, assuming they both have more than 10 levels or so. See the following links:\n\nhttps://stats.stackexchange.com/questions/197977/analyzing-nested-categorical-data\nhttps://stats.stackexchange.com/questions/79360/mixed-effects-model-with-nesting\nhttps://stats.stackexchange.com/questions/372257/how-do-you-deal-with-nested-variables-in-a-regression-model\nSecond bullet point from the answer: https://stats.stackexchange.com/questions/243811/how-to-model-nested-fixed-factor-with-glmm\nhttps://stackoverflow.com/questions/70537291/lmer-model-failed-to-converge-with-1-negative-eigenvalue\nhttps://bbolker.github.io/mixedmodels-misc/glmmFAQ.html\nhttps://stackoverflow.com/questions/40723196/why-do-i-get-na-coefficients-and-how-does-lm-drop-reference-level-for-interact"
  },
  {
    "objectID": "posts/tweedie-with-identity-link-and-offset/index.html",
    "href": "posts/tweedie-with-identity-link-and-offset/index.html",
    "title": "Specifying an offset in a Tweedie model with identity link",
    "section": "",
    "text": "This post explores several things:\nIn this article, the words duration, offset, exposure, and weight are used interchangeably."
  },
  {
    "objectID": "posts/tweedie-with-identity-link-and-offset/index.html#introduction",
    "href": "posts/tweedie-with-identity-link-and-offset/index.html#introduction",
    "title": "Specifying an offset in a Tweedie model with identity link",
    "section": "Introduction",
    "text": "Introduction\nData coming from fields like ecology, insurance, epidemiology – such as number of new cases of a disease in multiple cities with very different population sizes, number of claims and total claim amounts from insurance policies with different durations, etc. – need to have the varying exposures accounted for as offsets while building models. These might look something like the following simulated dataset with an exposure variable (w) and a response variable (y):\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nn &lt;- 1e6\n\n# tweedie distribution parameters\np &lt;- 1.3 # variance power\nmu &lt;- 200 # mean\nphi &lt;- 350 # dispersion, so variance = phi * mu ^ p\n\nset.seed(45)\nsim_data &lt;- tibble(\n  w = runif(n, min = 0.5, max = 3),\n  y = tweedie::rtweedie(n = n, mu = mu, phi = phi / w, power = p)\n)\n\n# summary(sim_data)\n\nsim_data %&gt;% slice_head(n = 3)\n\n# A tibble: 3 × 2\n      w     y\n  &lt;dbl&gt; &lt;dbl&gt;\n1  2.08     0\n2  1.29     0\n3  1.10     0\n\n\nFor readability, let’s pretend that this response variable is the individual claim amounts for an insurance company with a client base of 1 million customers. Additionally, for each individual the duration of how long they’ve been insured is also recorded. So the first customer has been insured for about 2 years and 1 month, and has not filed a claim at all. The third customer has been insured for a little over a year and has also not filed any claims."
  },
  {
    "objectID": "posts/tweedie-with-identity-link-and-offset/index.html#ratio-of-means-or-mean-of-ratios",
    "href": "posts/tweedie-with-identity-link-and-offset/index.html#ratio-of-means-or-mean-of-ratios",
    "title": "Specifying an offset in a Tweedie model with identity link",
    "section": "Ratio of means or mean of ratios?",
    "text": "Ratio of means or mean of ratios?\nThe quantity of interest from such datasets may be the mean per unit exposure – expected claim amount per individual per year, expected number of new cases of a disease per year per 100,000 people, etc. There are two separate quantities that can be calculated as expected values – the ratio of the means of amount and duration variables, or the mean of the individual ratios. The differences between these two quantities is explained pretty well in this stackexchange thread.\nThe ratio estimator estimates the first quantity \\(R = \\sum_i{y_i} / \\sum_i{w_i}\\), while the weighted sample mean of the individual ratios estimates the second quantity \\(\\mathbb{E} = \\sum_i{w_i y_i} / \\sum_i{w_i}\\). In the latter case, the link between claim amount and duration at the individual level is preserved, whereas for the former, the numerator and denominators are totals at the population level.\nIf everyone had exactly the same weight \\(w_i\\) of 1 year, the denominator would sum to the sample size of 1 million for the data above, and both the estimates would be the same. If the weights were different, then the two results would differ.\nIn epidemiology, the ratio estimator is used for incidence rate calculations. On the other hand, the insurance papers on Tweedie models mentioned at the bottom of this post all seem to use the weighted mean approach.\nFor the simulated data above, the two estimates are quite different:\n\nsum(sim_data$y) / sum(sim_data$w)\n\n[1] 114.5185\n\n\n\nweighted.mean(sim_data$y, w = sim_data$w)\n\n[1] 200.4661\n\n\nIn this case, the second estimate matches the true mean value chosen for the simulation, which makes sense given that the data are simulated from a Tweedie model with varying exposures (\\(Y_i \\sim \\text{Tweedie}(\\mu_i, \\phi / w_i, p)\\)) but with the mean-variance relationship preserved under unit exposure. This is described in part A of the supplement to the Yang et al 2016 paper.\nHowever, both the numbers are right, as they answer different questions."
  },
  {
    "objectID": "posts/tweedie-with-identity-link-and-offset/index.html#building-a-regression-model",
    "href": "posts/tweedie-with-identity-link-and-offset/index.html#building-a-regression-model",
    "title": "Specifying an offset in a Tweedie model with identity link",
    "section": "Building a regression model",
    "text": "Building a regression model\nThis formula is easy enough to apply if there are no predictors, but a regression model is needed to estimate these quantities when there are predictors in the data.\nThere are two ways of specifying the model. The first method corresponds to passing the claim amounts unmodified, and passing the exposures as weights:\n\n# weighted mean estimator\nsummary(glm(y ~ 1, weights = w, data = sim_data,\n            family = statmod::tweedie(var.power = 1.3, link.power = 1)))\n\n\nCall:\nglm(formula = y ~ 1, family = statmod::tweedie(var.power = 1.3, \n    link.power = 1), data = sim_data, weights = w)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 200.4661     0.4431   452.4   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Tweedie family taken to be 349.4572)\n\n    Null deviance: 240499666  on 999999  degrees of freedom\nResidual deviance: 240499666  on 999999  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 3\n\n\nThe estimated intercept and dispersion correspond to the same parameters (\\(\\mu = 200\\), \\(\\phi = 350\\)) picked for the simulation. This estimate also coincides with the weighted mean estimate. link.power = 1 indicates that the identity link function is used, and var.power = 1.3 or \\(p\\) is assumed to be known here. Usually the profile likelihood approach is used to pick the best value on the interval \\(p \\in (1, 2)\\) for data with exact zeroes.\nOnce \\(p\\) is chosen, \\(\\mu\\) can be estimated independently of \\(\\phi\\), and finally dispersion \\(\\phi\\) can be estimated using an optimization algorithm, or one of the estimators described in section 6.8 of the Dunn and Smyth book. The glm function in R uses the Pearson estimator:\n\\[\n\\phi = \\frac{1}{N-p'} \\sum_{i=1}^{N} \\frac{w_i (y_i - \\hat\\mu_i) ^ 2}{\\hat\\mu_i^p}\n\\]\nwhere \\(p'\\) is the number of parameters in the model and \\(\\text{Var}(\\mu_i) = \\mu_i^p\\) is the variance function.\n\n# pearson estimate of dispersion\n(sum((sim_data$w * ((sim_data$y - 200.4661)^2)) / (200.4661^1.3))) / (n - 1)\n\n[1] 349.4573\n\n\nThe second method rescales the response variable with the weights, and passes exposures as weights to the model:\n\n# ratio estimator\nsummary(glm(y / w ~ 1, weights = w, data = sim_data,\n            family = statmod::tweedie(var.power = 1.3, link.power = 1)))\n\n\nCall:\nglm(formula = y/w ~ 1, family = statmod::tweedie(var.power = 1.3, \n    link.power = 1), data = sim_data, weights = w)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 114.5185     0.3655   313.3   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Tweedie family taken to be 492.3754)\n\n    Null deviance: 177557174  on 999999  degrees of freedom\nResidual deviance: 177557174  on 999999  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 3\n\n\nThis estimate corresponds to the same output as the ratio estimator from the previous section. The estimate of dispersion \\(\\phi\\) is different from the true value of 350, which makes sense as dispersion is a function of the estimated value of the mean \\(\\mu\\)."
  },
  {
    "objectID": "posts/tweedie-with-identity-link-and-offset/index.html#what-does-the-math-look-like-behind-these-two-models",
    "href": "posts/tweedie-with-identity-link-and-offset/index.html#what-does-the-math-look-like-behind-these-two-models",
    "title": "Specifying an offset in a Tweedie model with identity link",
    "section": "What does the math look like behind these two models?",
    "text": "What does the math look like behind these two models?\nTo fit a Tweedie model to the data with weights to calculate the two different values in the previous section, the following log-likelihood function – taken from the Yang et al paper – can be maximized.\n\\[\nl(\\mu, \\phi, p | \\{y, x, w\\}_{i=1}^n) = \\sum_{i = 1}^{n}{ \\frac{w_i}{\\phi}} \\Bigg(y_i \\frac{\\mu_i^{1-p}}{1-p} - \\frac{\\mu_i^{2-p}}{2-p} \\Bigg) + log\\ a(y_i, \\phi / w_i, p)\n\\]\nFor this simulated dataset, \\(w_i\\) and \\(y_i\\) vary for each individual, but there are no predictors so an identity link function can be used 1, the overall mean is of interest so the \\(\\mu_i\\) term can be collapsed into a single \\(\\mu\\) parameter to be optimized, and the log a(...) term can be ignored as it’s not a function of \\(\\mu\\). Since the regression equation for an intercept only term is \\(\\mu_i = \\beta_0\\), we can replace the \\(\\mu\\) with \\(\\beta_0\\).1 which should be avoided if the model will be used for out-of-sample prediction to avoid predicting values below 0\nThis makes it easy to compute the closed form solution, which is calculated by differentiating this function to produce the score function, and setting it to 0.\n\\[\n\\frac{\\partial l}{\\partial \\beta} = \\sum_{i = 1}^{n}{ \\frac{w_i}{\\phi}} (y_i \\beta_0^{-p} - \\beta_0^{1-p}) = 0\n\\]\n\\(\\phi\\) and \\(\\beta_0^{-p}\\) are non-zero constants, so can be pulled out of the summation to give\n\\[\n\\sum_{i = 1}^{n}{ w_i (y_i - \\beta_0) } = 0\n\\]\nFor glm(y ~ 1, weights = w, ...), this equals\n\\[\n\\sum_{i = 1}^{n} w_i y_i - \\beta_0 \\sum_{i = 1}^{n} w_i = 0 \\Rightarrow \\beta_0 = \\frac{\\sum_{i = 1}^{n} {w_i y_i}}{\\sum_{i = 1}^{n} w_i}\n\\]\nand for glm(y / w ~ 1, weights = w, ...), this equals\n\\[\n\\sum_{i = 1}^{n} w_i \\frac{y_i}{w_i} - \\beta_0 \\sum_{i = 1}^{n} w_i = 0 \\Rightarrow \\beta_0 = \\frac{\\sum_{i = 1}^{n} {y_i}}{\\sum_{i = 1}^{n} w_i}\n\\]"
  },
  {
    "objectID": "posts/tweedie-with-identity-link-and-offset/index.html#a-method-that-works-for-poisson-but-not-for-tweedie",
    "href": "posts/tweedie-with-identity-link-and-offset/index.html#a-method-that-works-for-poisson-but-not-for-tweedie",
    "title": "Specifying an offset in a Tweedie model with identity link",
    "section": "A method that works for Poisson but not for Tweedie",
    "text": "A method that works for Poisson but not for Tweedie\nWhat initially led me down this rabbit hole was finding this stackexchange post for specifying the offset with identity link in a poisson model, and naively (and incorrectly) fitting the Tweedie glm like this\n\nsummary(glm(y ~ w - 1, data = sim_data,\n            family = statmod::tweedie(var.power = 1.3, link.power = 1)))\n\n\nCall:\nglm(formula = y ~ w - 1, family = statmod::tweedie(var.power = 1.3, \n    link.power = 1), data = sim_data)\n\nCoefficients:\n  Estimate Std. Error t value Pr(&gt;|t|)    \nw 121.7328     0.4064   299.6   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Tweedie family taken to be 465.8885)\n\n    Null deviance:       NaN  on 1000000  degrees of freedom\nResidual deviance: 158130565  on  999999  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 3\n\n\nand trying to figure out why this didn’t coincide with the ratio estimate of 114.5185, which is the case for the poisson models\n\n# ratio estimator\nsum(sim_data$y) / sum(sim_data$w)\n\n[1] 114.5185\n\n# generates warnings because we're passing a non-discrete response\n# point estimates are the same though\nunname(coef(suppressWarnings(glm(y ~ w - 1, family = poisson(link = \"identity\"), data = sim_data))))\n\n[1] 114.5185\n\nunname(coef(suppressWarnings(glm(y / w ~ 1, weights = w, family = poisson(link = \"identity\"), data = sim_data))))\n\n[1] 114.5185\n\n\nThis happens because substituting \\(\\mu_i = w_i \\beta_0\\) instead of \\(\\mu_i = \\beta_0\\) in the log-likelihood function\n\\[\nl(\\beta_0, \\phi, p | \\{y, x, w\\}_{i=1}^n) = \\sum_{i = 1}^{n}{ \\frac{w_i}{\\phi}} \\Bigg(y_i \\frac{(w_i \\beta_0)^{1-p}}{1-p} - \\frac{(w_i\\beta_0)^{2-p}}{2-p} \\Bigg) + log\\ a(y_i, \\phi / w_i, p)\n\\]\nleads to the following score function\n\\[\n\\frac{\\partial l}{\\partial \\beta} = \\sum_{i = 1}^{n} \\frac{w_i}{\\phi} (y_i w_i^{1-p} \\beta_0^{-p} - w_i^{2-p} \\beta_0^{1-p}) = 0\n\\]\nThe constant \\(\\phi\\) and \\(\\beta_0^{-p}\\) terms can be dropped from the equation, and the \\(w_i\\) outside the bracket are all 1 because no weights are passed to the glm call, so the following equation is solved\n\\[\n\\sum_{i = 1}^{n} y_i w_i^{1-p} - w_i^{2-p} \\beta_0 = 0\n\\]\nwhich can be simplified by pulling \\(w_i^{1-p}\\) as a common term\n\\[\n\\sum_{i = 1}^{n} w_i^{1-p} (y_i  - w_i \\beta_0) = 0\n\\]\nThis shows where the logical error happens, as well as how the original estimate can be obtained, i.e., by passing weights = w ^ (p - 1) to the glm call, so that the \\(w_i^{1-p}\\) term cancels out\n\nsummary(glm(y ~ w - 1, weights = I(w^(1.3 - 1)), data = sim_data,\n            family = statmod::tweedie(var.power = 1.3, link.power = 1)))\n\n\nCall:\nglm(formula = y ~ w - 1, family = statmod::tweedie(var.power = 1.3, \n    link.power = 1), data = sim_data, weights = I(w^(1.3 - 1)))\n\nCoefficients:\n  Estimate Std. Error t value Pr(&gt;|t|)    \nw 114.5185     0.3655   313.3   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Tweedie family taken to be 492.3754)\n\n    Null deviance:       NaN  on 1000000  degrees of freedom\nResidual deviance: 177557174  on  999999  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 3\n\n\nNow the point estimates, standard errors, and dispersion parameters correspond to the model where the ratio estimator is correctly specified."
  },
  {
    "objectID": "posts/tweedie-with-identity-link-and-offset/index.html#references",
    "href": "posts/tweedie-with-identity-link-and-offset/index.html#references",
    "title": "Specifying an offset in a Tweedie model with identity link",
    "section": "References",
    "text": "References\n\nYang et al 2016 paper and supplement (link)\nDelong et al 2021 paper (link)\nChapter 12 on Tweedie models from the Dunn and Smyth book on GLMs\n\nOthers\n\nZhang 2013 (link)\nStan code for Tweedie\n\nhttps://discourse.mc-stan.org/t/tweedie-likelihood-compound-poisson-gamma-in-stan/14636\nhttps://gist.github.com/MatsuuraKentaro/952b3301686c10adcb13"
  }
]