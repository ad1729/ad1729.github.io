<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-01-05">

<title>Akshat Dwivedi - Sampling from the poor man’s posterior distribution of parameters from models fitted to claims data</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Akshat Dwivedi</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/ad1729"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/akshatd/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://500px.com/p/akshatdwivedi?view=photos"> <i class="bi bi-images" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Sampling from the poor man’s posterior distribution of parameters from models fitted to claims data</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
                                <div class="quarto-categories">
                <div class="quarto-category">Bayesian</div>
                <div class="quarto-category">Bootstrap</div>
                <div class="quarto-category">Insurance</div>
                <div class="quarto-category">R</div>
                <div class="quarto-category">Tweedie</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 5, 2025</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">January 6, 2025</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#the-simplest-model" id="toc-the-simplest-model" class="nav-link active" data-scroll-target="#the-simplest-model">The simplest “model”</a></li>
  <li><a href="#tweedie-models" id="toc-tweedie-models" class="nav-link" data-scroll-target="#tweedie-models">Tweedie models</a>
  <ul class="collapse">
  <li><a href="#intercept-only-regression" id="toc-intercept-only-regression" class="nav-link" data-scroll-target="#intercept-only-regression">Intercept-only regression</a></li>
  <li><a href="#parametric-bootstrap" id="toc-parametric-bootstrap" class="nav-link" data-scroll-target="#parametric-bootstrap">Parametric Bootstrap</a></li>
  <li><a href="#nonparametric-bootstrap" id="toc-nonparametric-bootstrap" class="nav-link" data-scroll-target="#nonparametric-bootstrap">Nonparametric Bootstrap</a></li>
  <li><a href="#using-properties-of-edms" id="toc-using-properties-of-edms" class="nav-link" data-scroll-target="#using-properties-of-edms">Using properties of EDMs</a></li>
  <li><a href="#glm-with-predictors" id="toc-glm-with-predictors" class="nav-link" data-scroll-target="#glm-with-predictors">GLM with predictors</a></li>
  </ul></li>
  <li><a href="#all-the-distributions-together" id="toc-all-the-distributions-together" class="nav-link" data-scroll-target="#all-the-distributions-together">All the distributions together</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a>
  <ul class="collapse">
  <li><a href="#auto-claims-data" id="toc-auto-claims-data" class="nav-link" data-scroll-target="#auto-claims-data">Auto Claims Data</a></li>
  <li><a href="#bootstrapping" id="toc-bootstrapping" class="nav-link" data-scroll-target="#bootstrapping">Bootstrapping</a></li>
  <li><a href="#tweedie-models-1" id="toc-tweedie-models-1" class="nav-link" data-scroll-target="#tweedie-models-1">Tweedie Models</a></li>
  <li><a href="#books" id="toc-books" class="nav-link" data-scroll-target="#books">Books</a></li>
  </ul></li>
  <li><a href="#appendix-claims-data" id="toc-appendix-claims-data" class="nav-link" data-scroll-target="#appendix-claims-data">Appendix: Claims Data</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/ad1729/ad1729.github.io/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<p>This post is about fitting a handful of different models to a subset of a popular car-insurance claims data available online. Plausible future data values can be simulated from the fitted models and used for downstream tasks. Simulated values from the fitted models can also be compared with the actual observed data as a sanity check.</p>
<p>I’ve never worked in the field of insurance, but I’ve been wanting to dive into Tweedie models for a while, since non-negative (response) variables with lots of zeroes and positive skew are pretty common and show up in many diverse disciplines such across the social sciences, insurance, biology, etc.</p>
<p>What piqued my interest in insurance data is that the response variable can additionally have very large “outliers”. In other fields, outliers resulting from corrupted data or measurement errors can be discarded from the analysis, or robust estimators / loss functions can be used for modelling. However, in such settings, it may not necessarily make sense to discard such values because they likely represent the true cost of damages from accidents<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> — which an insurer may be on the hook for.</p>
<div class="no-row-height column-margin column-container"><p><sup>1</sup>&nbsp;“Well actually, …” - some actuary probably</p></div><p>This is also a bit of an unusual post in the sense that I’m using ideas I’ve encountered in Bayesian statistics but with frequentist methods. Sure, I could just fit Bayesian models, but that’s not the point here. To wrap my head around the ideas utilized in this post, I’m keeping things relatively simple by eschewing more complex predictive models like (my favourite) boosted trees, and using a single model for the data instead of <em>hurdle</em> models that split the response variable into a zero and a non-zero part and model them separately.</p>
<p>Before going further, I’m going to load some packages and the claims data used for this post.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.5.1     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.1
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="co"># functions from these packages are used via namespace::fun() </span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="co"># library(tweedie)</span></span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="co"># library(magrittr, include.only = "%$%") # importing the exposition pipe</span></span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="co"># library(glue)</span></span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="co"># library(scales)</span></span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="co"># library(broom)</span></span>
<span id="cb3-7"><a href="#cb3-7"></a><span class="co"># library(boot)</span></span>
<span id="cb3-8"><a href="#cb3-8"></a><span class="co"># library(ggExtra)</span></span>
<span id="cb3-9"><a href="#cb3-9"></a><span class="co"># library(statmod)</span></span>
<span id="cb3-10"><a href="#cb3-10"></a></span>
<span id="cb3-11"><a href="#cb3-11"></a><span class="fu">theme_set</span>(<span class="fu">theme_bw</span>())</span>
<span id="cb3-12"><a href="#cb3-12"></a></span>
<span id="cb3-13"><a href="#cb3-13"></a>claims <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"claims_subset.csv"</span>, <span class="at">show_col_types =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb3-14"><a href="#cb3-14"></a>  <span class="fu">glimpse</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 60,000
Columns: 13
$ IDpol       &lt;dbl&gt; 1, 3, 5, 10, 11, 13, 15, 17, 18, 21, 25, 27, 30, 32, 35, 3…
$ ClaimNb     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
$ Exposure    &lt;dbl&gt; 0.10, 0.77, 0.75, 0.09, 0.84, 0.52, 0.45, 0.27, 0.71, 0.15…
$ Area        &lt;chr&gt; "D", "D", "B", "B", "B", "E", "E", "C", "C", "B", "B", "C"…
$ VehPower    &lt;dbl&gt; 5, 5, 6, 7, 7, 6, 6, 7, 7, 7, 7, 7, 4, 4, 4, 9, 6, 6, 6, 6…
$ VehAge      &lt;dbl&gt; 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 1, 0, 9, 0, 2, 2, 2, 2…
$ DrivAge     &lt;dbl&gt; 55, 55, 52, 46, 46, 38, 38, 33, 33, 41, 41, 56, 27, 27, 23…
$ BonusMalus  &lt;dbl&gt; 50, 50, 50, 50, 50, 50, 50, 68, 68, 50, 50, 50, 90, 90, 10…
$ VehBrand    &lt;chr&gt; "B12", "B12", "B12", "B12", "B12", "B12", "B12", "B12", "B…
$ VehGas      &lt;chr&gt; "Regular", "Regular", "Diesel", "Diesel", "Diesel", "Regul…
$ Density     &lt;dbl&gt; 1217, 1217, 54, 76, 76, 3003, 3003, 137, 137, 60, 60, 173,…
$ Region      &lt;chr&gt; "R82", "R82", "R22", "R72", "R72", "R31", "R31", "R91", "R…
$ ClaimAmount &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…</code></pre>
</div>
</div>
<p>The most important variables are <code>IDpol</code> — which uniquely identifies individual policies (denoted with a subscript <span class="math inline">\(i\)</span>), <code>Exposure</code> — which indicates the duration (in years) that the policy is in effect (denoted by <span class="math inline">\(w_i\)</span>), and <code>ClaimAmount</code> — which is the total monetary amount of the claims filed by each policyholder (denoted by <span class="math inline">\(z_i\)</span>). Some of the other variables will be later used for building richer models.</p>
<p>Looking at the deciles of the exposure distribution for these 60,000 policies</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a>claims <span class="sc">%&gt;%</span> </span>
<span id="cb5-2"><a href="#cb5-2"></a>  <span class="fu">pull</span>(Exposure) <span class="sc">%&gt;%</span> </span>
<span id="cb5-3"><a href="#cb5-3"></a>  <span class="fu">quantile</span>(., <span class="at">probs =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb5-4"><a href="#cb5-4"></a>  <span class="fu">as_tibble</span>(<span class="at">rownames =</span> <span class="st">"percentile"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb5-5"><a href="#cb5-5"></a>  <span class="fu">print</span>(<span class="at">n =</span> <span class="cn">Inf</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 11 × 2
   percentile   value
   &lt;chr&gt;        &lt;dbl&gt;
 1 0%         0.00273
 2 10%        0.07   
 3 20%        0.16   
 4 30%        0.27   
 5 40%        0.42   
 6 50%        0.57   
 7 60%        0.76   
 8 70%        1      
 9 80%        1      
10 90%        1      
11 100%       1      </code></pre>
</div>
</div>
<p>many of the values are less than one, which means those policies were in effect for less than a year. All of these are non-zero as they should be, but more than 60% have a duration of less than one year. The smallest exposure is for a day, since <span class="math inline">\(1/365 \approx 0.02739\)</span>.</p>
<p>Assuming a closed cohort — i.e., all these contracts get renewed the following year and no new contracts are issued — the goal is to predict the total claim amount for each policy for the following year. The distribution of individual claim amounts is highly skewed and has <em>a lot</em> of zeroes (<span class="math inline">\(\approx 94\%\)</span>), as assessed by some quantiles</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a>claims <span class="sc">%&gt;%</span> </span>
<span id="cb7-2"><a href="#cb7-2"></a>  <span class="fu">pull</span>(ClaimAmount) <span class="sc">%&gt;%</span> </span>
<span id="cb7-3"><a href="#cb7-3"></a>  <span class="fu">quantile</span>(., <span class="at">probs =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>, <span class="fl">0.94</span>, <span class="fl">0.95</span>, <span class="fl">0.99</span>, <span class="fl">0.999</span>, <span class="fl">1.0</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb7-4"><a href="#cb7-4"></a>  <span class="fu">round</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     0%     50%     94%     95%     99%   99.9%    100% 
      0       0       0      54    1636   10839 1404186 </code></pre>
</div>
</div>
<section id="the-simplest-model" class="level2">
<h2 class="anchored" data-anchor-id="the-simplest-model">The simplest “model”</h2>
<p>Since I’ve worked in epidemiology these past few years, a natural quantity (i.e., estimand) similar to incidence rates (i.e., the number of events generated from some population divided by the total follow-up time for individuals with different follow-up durations or periods) seems to be a good starting step. This can be expressed as the sum of the individual claim amounts <span class="math inline">\(z_i\)</span> divided by the sum of policy durations <span class="math inline">\(w_i\)</span>, and denoted by the expectation operator <span class="math inline">\(\mathbb{E}\)</span>.</p>
<p><span class="math display">\[
\mathbb{E}\big[\text{Claim Amount}_i\big] = \frac{\sum_i z_i}{\sum_i w_i}
\]</span>It’s a way of equally dividing the total claims generated from some population at risk among the individuals in that population. Each of the individual claim amounts is a random variable, so is expected to vary from person to person, as well as from year to year for the same person.</p>
<p>Taking the regular (arithmetic) mean — which is the same as setting <span class="math inline">\(w_i = 1\)</span> for each individual in the formula above — underestimates the expected claim cost as many individuals are observed for less than a year. It is expected that had they been observed for the full year, their claim amounts would have been larger. A similar argument applies in the case of individuals with <span class="math inline">\(w_i &gt; 1\)</span>, although in this case we’d be overestimating instead of underestimating.</p>
<p>For the data above, this comes out to about 125 per person per year assuming <span class="math inline">\(w_i = 1\)</span>, and to about 218 per person per year using the observed <span class="math inline">\(w_i\)</span>’s.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a>claims <span class="sc">%&gt;%</span> </span>
<span id="cb9-2"><a href="#cb9-2"></a>  <span class="fu">summarise</span>(</span>
<span id="cb9-3"><a href="#cb9-3"></a>    <span class="at">total_amount =</span> <span class="fu">sum</span>(ClaimAmount), </span>
<span id="cb9-4"><a href="#cb9-4"></a>    <span class="at">max_claim_amount =</span> <span class="fu">max</span>(ClaimAmount),</span>
<span id="cb9-5"><a href="#cb9-5"></a>    <span class="at">n_policies =</span> <span class="fu">n</span>(), </span>
<span id="cb9-6"><a href="#cb9-6"></a>    <span class="at">person_time =</span> <span class="fu">sum</span>(Exposure), </span>
<span id="cb9-7"><a href="#cb9-7"></a>    <span class="at">mean_person_time =</span> <span class="fu">mean</span>(Exposure)</span>
<span id="cb9-8"><a href="#cb9-8"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb9-9"><a href="#cb9-9"></a>  <span class="fu">mutate</span>(</span>
<span id="cb9-10"><a href="#cb9-10"></a>    <span class="at">mean =</span> total_amount <span class="sc">/</span> n_policies, </span>
<span id="cb9-11"><a href="#cb9-11"></a>    <span class="at">avg_claim_cost =</span> total_amount <span class="sc">/</span> person_time,</span>
<span id="cb9-12"><a href="#cb9-12"></a>    <span class="fu">across</span>(<span class="at">.cols =</span> <span class="fu">everything</span>(), </span>
<span id="cb9-13"><a href="#cb9-13"></a>           <span class="at">.fns =</span> <span class="sc">~</span> <span class="fu">as.character</span>(<span class="fu">round</span>(.x, <span class="dv">4</span>)))</span>
<span id="cb9-14"><a href="#cb9-14"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb9-15"><a href="#cb9-15"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">everything</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 7 × 2
  name             value     
  &lt;chr&gt;            &lt;chr&gt;     
1 total_amount     7507466.02
2 max_claim_amount 1404185.52
3 n_policies       60000     
4 person_time      34471.8546
5 mean_person_time 0.5745    
6 mean             125.1244  
7 avg_claim_cost   217.7854  </code></pre>
</div>
</div>
<p>So now we have an estimate for the expected claim amount per person per year, even though we can expect most policies to generate zero claims, and a few policies to generate some very large claim amounts based on the observed claims distribution. This expected claim cost estimate will be used again, so it’s assigned to a variable here.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a>expected_claim_amount <span class="ot">&lt;-</span> <span class="fu">sum</span>(claims<span class="sc">$</span>ClaimAmount) <span class="sc">/</span> <span class="fu">sum</span>(claims<span class="sc">$</span>Exposure)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For an insurance company, they need to ensure they have enough capital reserves to be able to pay out money for these claims, which they’re legally liable for. For the current year, the total claim amount across the policies was about 7.5 million, from a population that was on averaged exposed for 0.57 years. The total expected claim amount for this population with each person being observed for a full year is <span class="math inline">\(217.8 \times 60,000\)</span> which comes out to about 13 million.</p>
<p>In this case, the sample of customers constitutes the population of interest so it may not make sense to produce uncertainty estimates for this estimated total amount for the current year. However, the claim amounts can be seen as the result of a stochastic process, so superpopulation inference on this parameter can still make sense since next year’s claim amounts may be expected to be similar, but not identical.</p>
<p>This is carried out here using a <a href="https://www.sumsar.net/blog/2015/04/the-non-parametric-bootstrap-as-a-bayesian-model/">weird Bayesian model</a> (a.k.a. the nonparametric bootstrap). The following code chunk generates <span class="math inline">\(B = 10,000\)</span> resamples and calculates the expected claim amount on each resample.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a>expected_claim_cost_fun <span class="ot">&lt;-</span> <span class="cf">function</span>(data, indx, ...) {</span>
<span id="cb12-2"><a href="#cb12-2"></a>  data <span class="ot">&lt;-</span> data[indx, ]</span>
<span id="cb12-3"><a href="#cb12-3"></a></span>
<span id="cb12-4"><a href="#cb12-4"></a>  expected_value <span class="ot">&lt;-</span> <span class="fu">sum</span>(data<span class="sc">$</span>ClaimAmount) <span class="sc">/</span> <span class="fu">sum</span>(data<span class="sc">$</span>Exposure)</span>
<span id="cb12-5"><a href="#cb12-5"></a></span>
<span id="cb12-6"><a href="#cb12-6"></a>  <span class="co"># this is the single / largest outlier in the data</span></span>
<span id="cb12-7"><a href="#cb12-7"></a>  outlier_counts <span class="ot">&lt;-</span> <span class="fu">nrow</span>(data[data<span class="sc">$</span>ClaimAmount <span class="sc">==</span> <span class="fl">1404185.52</span>, ])</span>
<span id="cb12-8"><a href="#cb12-8"></a></span>
<span id="cb12-9"><a href="#cb12-9"></a>  <span class="fu">return</span>(<span class="fu">c</span>(expected_value, outlier_counts))</span>
<span id="cb12-10"><a href="#cb12-10"></a>}</span>
<span id="cb12-11"><a href="#cb12-11"></a></span>
<span id="cb12-12"><a href="#cb12-12"></a>boot_fun <span class="ot">&lt;-</span> <span class="cf">function</span>(data, <span class="at">R =</span> <span class="dv">100</span>, <span class="at">parallel =</span> <span class="st">"snow"</span>) {</span>
<span id="cb12-13"><a href="#cb12-13"></a>  <span class="fu">stopifnot</span>(parallel <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"no"</span>, <span class="st">"snow"</span>))</span>
<span id="cb12-14"><a href="#cb12-14"></a></span>
<span id="cb12-15"><a href="#cb12-15"></a>  <span class="co"># TRUE if using parallelization, otherwise FALSE</span></span>
<span id="cb12-16"><a href="#cb12-16"></a>  simple <span class="ot">&lt;-</span> parallel <span class="sc">==</span> <span class="st">"snow"</span></span>
<span id="cb12-17"><a href="#cb12-17"></a></span>
<span id="cb12-18"><a href="#cb12-18"></a>  boot<span class="sc">::</span><span class="fu">boot</span>(</span>
<span id="cb12-19"><a href="#cb12-19"></a>    <span class="at">data =</span> data,</span>
<span id="cb12-20"><a href="#cb12-20"></a>    <span class="at">statistic =</span> expected_claim_cost_fun,</span>
<span id="cb12-21"><a href="#cb12-21"></a>    <span class="at">R =</span> R,</span>
<span id="cb12-22"><a href="#cb12-22"></a>    <span class="at">sim =</span> <span class="st">"ordinary"</span>,</span>
<span id="cb12-23"><a href="#cb12-23"></a>    <span class="at">stype =</span> <span class="st">"i"</span>,</span>
<span id="cb12-24"><a href="#cb12-24"></a>    <span class="at">simple =</span> simple,</span>
<span id="cb12-25"><a href="#cb12-25"></a>    <span class="at">parallel =</span> parallel,</span>
<span id="cb12-26"><a href="#cb12-26"></a>    <span class="at">ncpus =</span> <span class="dv">18</span></span>
<span id="cb12-27"><a href="#cb12-27"></a>  )</span>
<span id="cb12-28"><a href="#cb12-28"></a>}</span>
<span id="cb12-29"><a href="#cb12-29"></a></span>
<span id="cb12-30"><a href="#cb12-30"></a><span class="co"># uncomment to run</span></span>
<span id="cb12-31"><a href="#cb12-31"></a><span class="co"># boot_fit &lt;- boot_fun(data = claims, R = 10000)</span></span>
<span id="cb12-32"><a href="#cb12-32"></a></span>
<span id="cb12-33"><a href="#cb12-33"></a><span class="co"># uncomment to save the results </span></span>
<span id="cb12-34"><a href="#cb12-34"></a><span class="co"># saveRDS(boot_fit, file = "bootstrap_expected_claim_cost.rds")</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>This can take a while to run (even in parallel), so saved results are read back in and used to produce the following plot of the sampling distribution of the expected claim amount.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a>boot_fit <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"bootstrap_expected_claim_cost.rds"</span>)</span>
<span id="cb13-2"><a href="#cb13-2"></a></span>
<span id="cb13-3"><a href="#cb13-3"></a><span class="co"># convert the results into a data frame</span></span>
<span id="cb13-4"><a href="#cb13-4"></a>boot_dist <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb13-5"><a href="#cb13-5"></a>  <span class="at">expected_claim_cost =</span> boot_fit<span class="sc">$</span>t[, <span class="dv">1</span>],</span>
<span id="cb13-6"><a href="#cb13-6"></a>  <span class="at">outlier_counts =</span> boot_fit<span class="sc">$</span>t[, <span class="dv">2</span>],</span>
<span id="cb13-7"><a href="#cb13-7"></a>  <span class="co"># used for coloring / facetting plots</span></span>
<span id="cb13-8"><a href="#cb13-8"></a>  <span class="co">#`Outlier counts` = paste0(boot_fit$t[, 2], " replicates")</span></span>
<span id="cb13-9"><a href="#cb13-9"></a>  <span class="st">`</span><span class="at">Outlier counts</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">factor</span>(boot_fit<span class="sc">$</span>t[, <span class="dv">2</span>])</span>
<span id="cb13-10"><a href="#cb13-10"></a>)</span>
<span id="cb13-11"><a href="#cb13-11"></a></span>
<span id="cb13-12"><a href="#cb13-12"></a>boot_dist <span class="sc">%&gt;%</span></span>
<span id="cb13-13"><a href="#cb13-13"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> expected_claim_cost)) <span class="sc">+</span></span>
<span id="cb13-14"><a href="#cb13-14"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">100</span>) <span class="sc">+</span></span>
<span id="cb13-15"><a href="#cb13-15"></a>  <span class="fu">geom_vline</span>(</span>
<span id="cb13-16"><a href="#cb13-16"></a>    <span class="at">xintercept =</span> expected_claim_amount, </span>
<span id="cb13-17"><a href="#cb13-17"></a>    <span class="at">color =</span> <span class="st">"orange"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span></span>
<span id="cb13-18"><a href="#cb13-18"></a>  ) <span class="sc">+</span></span>
<span id="cb13-19"><a href="#cb13-19"></a>  <span class="fu">xlab</span>(</span>
<span id="cb13-20"><a href="#cb13-20"></a>    glue<span class="sc">::</span><span class="fu">glue</span>(<span class="st">"Bootstrap distribution of expected "</span>, </span>
<span id="cb13-21"><a href="#cb13-21"></a>               <span class="st">"exposure-adjusted claim amount "</span>, </span>
<span id="cb13-22"><a href="#cb13-22"></a>               <span class="st">"per person per year"</span>, </span>
<span id="cb13-23"><a href="#cb13-23"></a>               <span class="st">"</span><span class="sc">\n</span><span class="st">(Estimate from the full sample in orange)"</span>)</span>
<span id="cb13-24"><a href="#cb13-24"></a>  ) <span class="sc">+</span></span>
<span id="cb13-25"><a href="#cb13-25"></a>  <span class="fu">ylab</span>(<span class="st">"Count"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>That’s an unusual looking bootstrap distribution. Googling led me to <a href="https://stats.stackexchange.com/questions/63999/how-to-interpret-multimodal-distribution-of-bootstrapped-correlation">this stackexchange thread</a> which indicates similar behaviour arising due to outlier(s) and small sample sizes. Policies with the largest top-6 claim amounts are</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1"></a>claims <span class="sc">%&gt;%</span> </span>
<span id="cb14-2"><a href="#cb14-2"></a>  <span class="fu">select</span>(ClaimAmount) <span class="sc">%&gt;%</span> </span>
<span id="cb14-3"><a href="#cb14-3"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(ClaimAmount)) <span class="sc">%&gt;%</span> </span>
<span id="cb14-4"><a href="#cb14-4"></a>  <span class="fu">slice_head</span>(<span class="at">n =</span> <span class="dv">6</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb14-5"><a href="#cb14-5"></a>  <span class="fu">pull</span>(ClaimAmount)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1404185.52  183073.66  152666.39  116318.90  115232.88   96422.32</code></pre>
</div>
</div>
<p>of which the largest at 1.4 million is roughly 8 times larger than the next largest value. It is interesting that despite having a large sample size of 60,000 (or 34,500 policy-years), this outlier is large enough relative to the sample size to cause the multimodality seen here.</p>
<p>The function used to calculate the expected claim amount on each bootstrap sample can be modified to also count the number of times the maximum value from the original sample shows up in each bootstrap sample. The bootstrap distribution is plotted again but this time colored by the number of times the maximum amount shows up in a replicate.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a>boot_dist <span class="sc">%&gt;%</span></span>
<span id="cb16-2"><a href="#cb16-2"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> expected_claim_cost,</span>
<span id="cb16-3"><a href="#cb16-3"></a>             <span class="at">fill =</span> <span class="st">`</span><span class="at">Outlier counts</span><span class="st">`</span>)) <span class="sc">+</span></span>
<span id="cb16-4"><a href="#cb16-4"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">100</span>) <span class="sc">+</span></span>
<span id="cb16-5"><a href="#cb16-5"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> expected_claim_amount, <span class="at">color =</span> <span class="st">"gray40"</span>,</span>
<span id="cb16-6"><a href="#cb16-6"></a>             <span class="at">linewidth =</span> <span class="fl">1.2</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb16-7"><a href="#cb16-7"></a>  <span class="fu">xlab</span>(</span>
<span id="cb16-8"><a href="#cb16-8"></a>    glue<span class="sc">::</span><span class="fu">glue</span>(<span class="st">"Bootstrap distribution of expected "</span>, </span>
<span id="cb16-9"><a href="#cb16-9"></a>               <span class="st">"exposure-adjusted claim amount "</span>, </span>
<span id="cb16-10"><a href="#cb16-10"></a>               <span class="st">"per person per year"</span>, </span>
<span id="cb16-11"><a href="#cb16-11"></a>               <span class="st">"</span><span class="sc">\n</span><span class="st">(Estimate from the full sample in gray)"</span>)</span>
<span id="cb16-12"><a href="#cb16-12"></a>  ) <span class="sc">+</span></span>
<span id="cb16-13"><a href="#cb16-13"></a>  <span class="fu">ylab</span>(<span class="st">"Count"</span>) <span class="sc">+</span> </span>
<span id="cb16-14"><a href="#cb16-14"></a>  <span class="fu">theme</span>(</span>
<span id="cb16-15"><a href="#cb16-15"></a>    <span class="at">legend.position =</span> <span class="st">"inside"</span>,</span>
<span id="cb16-16"><a href="#cb16-16"></a>    <span class="co">#legend.background = element_blank(),</span></span>
<span id="cb16-17"><a href="#cb16-17"></a>    <span class="at">legend.position.inside =</span> <span class="fu">c</span>(<span class="fl">0.88</span>, <span class="fl">0.65</span>)</span>
<span id="cb16-18"><a href="#cb16-18"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>So this makes sense. Resamples with more repeats of the maximum claim amount have higher expected claim cost amounts.</p>
<p>Since the total claim amount for the following year is of interest, the bootstrap distribution can be multiplied by the number of policy holders to get a distribution of plausible values for the total claim amount for this population — which is expected to be around 13 million, but could be anywhere between 8 million to 28 million.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1"></a>nonparametric_bootstrap_totals <span class="ot">&lt;-</span> boot_dist <span class="sc">%&gt;%</span></span>
<span id="cb17-2"><a href="#cb17-2"></a>  <span class="fu">mutate</span>(</span>
<span id="cb17-3"><a href="#cb17-3"></a>    <span class="at">total_claim_amount =</span> <span class="dv">60000</span> <span class="sc">*</span> expected_claim_cost,</span>
<span id="cb17-4"><a href="#cb17-4"></a>    <span class="at">total_claim_amount_in_millions =</span> total_claim_amount <span class="sc">/</span> <span class="fl">1e6</span>,</span>
<span id="cb17-5"><a href="#cb17-5"></a>    <span class="at">method =</span> <span class="st">"Nonparametric Bootstrap (Weighted mean)"</span></span>
<span id="cb17-6"><a href="#cb17-6"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb17-7"><a href="#cb17-7"></a>  <span class="fu">select</span>(method, total_claim_amount_in_millions)</span>
<span id="cb17-8"><a href="#cb17-8"></a></span>
<span id="cb17-9"><a href="#cb17-9"></a>nonparametric_bootstrap_totals <span class="sc">%&gt;%</span></span>
<span id="cb17-10"><a href="#cb17-10"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> total_claim_amount_in_millions)) <span class="sc">+</span></span>
<span id="cb17-11"><a href="#cb17-11"></a>  <span class="fu">stat_ecdf</span>(<span class="at">pad =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb17-12"><a href="#cb17-12"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> (<span class="fl">6e4</span> <span class="sc">*</span> expected_claim_amount) <span class="sc">/</span> <span class="fl">1e6</span>,</span>
<span id="cb17-13"><a href="#cb17-13"></a>             <span class="at">color =</span> <span class="st">"orange"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb17-14"><a href="#cb17-14"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">8</span>, <span class="dv">30</span>, <span class="dv">2</span>)) <span class="sc">+</span></span>
<span id="cb17-15"><a href="#cb17-15"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span><span class="fu">label_percent</span>()) <span class="sc">+</span></span>
<span id="cb17-16"><a href="#cb17-16"></a>  <span class="fu">xlab</span>(</span>
<span id="cb17-17"><a href="#cb17-17"></a>    glue<span class="sc">::</span><span class="fu">glue</span>(<span class="st">"Plausible values for the "</span>, </span>
<span id="cb17-18"><a href="#cb17-18"></a>                <span class="st">"following year's</span><span class="sc">\n</span><span class="st">total claim "</span>, </span>
<span id="cb17-19"><a href="#cb17-19"></a>                <span class="st">"amount assuming unit exposure (in millions)"</span>, </span>
<span id="cb17-20"><a href="#cb17-20"></a>               <span class="st">"</span><span class="sc">\n</span><span class="st">(Estimate from the full sample in orange)"</span>)</span>
<span id="cb17-21"><a href="#cb17-21"></a>  ) <span class="sc">+</span></span>
<span id="cb17-22"><a href="#cb17-22"></a>  <span class="fu">ylab</span>(</span>
<span id="cb17-23"><a href="#cb17-23"></a>    glue<span class="sc">::</span><span class="fu">glue</span>(<span class="st">"Empirical distribution function of the</span><span class="sc">\n</span><span class="st">"</span>, </span>
<span id="cb17-24"><a href="#cb17-24"></a>               <span class="st">"bootstrap distribution of total claim amounts"</span>)</span>
<span id="cb17-25"><a href="#cb17-25"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The empirical (cumulative) distribution function (EDF or eCDF) for the bootstrap distribution of the total claim amount from the population under unit exposure is shown above. The strong multimodality shows up as bumps in the eCDF but these seem pretty minor.</p>
<p>This approach ignores all the predictors in the data, and assumes that everyone has the same risk and spreads out that risk across every individual equally. However, it’s expected that the risk may differ across factors such as driver’s age, car model characteristics, region, etc. For this, we need more advanced approaches in the form of regression models.</p>
</section>
<section id="tweedie-models" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="tweedie-models">Tweedie models</h2>
<p>A common probability model used to model claims data — the <a href="https://en.wikipedia.org/wiki/Tweedie_distribution">Tweedie distribution</a> — is characterized by the power-law mean-variance relationship <span class="math inline">\(\text{Var}[Y_i] \propto \mathbb{E}[Y_i] ^ p\)</span> where the variance <span class="math inline">\(\text{Var}[Y_i]\)</span> is proportional to the mean <span class="math inline">\(\mathbb{E}[Y_i]\)</span>. The Tweedie distribution with <span class="math inline">\(p \in (1, 2)\)</span> — also known as the compound Poisson(-gamma) distribution — is commonly used to model the total cost of claims from an insurance policy. In the insurance world, it can be derived at the policy level as a model of Poisson claim frequency with the sum of claim amounts (i.e., claim severity) coming from a gamma distribution.</p>
<p>The Tweedie distribution has three parameters — mean (<span class="math inline">\(\mu &gt; 0\)</span>), dispersion (<span class="math inline">\(\sigma &gt; 0\)</span>) which functions as the constant of proportionality, and variance function power <span class="math inline">\(p \in (-\infty, 0] \cup [1, \infty)\)</span>. Restricting to <span class="math inline">\(p \in (1, 2)\)</span> make sense here since we have policies with zero claim amounts in the data and <span class="math inline">\(p \notin(1, 2)\)</span> is not suitable for modelling data with exact zeroes. The extreme of <span class="math inline">\(p = 1\)</span> corresponds to a Poisson distribution (which has support on non-negative integers), and <span class="math inline">\(p = 2\)</span> corresponds to a gamma distribution (which has support on positive real numbers). Special cases are also the Gaussian distribution (<span class="math inline">\(p = 0\)</span>), and the inverse-Gaussian distribution (<span class="math inline">\(p = 3\)</span>).</p>
<p>Section 4 of <a href="https://arxiv.org/abs/1508.06378">this paper</a> has the clearest distinction I’ve seen between three related random variables for the <span class="math inline">\(i^{th}\)</span> policy — <span class="math inline">\(Z_i\)</span> is the observed total claim amount with exposure <span class="math inline">\(w_i\)</span> (we have <span class="math inline">\(z_i\)</span>’s in our data), <span class="math inline">\(Y_i = Z_i / w_i \sim \text{Tweedie}(\mu_i, \phi / w_i, p)\)</span> is a derived quantity known as the <em>pure premium</em> under exposure <span class="math inline">\(w_i\)</span>, and <span class="math inline">\(Y^*_i \sim \text{Tweedie}(\mu_i, \phi, p)\)</span> is the pure premium under unit exposure (so <span class="math inline">\(w_i = 1\)</span>) which satisfies the mean-variance relationship <span class="math inline">\(\text{Var}[Y_i^*] = \phi \mathbb{E}[Y_i^*]^p\)</span>. I’m treating <span class="math inline">\(\phi\)</span> as a constant here, but it can be modelled as a function of covariates, as is done in <a href="https://link.springer.com/article/10.1007/s13385-021-00264-3">this paper</a> for example.</p>
<p>What tripped me up while writing a <a href="../../posts/tweedie-with-identity-link-and-offset/index.html">previous post</a><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> on this topic was that I kept trying to take the weighted mean of the <span class="math inline">\(z_i\)</span> values instead of the <span class="math inline">\(y_i\)</span> values and getting different results compared with the ratio <span class="math inline">\(\sum_i z_i / \sum_i w_i\)</span> when they should’ve been identical. Taking the weighted mean of the <span class="math inline">\(y_i\)</span> values leads to the same estimate as the ratio of these sums because the <span class="math inline">\(w_i\)</span>’s cancel out in the numerator.</p>
<div class="no-row-height column-margin column-container"><p><sup>2</sup>&nbsp;To be fair, I’d read the Yang et al.&nbsp;paper for that post too, but had overlooked that (subtle?) distinction.</p></div><section id="intercept-only-regression" class="level3">
<h3 class="anchored" data-anchor-id="intercept-only-regression">Intercept-only regression</h3>
<p>There are two ways of accounting for the varying exposures in a model. The first method uses pure premium <span class="math inline">\(y_i\)</span> as the response variable and the exposure <span class="math inline">\(w_i\)</span>’s are passed as weights to the fitting functions. The second method uses the observed amount <span class="math inline">\(z_i\)</span> with <span class="math inline">\(w_i\)</span> as an offset (i.e., a variable in the model with a fixed coefficient of 1). For the Tweedie model with <span class="math inline">\(p \in (1, 2)\)</span>, these two methods result in different parameter estimates (compared to the Poisson regression case where they give the same estimates). I’m sticking with the first approach here since more modelling packages across languages support model weights compared with offsets.</p>
<p>The following code fits an intercept-only Tweedie <em>generalized linear model</em> (GLM) with pure premium as the response variable and exposure as weights, and uses an identity link (<code>link.power = 1</code>). For this simple model, the link function shouldn’t really matter for the parameter estimate for the mean <span class="math inline">\(\mu\)</span>. The variance power is taken to be <span class="math inline">\(p = 1.6\)</span> throughout. This is very close to the chosen value for <span class="math inline">\(p\)</span> from calling <code>tweedie::tweedie.profile()</code> using the model offset formulation described in the previous paragraph. I couldn’t get this function to work for the pure premium model with weights because the log-likelihood estimates were (negative) infinite for all <span class="math inline">\(p\)</span>, and <span class="math inline">\(p = 1.8\)</span> was the value that minimized the Tweedie deviance (including on simulated data with known <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\phi\)</span>, and <span class="math inline">\(p = 1.6\)</span>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1"></a>tweedie_intercept_only <span class="ot">&lt;-</span> <span class="fu">glm</span>(</span>
<span id="cb18-2"><a href="#cb18-2"></a>  <span class="fu">I</span>(ClaimAmount <span class="sc">/</span> Exposure) <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb18-3"><a href="#cb18-3"></a>  <span class="at">weights =</span> Exposure,</span>
<span id="cb18-4"><a href="#cb18-4"></a>  <span class="at">data =</span> claims,</span>
<span id="cb18-5"><a href="#cb18-5"></a>  <span class="co"># using link.power = 1 implies identity link for the mean parameter mu</span></span>
<span id="cb18-6"><a href="#cb18-6"></a>  <span class="at">family =</span> statmod<span class="sc">::</span><span class="fu">tweedie</span>(<span class="at">var.power =</span> <span class="fl">1.6</span>, <span class="at">link.power =</span> <span class="dv">1</span>)</span>
<span id="cb18-7"><a href="#cb18-7"></a>)</span>
<span id="cb18-8"><a href="#cb18-8"></a></span>
<span id="cb18-9"><a href="#cb18-9"></a><span class="fu">summary</span>(tweedie_intercept_only)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = I(ClaimAmount/Exposure) ~ 1, family = statmod::tweedie(var.power = 1.6, 
    link.power = 1), data = claims, weights = Exposure)

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)    217.8       64.4   3.382 0.000721 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for Tweedie family taken to be 25966.84)

    Null deviance: 2144044  on 59999  degrees of freedom
Residual deviance: 2144044  on 59999  degrees of freedom
AIC: NA

Number of Fisher Scoring iterations: 3</code></pre>
</div>
</div>
<p>So our best guess for the distribution of <span class="math inline">\(Y_i^*\)</span>’s from the Tweedie class of models is <span class="math inline">\(\text{Tweedie}(\mu = 217.78..., \phi = 25966.83..., p = 1.6...)\)</span> (where the ellipses indicate truncation). These estimates for <span class="math inline">\(\hat\mu_{\text{int}}\)</span> and <span class="math inline">\(\hat\phi_{\text{int}}\)</span> will be used again, so they’re stored as variables.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">coef</span>(tweedie_intercept_only)</span>
<span id="cb20-2"><a href="#cb20-2"></a>phi <span class="ot">&lt;-</span> tweedie_intercept_only <span class="sc">%&gt;%</span> </span>
<span id="cb20-3"><a href="#cb20-3"></a>  <span class="fu">summary</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb20-4"><a href="#cb20-4"></a>  <span class="fu">pluck</span>(<span class="st">"dispersion"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="parametric-bootstrap" class="level3">
<h3 class="anchored" data-anchor-id="parametric-bootstrap">Parametric Bootstrap</h3>
<p>One way of getting a distribution for the statistic of interest <span class="math inline">\(T\)</span> is the use of the parametric bootstrap. This involves drawing <span class="math inline">\(B\)</span> samples each of size <span class="math inline">\(n\)</span> from the fitted model, computing the statistic for each of the <span class="math inline">\(B\)</span> samples, and using this as an estimate of the sampling distribution from which summary statistics (e.g.&nbsp;mean, quantiles, sd, etc.) can be computed.</p>
<p>The observed statistics — such as the number of claims with amounts &gt; 0, the total claim amounts, and the largest claim amount — from the one sample of <span class="math inline">\(z_i\)</span>’s that we have can be compared with the sampling distribution from the parametric bootstrap using the observed exposures <span class="math inline">\(w_i\)</span>.</p>
<p>The following code carries this out with <span class="math inline">\(B = 10,000\)</span> where for each <span class="math inline">\(b\)</span> we draw a vector of <span class="math inline">\(n\)</span> claim amounts <span class="math inline">\(Z_{i, b}\)</span> and the statistic <span class="math inline">\(\hat{T_b}\)</span> is computed. <span class="math inline">\(Z_{i, b}\)</span> is drawn as <span class="math inline">\(Z_{i, b} \sim w_i \times \text{Tweedie}(\hat\mu_{\text{int}}, \hat\phi_{\text{int}} / w_i, 1.6)\)</span>.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1"></a><span class="co"># how well does the model fit the data?</span></span>
<span id="cb21-2"><a href="#cb21-2"></a><span class="co"># a form of posterior predictive checking</span></span>
<span id="cb21-3"><a href="#cb21-3"></a><span class="co"># ppc_obs_exposure &lt;- map(</span></span>
<span id="cb21-4"><a href="#cb21-4"></a><span class="co">#   .x = 1:10000,</span></span>
<span id="cb21-5"><a href="#cb21-5"></a><span class="co">#   .f = ~ {</span></span>
<span id="cb21-6"><a href="#cb21-6"></a><span class="co">#     if(.x %% 100 == 0) {</span></span>
<span id="cb21-7"><a href="#cb21-7"></a><span class="co">#       print(.x)</span></span>
<span id="cb21-8"><a href="#cb21-8"></a><span class="co">#     }</span></span>
<span id="cb21-9"><a href="#cb21-9"></a><span class="co">#     set.seed(.x)</span></span>
<span id="cb21-10"><a href="#cb21-10"></a><span class="co">#     draw &lt;- claims$Exposure * tweedie::rtweedie(60000, mu = mu,</span></span>
<span id="cb21-11"><a href="#cb21-11"></a><span class="co">#                                                 phi = phi / claims$Exposure,</span></span>
<span id="cb21-12"><a href="#cb21-12"></a><span class="co">#                                                 power = 1.6)</span></span>
<span id="cb21-13"><a href="#cb21-13"></a><span class="co">#     tibble(prop_zero = mean(draw == 0), sample_total = sum(draw),</span></span>
<span id="cb21-14"><a href="#cb21-14"></a><span class="co">#            sample_max = max(draw), n_nonzero = sum(draw &gt; 0))</span></span>
<span id="cb21-15"><a href="#cb21-15"></a><span class="co">#   }) %&gt;%</span></span>
<span id="cb21-16"><a href="#cb21-16"></a><span class="co">#   list_rbind()</span></span>
<span id="cb21-17"><a href="#cb21-17"></a><span class="co">#</span></span>
<span id="cb21-18"><a href="#cb21-18"></a><span class="co"># saveRDS(ppc_obs_exposure, file = "ppc_obs_exposure.rds")</span></span>
<span id="cb21-19"><a href="#cb21-19"></a></span>
<span id="cb21-20"><a href="#cb21-20"></a><span class="co"># code takes a while to run, so we can read in the saved results</span></span>
<span id="cb21-21"><a href="#cb21-21"></a>ppc_obs_exposure <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="at">file =</span> <span class="st">"ppc_obs_exposure.rds"</span>)</span>
<span id="cb21-22"><a href="#cb21-22"></a></span>
<span id="cb21-23"><a href="#cb21-23"></a><span class="co"># summary statistics on the observed data</span></span>
<span id="cb21-24"><a href="#cb21-24"></a>sample_statistics_obs_exposure <span class="ot">&lt;-</span> claims <span class="sc">%&gt;%</span></span>
<span id="cb21-25"><a href="#cb21-25"></a>  <span class="fu">summarise</span>(</span>
<span id="cb21-26"><a href="#cb21-26"></a>    <span class="at">prop_zero =</span> <span class="fu">mean</span>(ClaimAmount <span class="sc">==</span> <span class="dv">0</span>),</span>
<span id="cb21-27"><a href="#cb21-27"></a>    <span class="at">sample_total =</span> <span class="fu">sum</span>(ClaimAmount),</span>
<span id="cb21-28"><a href="#cb21-28"></a>    <span class="at">sample_max =</span> <span class="fu">max</span>(ClaimAmount),</span>
<span id="cb21-29"><a href="#cb21-29"></a>    <span class="at">n_nonzero =</span> <span class="fu">sum</span>(ClaimAmount <span class="sc">&gt;</span> <span class="dv">0</span>)</span>
<span id="cb21-30"><a href="#cb21-30"></a>  )</span>
<span id="cb21-31"><a href="#cb21-31"></a></span>
<span id="cb21-32"><a href="#cb21-32"></a><span class="co"># combine the ppc data and the original sample data</span></span>
<span id="cb21-33"><a href="#cb21-33"></a>plot_data_obs_exposure <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(</span>
<span id="cb21-34"><a href="#cb21-34"></a>  ppc_obs_exposure <span class="sc">%&gt;%</span> </span>
<span id="cb21-35"><a href="#cb21-35"></a>    <span class="fu">mutate</span>(<span class="at">group =</span> <span class="st">"sampled"</span>, <span class="at">.before =</span> <span class="dv">0</span>),</span>
<span id="cb21-36"><a href="#cb21-36"></a>  sample_statistics_obs_exposure <span class="sc">%&gt;%</span> </span>
<span id="cb21-37"><a href="#cb21-37"></a>    <span class="fu">mutate</span>(<span class="at">group =</span> <span class="st">"observed"</span>, <span class="at">.before =</span> <span class="dv">0</span>)</span>
<span id="cb21-38"><a href="#cb21-38"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb21-39"><a href="#cb21-39"></a>  <span class="fu">mutate</span>(</span>
<span id="cb21-40"><a href="#cb21-40"></a>    <span class="fu">across</span>(<span class="fu">c</span>(sample_total, sample_max), <span class="sc">~</span> .x <span class="sc">/</span> <span class="fl">1e6</span>),</span>
<span id="cb21-41"><a href="#cb21-41"></a>    <span class="at">prop_zero =</span> <span class="dv">100</span> <span class="sc">*</span> prop_zero</span>
<span id="cb21-42"><a href="#cb21-42"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb21-43"><a href="#cb21-43"></a>  <span class="fu">rename</span>(</span>
<span id="cb21-44"><a href="#cb21-44"></a>    <span class="st">`</span><span class="at">% of policies with zero claims</span><span class="st">`</span> <span class="ot">=</span> prop_zero,</span>
<span id="cb21-45"><a href="#cb21-45"></a>    <span class="st">`</span><span class="at">Number of policies with non zero claim amounts</span><span class="st">`</span> <span class="ot">=</span> n_nonzero,</span>
<span id="cb21-46"><a href="#cb21-46"></a>    <span class="st">`</span><span class="at">Maximum claim amount (in millions)</span><span class="st">`</span> <span class="ot">=</span> sample_max,</span>
<span id="cb21-47"><a href="#cb21-47"></a>    <span class="st">`</span><span class="at">Total claim amount (in millions)</span><span class="st">`</span> <span class="ot">=</span> sample_total</span>
<span id="cb21-48"><a href="#cb21-48"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb21-49"><a href="#cb21-49"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="sc">-</span>group, <span class="at">names_to =</span> <span class="st">"statistic"</span>, <span class="at">values_to =</span> <span class="st">"values"</span>)</span>
<span id="cb21-50"><a href="#cb21-50"></a></span>
<span id="cb21-51"><a href="#cb21-51"></a><span class="co"># mean of the posterior predictive distribution values</span></span>
<span id="cb21-52"><a href="#cb21-52"></a>ppc_mean_obs_exposure <span class="ot">&lt;-</span> plot_data_obs_exposure <span class="sc">%&gt;%</span></span>
<span id="cb21-53"><a href="#cb21-53"></a>  <span class="fu">filter</span>(group <span class="sc">==</span> <span class="st">"sampled"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb21-54"><a href="#cb21-54"></a>  <span class="fu">summarise</span>(<span class="at">values =</span> <span class="fu">mean</span>(values), <span class="at">.by =</span> statistic) <span class="sc">%&gt;%</span></span>
<span id="cb21-55"><a href="#cb21-55"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="at">.cols =</span> <span class="fu">where</span>(is.numeric), </span>
<span id="cb21-56"><a href="#cb21-56"></a>                <span class="at">.fns =</span> <span class="sc">~</span> <span class="fu">round</span>(.x, <span class="dv">2</span>)))</span>
<span id="cb21-57"><a href="#cb21-57"></a></span>
<span id="cb21-58"><a href="#cb21-58"></a><span class="co"># compare these visually</span></span>
<span id="cb21-59"><a href="#cb21-59"></a>plot_data_obs_exposure <span class="sc">%&gt;%</span></span>
<span id="cb21-60"><a href="#cb21-60"></a>  <span class="fu">filter</span>(group <span class="sc">==</span> <span class="st">"sampled"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb21-61"><a href="#cb21-61"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> values, <span class="at">group =</span> statistic)) <span class="sc">+</span></span>
<span id="cb21-62"><a href="#cb21-62"></a>  <span class="fu">stat_ecdf</span>(<span class="at">pad =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb21-63"><a href="#cb21-63"></a>  <span class="co"># plot the sample statistic</span></span>
<span id="cb21-64"><a href="#cb21-64"></a>  <span class="fu">geom_vline</span>(<span class="at">data =</span> <span class="fu">filter</span>(plot_data_obs_exposure,</span>
<span id="cb21-65"><a href="#cb21-65"></a>                           group <span class="sc">==</span> <span class="st">"observed"</span>),</span>
<span id="cb21-66"><a href="#cb21-66"></a>             <span class="fu">aes</span>(<span class="at">xintercept =</span> values, <span class="at">group =</span> statistic),</span>
<span id="cb21-67"><a href="#cb21-67"></a>             <span class="at">color =</span> <span class="st">"orange"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb21-68"><a href="#cb21-68"></a>  <span class="co"># plot the distribution means</span></span>
<span id="cb21-69"><a href="#cb21-69"></a>  <span class="fu">geom_vline</span>(<span class="at">data =</span> ppc_mean_obs_exposure,</span>
<span id="cb21-70"><a href="#cb21-70"></a>             <span class="fu">aes</span>(<span class="at">xintercept =</span> values, <span class="at">group =</span> statistic),</span>
<span id="cb21-71"><a href="#cb21-71"></a>             <span class="at">color =</span> <span class="st">"red4"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb21-72"><a href="#cb21-72"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> statistic, <span class="at">scales =</span> <span class="st">"free"</span>) <span class="sc">+</span></span>
<span id="cb21-73"><a href="#cb21-73"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span><span class="fu">label_percent</span>()) <span class="sc">+</span></span>
<span id="cb21-74"><a href="#cb21-74"></a>  <span class="fu">xlab</span>(glue<span class="sc">::</span><span class="fu">glue</span>(<span class="st">"Statistics from the observed data (in orange);"</span>,</span>
<span id="cb21-75"><a href="#cb21-75"></a>                  <span class="st">"</span><span class="sc">\n</span><span class="st">mean of means from the simulated datasets (in red)"</span>)) <span class="sc">+</span></span>
<span id="cb21-76"><a href="#cb21-76"></a>  <span class="fu">ylab</span>(<span class="st">"Empirical distribution function"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>What’s really interesting about this plot is that the proportion (and number) of policies with zero claim amounts is really far from the observed proportion (number) of 95% (3000) vs the mean of the sampling distribution (99% and 29). On the other hand, the observed and average total claim amounts are virtually indistinguishable, and the average maximum claim amount isn’t too far off from the observed maximum claim amount.</p>
<p>Given that the statistic of interest has been the total claim amount across the policies, this doesn’t seem to be a bad approach, even though the EDFs of the sampled <span class="math inline">\(Z_{i, b} &gt; 0\)</span>’s from the model (10 datasets shown in gray) look pretty far off from the observed distribution of <span class="math inline">\(Z_{i, \text{obs}} &gt; 0\)</span>’s (observed claim amounts in black)</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1"></a><span class="co"># plot eCDFs of sampled datasets with the observed data</span></span>
<span id="cb22-2"><a href="#cb22-2"></a><span class="fu">map</span>(</span>
<span id="cb22-3"><a href="#cb22-3"></a>  <span class="at">.x =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,</span>
<span id="cb22-4"><a href="#cb22-4"></a>  <span class="at">.f =</span> <span class="sc">~</span> {</span>
<span id="cb22-5"><a href="#cb22-5"></a>    <span class="fu">set.seed</span>(.x)</span>
<span id="cb22-6"><a href="#cb22-6"></a>    draw <span class="ot">&lt;-</span> claims<span class="sc">$</span>Exposure <span class="sc">*</span> tweedie<span class="sc">::</span><span class="fu">rtweedie</span>(<span class="dv">60000</span>, <span class="at">mu =</span> mu,</span>
<span id="cb22-7"><a href="#cb22-7"></a>                                                <span class="at">phi =</span> phi <span class="sc">/</span> claims<span class="sc">$</span>Exposure,</span>
<span id="cb22-8"><a href="#cb22-8"></a>                                                <span class="at">power =</span> <span class="fl">1.6</span>)</span>
<span id="cb22-9"><a href="#cb22-9"></a>    <span class="fu">tibble</span>(<span class="at">sim_id =</span> .x, <span class="at">y =</span> draw, <span class="at">grp =</span> <span class="st">"Simulated"</span>)</span>
<span id="cb22-10"><a href="#cb22-10"></a>  }) <span class="sc">%&gt;%</span></span>
<span id="cb22-11"><a href="#cb22-11"></a>  <span class="fu">list_rbind</span>() <span class="sc">%&gt;%</span></span>
<span id="cb22-12"><a href="#cb22-12"></a>  <span class="fu">bind_rows</span>(</span>
<span id="cb22-13"><a href="#cb22-13"></a>    .,</span>
<span id="cb22-14"><a href="#cb22-14"></a>    claims <span class="sc">%&gt;%</span></span>
<span id="cb22-15"><a href="#cb22-15"></a>      <span class="fu">mutate</span>(<span class="at">sim_id =</span> <span class="dv">100</span>, <span class="at">grp =</span> <span class="st">"Observed"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb22-16"><a href="#cb22-16"></a>      <span class="fu">select</span>(sim_id, <span class="at">y =</span> ClaimAmount, grp)</span>
<span id="cb22-17"><a href="#cb22-17"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb22-18"><a href="#cb22-18"></a>  <span class="fu">filter</span>(y <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb22-19"><a href="#cb22-19"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> y, <span class="at">group =</span> sim_id, <span class="at">color =</span> grp)) <span class="sc">+</span></span>
<span id="cb22-20"><a href="#cb22-20"></a>  <span class="fu">stat_ecdf</span>() <span class="sc">+</span></span>
<span id="cb22-21"><a href="#cb22-21"></a>  <span class="fu">xlab</span>(<span class="st">"Policies with non-zero claim amounts (log10 scale)"</span>) <span class="sc">+</span></span>
<span id="cb22-22"><a href="#cb22-22"></a>  <span class="fu">ylab</span>(<span class="st">"Empirical distribution function"</span>) <span class="sc">+</span></span>
<span id="cb22-23"><a href="#cb22-23"></a>  <span class="fu">scale_x_log10</span>(</span>
<span id="cb22-24"><a href="#cb22-24"></a>    <span class="at">breaks =</span> scales<span class="sc">::</span><span class="fu">trans_breaks</span>(<span class="st">"log10"</span>, <span class="cf">function</span>(x) <span class="dv">10</span><span class="sc">^</span>x),</span>
<span id="cb22-25"><a href="#cb22-25"></a>    <span class="at">labels =</span> scales<span class="sc">::</span><span class="fu">trans_format</span>(<span class="st">"log10"</span>, scales<span class="sc">::</span><span class="fu">math_format</span>(<span class="dv">10</span><span class="sc">^</span>.x))</span>
<span id="cb22-26"><a href="#cb22-26"></a>  ) <span class="sc">+</span></span>
<span id="cb22-27"><a href="#cb22-27"></a>  <span class="fu">annotation_logticks</span>(<span class="at">sides =</span> <span class="st">"b"</span>) <span class="sc">+</span></span>
<span id="cb22-28"><a href="#cb22-28"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span>percent) <span class="sc">+</span></span>
<span id="cb22-29"><a href="#cb22-29"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb22-30"><a href="#cb22-30"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Simulated"</span> <span class="ot">=</span> <span class="st">"gray70"</span>, <span class="st">"Observed"</span> <span class="ot">=</span> <span class="st">"Black"</span>)</span>
<span id="cb22-31"><a href="#cb22-31"></a>  ) <span class="sc">+</span></span>
<span id="cb22-32"><a href="#cb22-32"></a>  <span class="fu">theme</span>(</span>
<span id="cb22-33"><a href="#cb22-33"></a>    <span class="at">legend.title =</span> <span class="fu">element_blank</span>(), </span>
<span id="cb22-34"><a href="#cb22-34"></a>    <span class="at">legend.position =</span> <span class="st">"inside"</span>,</span>
<span id="cb22-35"><a href="#cb22-35"></a>    <span class="at">legend.position.inside =</span> <span class="fu">c</span>(<span class="fl">0.9</span>, <span class="fl">0.2</span>)</span>
<span id="cb22-36"><a href="#cb22-36"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Simulated claim amounts are orders of magnitude larger than the observed claim amounts, which is how the totals are very similar despite the very different sample sizes of policies with non-zero claim amounts. The very low number of non-zero claim amounts in the simulated datasets is what leads to the jaggedness of the distribution functions.</p>
<p>If the goal is to have accurate estimates for the proportion of non-zero claims, then a hurdle model mentioned earlier would be a better approach. The observed distribution has a pretty big jump at 1128.12 which shows up 1169 times in the data, so a mixture model might be more appropriate if want to have a model with approximately the same eCDF.</p>
<p>This approach of comparing the statistics on samples drawn from the model vs the statistics from the observed sample is the concept of <a href="https://mc-stan.org/docs/stan-users-guide/posterior-predictive-checks.html"><em>posterior predictive checking</em></a> (PPC). If the model adequately describes the data generating process, the distribution of all the statistics from sampled datasets should be approximately centered at the observed statistics.</p>
<p>For next year’s claim amount, we can repeat the same step with a slight modification — sample <span class="math inline">\(Y_{i, b}^* \sim \text{Tweedie}(\hat\mu_{\text{int}}, \hat\phi_{\text{int}}, p = 1.6)\)</span> and calculate <span class="math inline">\(\hat{T_b} = \sum_i Y_{i, b}^*\)</span> which ranges from about 4 to 27.5 million.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1"></a><span class="co"># predicted_totals_for_unit_exposure &lt;- map_dbl(.x = 1:10000, .f = ~ {</span></span>
<span id="cb23-2"><a href="#cb23-2"></a><span class="co">#   if(.x %% 100 == 0) {</span></span>
<span id="cb23-3"><a href="#cb23-3"></a><span class="co">#     print(.x)</span></span>
<span id="cb23-4"><a href="#cb23-4"></a><span class="co">#   }</span></span>
<span id="cb23-5"><a href="#cb23-5"></a><span class="co">#   set.seed(.x)</span></span>
<span id="cb23-6"><a href="#cb23-6"></a><span class="co">#   sum(tweedie::rtweedie(60000, mu = mu, phi = phi, power = 1.6))</span></span>
<span id="cb23-7"><a href="#cb23-7"></a><span class="co"># })</span></span>
<span id="cb23-8"><a href="#cb23-8"></a><span class="co">#</span></span>
<span id="cb23-9"><a href="#cb23-9"></a><span class="co"># saveRDS(predicted_totals_for_unit_exposure,</span></span>
<span id="cb23-10"><a href="#cb23-10"></a><span class="co">#         file = "predicted_totals_for_unit_exposure.rds")</span></span>
<span id="cb23-11"><a href="#cb23-11"></a></span>
<span id="cb23-12"><a href="#cb23-12"></a>predicted_totals_for_unit_exposure <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(</span>
<span id="cb23-13"><a href="#cb23-13"></a>  <span class="at">file =</span> <span class="st">"predicted_totals_for_unit_exposure.rds"</span></span>
<span id="cb23-14"><a href="#cb23-14"></a>)</span>
<span id="cb23-15"><a href="#cb23-15"></a></span>
<span id="cb23-16"><a href="#cb23-16"></a><span class="fu">summary</span>(predicted_totals_for_unit_exposure)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
 3904985 11011626 12889186 13044586 14930666 27255385 </code></pre>
</div>
</div>
</section>
<section id="nonparametric-bootstrap" class="level3">
<h3 class="anchored" data-anchor-id="nonparametric-bootstrap">Nonparametric Bootstrap</h3>
<p>The parametric bootstrap uses the point estimate to simulate new samples. From a Bayesian point of view, this corresponds to using the Dirac delta posterior distribution with a spike at the point estimate <span class="math inline">\((\hat\mu_{\text{int}}, \hat\phi_{\text{int}})\)</span> and ignoring the uncertainty in the parameter estimates by treating it as zero. This section extends the parametric bootstrap approach by accounting for the uncertainty in the <span class="math inline">\((\hat\mu_{\text{int}}, \hat\phi_{\text{int}})\)</span> values.</p>
<p>In the first stage, a separate Tweedie model is fit to each bootstrapped sample from the original data and the estimated <span class="math inline">\((\hat\mu_{\text{int}, b}, \hat\phi_{\text{int}, b})_{b = 1}^{10,000}\)</span> pairs are collected. These 10,000 pairs are a sample from the “poor man’s” posterior distribution for these parameters and are visualized here</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1"></a><span class="co"># bootstrap and get the joint distribution of (mu, phi)</span></span>
<span id="cb25-2"><a href="#cb25-2"></a><span class="co"># bootstrap_mu_phi &lt;- map_dfr(</span></span>
<span id="cb25-3"><a href="#cb25-3"></a><span class="co">#   .x = 1:10000,</span></span>
<span id="cb25-4"><a href="#cb25-4"></a><span class="co">#   .f = ~ {</span></span>
<span id="cb25-5"><a href="#cb25-5"></a><span class="co">#     if(.x %% 100 == 0) {</span></span>
<span id="cb25-6"><a href="#cb25-6"></a><span class="co">#       print(.x)</span></span>
<span id="cb25-7"><a href="#cb25-7"></a><span class="co">#     }</span></span>
<span id="cb25-8"><a href="#cb25-8"></a><span class="co">#     set.seed(.x)</span></span>
<span id="cb25-9"><a href="#cb25-9"></a><span class="co">#     data &lt;- claims %&gt;%</span></span>
<span id="cb25-10"><a href="#cb25-10"></a><span class="co">#       slice_sample(n = 60000, replace = TRUE)</span></span>
<span id="cb25-11"><a href="#cb25-11"></a><span class="co">#     outlier_counts &lt;- nrow(data[data$ClaimAmount == 1404185.52, ])</span></span>
<span id="cb25-12"><a href="#cb25-12"></a><span class="co">#     mod &lt;- data %&gt;%</span></span>
<span id="cb25-13"><a href="#cb25-13"></a><span class="co">#       glm(</span></span>
<span id="cb25-14"><a href="#cb25-14"></a><span class="co">#         I(ClaimAmount / Exposure) ~ 1,</span></span>
<span id="cb25-15"><a href="#cb25-15"></a><span class="co">#         weights = Exposure,</span></span>
<span id="cb25-16"><a href="#cb25-16"></a><span class="co">#         data = .,</span></span>
<span id="cb25-17"><a href="#cb25-17"></a><span class="co">#         family = statmod::tweedie(var.power = 1.6, link.power = 0)</span></span>
<span id="cb25-18"><a href="#cb25-18"></a><span class="co">#       )</span></span>
<span id="cb25-19"><a href="#cb25-19"></a><span class="co">#</span></span>
<span id="cb25-20"><a href="#cb25-20"></a><span class="co">#     tibble(</span></span>
<span id="cb25-21"><a href="#cb25-21"></a><span class="co">#       mu = exp(coef(mod)),</span></span>
<span id="cb25-22"><a href="#cb25-22"></a><span class="co">#       phi = summary(mod)$dispersion,</span></span>
<span id="cb25-23"><a href="#cb25-23"></a><span class="co">#       outlier_counts = outlier_counts</span></span>
<span id="cb25-24"><a href="#cb25-24"></a><span class="co">#     )</span></span>
<span id="cb25-25"><a href="#cb25-25"></a><span class="co">#   }</span></span>
<span id="cb25-26"><a href="#cb25-26"></a><span class="co"># )</span></span>
<span id="cb25-27"><a href="#cb25-27"></a><span class="co">#</span></span>
<span id="cb25-28"><a href="#cb25-28"></a><span class="co"># saveRDS(bootstrap_mu_phi, file = "bootstrap_mu_phi.rds")</span></span>
<span id="cb25-29"><a href="#cb25-29"></a></span>
<span id="cb25-30"><a href="#cb25-30"></a>bootstrap_mu_phi <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"bootstrap_mu_phi.rds"</span>)</span>
<span id="cb25-31"><a href="#cb25-31"></a></span>
<span id="cb25-32"><a href="#cb25-32"></a>mu_phi_plot <span class="ot">&lt;-</span> bootstrap_mu_phi <span class="sc">%&gt;%</span></span>
<span id="cb25-33"><a href="#cb25-33"></a>  <span class="fu">mutate</span>(<span class="st">`</span><span class="at">Outlier counts</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">factor</span>(outlier_counts)) <span class="sc">%&gt;%</span></span>
<span id="cb25-34"><a href="#cb25-34"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> phi, <span class="at">color =</span> <span class="st">`</span><span class="at">Outlier counts</span><span class="st">`</span>)) <span class="sc">+</span></span>
<span id="cb25-35"><a href="#cb25-35"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb25-36"><a href="#cb25-36"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> <span class="fu">tibble</span>(<span class="at">mu =</span> mu, <span class="at">phi =</span> phi),</span>
<span id="cb25-37"><a href="#cb25-37"></a>             <span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> phi),</span>
<span id="cb25-38"><a href="#cb25-38"></a>             <span class="at">color =</span> <span class="st">"gray20"</span>, <span class="at">size =</span> <span class="dv">5</span>, <span class="at">inherit.aes =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb25-39"><a href="#cb25-39"></a>  <span class="fu">labs</span>(</span>
<span id="cb25-40"><a href="#cb25-40"></a>    <span class="at">x =</span> glue<span class="sc">::</span><span class="fu">glue</span>(<span class="st">"Mean (\u03bc)</span><span class="sc">\n</span><span class="st">"</span>, </span>
<span id="cb25-41"><a href="#cb25-41"></a>                   <span class="st">"Point estimates for mean and"</span>, </span>
<span id="cb25-42"><a href="#cb25-42"></a>                   <span class="st">" dispersion from the full sample "</span>,</span>
<span id="cb25-43"><a href="#cb25-43"></a>                   <span class="st">"shown in black"</span>),</span>
<span id="cb25-44"><a href="#cb25-44"></a>    <span class="at">y =</span> <span class="st">"Dispersion (\u03d5)"</span></span>
<span id="cb25-45"><a href="#cb25-45"></a>  ) <span class="sc">+</span></span>
<span id="cb25-46"><a href="#cb25-46"></a>  <span class="fu">theme</span>(</span>
<span id="cb25-47"><a href="#cb25-47"></a>    <span class="at">legend.position =</span> <span class="st">"inside"</span>,</span>
<span id="cb25-48"><a href="#cb25-48"></a>    <span class="at">legend.background =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb25-49"><a href="#cb25-49"></a>    <span class="at">legend.position.inside =</span> <span class="fu">c</span>(<span class="fl">0.8</span>, <span class="fl">0.18</span>)</span>
<span id="cb25-50"><a href="#cb25-50"></a>  ) <span class="sc">+</span></span>
<span id="cb25-51"><a href="#cb25-51"></a>  <span class="fu">guides</span>(<span class="at">color =</span> <span class="fu">guide_legend</span>(<span class="at">nrow =</span> <span class="dv">2</span>))</span>
<span id="cb25-52"><a href="#cb25-52"></a></span>
<span id="cb25-53"><a href="#cb25-53"></a><span class="co"># this thorws warnings that bins are ignored, but </span></span>
<span id="cb25-54"><a href="#cb25-54"></a><span class="co"># the correct behaviour is observed anyway</span></span>
<span id="cb25-55"><a href="#cb25-55"></a>ggExtra<span class="sc">::</span><span class="fu">ggMarginal</span>(</span>
<span id="cb25-56"><a href="#cb25-56"></a>  <span class="at">p =</span> mu_phi_plot, <span class="at">type =</span> <span class="st">"densigram"</span>, </span>
<span id="cb25-57"><a href="#cb25-57"></a>  <span class="at">xparams =</span> <span class="fu">list</span>(<span class="at">bins =</span> <span class="dv">100</span>), </span>
<span id="cb25-58"><a href="#cb25-58"></a>  <span class="at">yparams =</span> <span class="fu">list</span>(<span class="at">bins =</span> <span class="dv">100</span>)</span>
<span id="cb25-59"><a href="#cb25-59"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The clustering of points was initially a bit puzzling. The marginal density for the mean (top) is the same as the multimodal bootstrap distribution from a few sections above. The density for dispersion seems to be a lot less well-behaved. Coloring by the number of times that the original sample maximum claim amount is sampled in the bootstrap datasets, it’s clear that the frequency of occurrence is largely responsible for the clustering observed here.</p>
<p>In the second stage, a random pair <span class="math inline">\((\hat\mu_{\text{int}, b}, \hat\phi_{\text{int}, b})\)</span> is drawn first, followed by drawing <span class="math inline">\(n\)</span> values <span class="math inline">\(Y_{i, b}^* \sim \text{Tweedie}(\hat\mu_{\text{int}, b}, \hat\phi_{\text{int}, b}, p = 1.6)\)</span>, and summing these to get an estimate of the total claim amount <span class="math inline">\(\hat{T_b}\)</span>.</p>
<p>It is expected that accounting for uncertainty in the estimation of <span class="math inline">\((\hat\mu_{\text{int}}, \hat\phi_{\text{int}})\)</span> should lead to thicker tails for the distribution of <span class="math inline">\(\hat{T_b}\)</span>’s. The right tail now extends beyond 28 million and goes up to 34 million.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1"></a><span class="co"># sample Y_i from the posterior predictive distribution and sum them</span></span>
<span id="cb26-2"><a href="#cb26-2"></a><span class="co"># do this 10k times to get the posterior distribution</span></span>
<span id="cb26-3"><a href="#cb26-3"></a><span class="co"># posterior_distribution_samples_for_total_claims &lt;- map(</span></span>
<span id="cb26-4"><a href="#cb26-4"></a><span class="co">#   .x = 1:10000,</span></span>
<span id="cb26-5"><a href="#cb26-5"></a><span class="co">#   .f = ~ {</span></span>
<span id="cb26-6"><a href="#cb26-6"></a><span class="co">#     if(.x %% 100 == 0) {</span></span>
<span id="cb26-7"><a href="#cb26-7"></a><span class="co">#       print(.x)</span></span>
<span id="cb26-8"><a href="#cb26-8"></a><span class="co">#     }</span></span>
<span id="cb26-9"><a href="#cb26-9"></a><span class="co">#     set.seed(.x)</span></span>
<span id="cb26-10"><a href="#cb26-10"></a><span class="co">#     draw &lt;- bootstrap_mu_phi %&gt;%</span></span>
<span id="cb26-11"><a href="#cb26-11"></a><span class="co">#       slice_sample(n = 1)</span></span>
<span id="cb26-12"><a href="#cb26-12"></a><span class="co">#</span></span>
<span id="cb26-13"><a href="#cb26-13"></a><span class="co">#     set.seed(.x)</span></span>
<span id="cb26-14"><a href="#cb26-14"></a><span class="co">#     sum_values &lt;- draw %$%</span></span>
<span id="cb26-15"><a href="#cb26-15"></a><span class="co">#       tweedie::rtweedie(n = 60000, mu = mu, phi = phi, power = 1.6) %&gt;%</span></span>
<span id="cb26-16"><a href="#cb26-16"></a><span class="co">#       sum()</span></span>
<span id="cb26-17"><a href="#cb26-17"></a><span class="co">#</span></span>
<span id="cb26-18"><a href="#cb26-18"></a><span class="co">#     draw %&gt;%</span></span>
<span id="cb26-19"><a href="#cb26-19"></a><span class="co">#       mutate(total = sum_values)</span></span>
<span id="cb26-20"><a href="#cb26-20"></a><span class="co">#   }</span></span>
<span id="cb26-21"><a href="#cb26-21"></a><span class="co"># ) %&gt;%</span></span>
<span id="cb26-22"><a href="#cb26-22"></a><span class="co">#   list_rbind()</span></span>
<span id="cb26-23"><a href="#cb26-23"></a><span class="co">#</span></span>
<span id="cb26-24"><a href="#cb26-24"></a><span class="co"># saveRDS(posterior_distribution_samples_for_total_claims,</span></span>
<span id="cb26-25"><a href="#cb26-25"></a><span class="co">#         file = "posterior_distribution_samples_for_total_claims.rds")</span></span>
<span id="cb26-26"><a href="#cb26-26"></a></span>
<span id="cb26-27"><a href="#cb26-27"></a>posterior_distribution_samples_for_total_claims <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(</span>
<span id="cb26-28"><a href="#cb26-28"></a>  <span class="at">file =</span> <span class="st">"posterior_distribution_samples_for_total_claims.rds"</span></span>
<span id="cb26-29"><a href="#cb26-29"></a>)</span>
<span id="cb26-30"><a href="#cb26-30"></a></span>
<span id="cb26-31"><a href="#cb26-31"></a><span class="fu">summary</span>(posterior_distribution_samples_for_total_claims)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>       mu             phi              total         
 Min.   :144.3   Min.   :  883.9   Min.   : 3244481  
 1st Qu.:182.1   1st Qu.:16455.5   1st Qu.:10286795  
 Median :213.6   Median :24801.9   Median :12234351  
 Mean   :218.2   Mean   :23607.4   Mean   :13061045  
 3rd Qu.:243.8   3rd Qu.:31349.8   3rd Qu.:15142596  
 Max.   :452.7   Max.   :68572.1   Max.   :34585477  </code></pre>
</div>
</div>
</section>
<section id="using-properties-of-edms" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="using-properties-of-edms">Using properties of EDMs</h3>
<p>This section uses two properties — sampling distribution of the weighted average, and scale invariance — of <a href="https://en.wikipedia.org/wiki/Exponential_dispersion_model">exponential dispersion models</a> (EDMs) of which Tweedie distributions are a special case.</p>
<p>The main statistic of interest has been the weighted mean <span class="math inline">\(T_{wm}\)</span> of the pure premium values (<span class="math inline">\(Y_i = Z_i / w_i\)</span>)</p>
<p><span class="math display">\[
T_{wm} = w_{\bullet}^{-1} \sum_{i = 1}^n w_i Y_i
\]</span></p>
<p>where <span class="math inline">\(w_{\bullet} = \sum_i w_i\)</span> is the sum of the exposures. If <span class="math inline">\(Y_i \sim \text{Tweedie}(\mu, \phi / w_i, p)\)</span>, then the sampling distribution of the weighted mean is also a Tweedie distribution with the same mean but with the dispersion <span class="math inline">\(\phi\)</span> scaled by the total exposure, i.e., <span class="math inline">\(T_{wm} \sim \text{Tweedie}(\mu, \phi / w_{\bullet}, p)\)</span>.</p>
<p>The scale invariance property says that</p>
<p><span class="math display">\[
c \text{Tweedie}(\mu, \phi, p) = \text{Tweedie}(c \mu, c^{2-p} \phi, p)
\]</span></p>
<p>Combining these two and setting <span class="math inline">\(c = 60,000\)</span> since we’re interested in the total claim amount across the policies, we can write</p>
<p><span class="math display">\[
T_\text{total} \sim \text{Tweedie}(60000 \mu, 60000^{2-p} \phi / w_{\bullet}, p)
\]</span></p>
<p>This is much simpler and faster than the parametric bootstrap (for the weighted mean <span class="math inline">\(T_{wm}\)</span>) since we don’t need to sample the vector of <span class="math inline">\(Y_{i, b}^*\)</span>’s as an intermediate step<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p>
<div class="no-row-height column-margin column-container"><p><sup>3</sup>&nbsp;Of course the parametric bootstrap is much more general, so it’s not really a fair comparison.</p></div><div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1"></a>total_exposure <span class="ot">&lt;-</span> claims <span class="sc">%&gt;%</span> </span>
<span id="cb28-2"><a href="#cb28-2"></a>  <span class="fu">pull</span>(Exposure) <span class="sc">%&gt;%</span> </span>
<span id="cb28-3"><a href="#cb28-3"></a>  <span class="fu">sum</span>()</span>
<span id="cb28-4"><a href="#cb28-4"></a></span>
<span id="cb28-5"><a href="#cb28-5"></a><span class="fu">set.seed</span>(<span class="dv">43</span>)</span>
<span id="cb28-6"><a href="#cb28-6"></a>predicted_totals_tweedie_sampling_dist <span class="ot">&lt;-</span> tweedie<span class="sc">::</span><span class="fu">rtweedie</span>(</span>
<span id="cb28-7"><a href="#cb28-7"></a>  <span class="at">n =</span> <span class="dv">10000</span>,</span>
<span id="cb28-8"><a href="#cb28-8"></a>  <span class="at">mu =</span> <span class="dv">60000</span> <span class="sc">*</span> mu,</span>
<span id="cb28-9"><a href="#cb28-9"></a>  <span class="at">phi =</span> ((<span class="dv">60000</span> <span class="sc">^</span> (<span class="dv">2</span> <span class="sc">-</span> <span class="fl">1.6</span>)) <span class="sc">*</span> phi) <span class="sc">/</span> total_exposure,</span>
<span id="cb28-10"><a href="#cb28-10"></a>  <span class="at">power =</span> <span class="fl">1.6</span></span>
<span id="cb28-11"><a href="#cb28-11"></a>)</span>
<span id="cb28-12"><a href="#cb28-12"></a></span>
<span id="cb28-13"><a href="#cb28-13"></a>predicted_totals_tweedie_sampling_dist <span class="sc">%&gt;%</span> <span class="fu">summary</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
 2848259 10276333 12713295 13030839 15472733 32389786 </code></pre>
</div>
</div>
</section>
<section id="glm-with-predictors" class="level3">
<h3 class="anchored" data-anchor-id="glm-with-predictors">GLM with predictors</h3>
<p>So far, we’ve ignored all other variables in the data that provide information at the level of the policyholder, and modelled the marginal distribution of the pure premiums. Using this so-called <em>collective</em> model can be contrasted with the <em>individual</em> model where information at the policy level can be used for modelling individual risk.</p>
<p>The simplest extension to the intercept-only model is the <em>main effects</em> model which includes all the additional variables at the policy level in the model</p>
<p><span class="math display">\[
\begin{align*}
Y_i &amp;\sim \text{Tweedie}(\mu_i = \text{exp}(\text{log}(E[Y_i])), \phi, p) \\
\text{log}(E[Y_i]) &amp;= \beta_0 + \beta_1 x_{i, 1} + \dots + \beta_p x_{i, p}
\end{align*}
\]</span></p>
<p>For simplicity, linearity and additivity of the predictors are assumed on the log scale, which leads to a multiplicative model on the original scale. This has the additional advantage of ensuring that the expected values can never be less than 0 (since <span class="math inline">\(\mu &gt; 0\)</span>). Using boosted trees (e.g.&nbsp;LightGBM) would be a natural next step for improvement as they can model interactions, carry out variable selection by dropping terms that don’t impact risk, don’t impose functional form restrictions, etc. and can lead to more accurate predictions.</p>
<p>The following code fits a Tweedie GLM to the pure premium values <span class="math inline">\(y_i\)</span> with exposure weights <span class="math inline">\(w_i\)</span> using the log link (<code>link.power = 0</code>) and fixing <span class="math inline">\(p = 1.6\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1"></a>claims_modelling <span class="ot">&lt;-</span> claims <span class="sc">%&gt;%</span></span>
<span id="cb30-2"><a href="#cb30-2"></a>  <span class="fu">mutate</span>(</span>
<span id="cb30-3"><a href="#cb30-3"></a>    <span class="fu">across</span>(<span class="fu">c</span>(Area, VehPower, VehBrand, VehGas, Region), <span class="sc">~</span> <span class="fu">as.factor</span>(.x)),</span>
<span id="cb30-4"><a href="#cb30-4"></a>    <span class="at">pure_premium =</span> ClaimAmount <span class="sc">/</span> Exposure</span>
<span id="cb30-5"><a href="#cb30-5"></a>  )</span>
<span id="cb30-6"><a href="#cb30-6"></a></span>
<span id="cb30-7"><a href="#cb30-7"></a>main_effects_glm <span class="ot">&lt;-</span> <span class="fu">glm</span>(</span>
<span id="cb30-8"><a href="#cb30-8"></a>  pure_premium <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> Area <span class="sc">+</span> VehPower <span class="sc">+</span> VehAge <span class="sc">+</span> DrivAge</span>
<span id="cb30-9"><a href="#cb30-9"></a>  <span class="sc">+</span> BonusMalus <span class="sc">+</span> VehBrand <span class="sc">+</span> VehGas <span class="sc">+</span> Density <span class="sc">+</span> Region,</span>
<span id="cb30-10"><a href="#cb30-10"></a>  <span class="at">weights =</span> Exposure,</span>
<span id="cb30-11"><a href="#cb30-11"></a>  <span class="at">data =</span> claims_modelling,</span>
<span id="cb30-12"><a href="#cb30-12"></a>  <span class="at">family =</span> statmod<span class="sc">::</span><span class="fu">tweedie</span>(<span class="at">var.power =</span> <span class="fl">1.6</span>, <span class="at">link.power =</span> <span class="dv">0</span>)</span>
<span id="cb30-13"><a href="#cb30-13"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Given the increase in complexity of this model and to eventually try more complex models, it would be good to switch to cross-validation to see how well this model performs on unseen data. I’ll get to this in a future post.</p>
<p>It can be informative to explore the fitted values.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1"></a>fitted_values <span class="ot">&lt;-</span> main_effects_glm <span class="sc">%&gt;%</span></span>
<span id="cb31-2"><a href="#cb31-2"></a>  broom<span class="sc">::</span><span class="fu">augment</span>(<span class="at">newdata =</span> claims_modelling, <span class="at">type.predict =</span> <span class="st">"response"</span>)</span>
<span id="cb31-3"><a href="#cb31-3"></a></span>
<span id="cb31-4"><a href="#cb31-4"></a>mean_fitted <span class="ot">&lt;-</span> fitted_values <span class="sc">%&gt;%</span></span>
<span id="cb31-5"><a href="#cb31-5"></a>  <span class="fu">pull</span>(<span class="st">".fitted"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb31-6"><a href="#cb31-6"></a>  <span class="fu">mean</span>()</span>
<span id="cb31-7"><a href="#cb31-7"></a></span>
<span id="cb31-8"><a href="#cb31-8"></a>fitted_values <span class="sc">%&gt;%</span></span>
<span id="cb31-9"><a href="#cb31-9"></a>  <span class="fu">pull</span>(.fitted) <span class="sc">%&gt;%</span></span>
<span id="cb31-10"><a href="#cb31-10"></a>  <span class="fu">quantile</span>(</span>
<span id="cb31-11"><a href="#cb31-11"></a>    <span class="at">probs =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">0.95</span>, <span class="fl">0.99</span>, <span class="fl">1.0</span>)</span>
<span id="cb31-12"><a href="#cb31-12"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb31-13"><a href="#cb31-13"></a>  <span class="fu">c</span>(., <span class="st">"Mean"</span> <span class="ot">=</span> mean_fitted) <span class="sc">%&gt;%</span></span>
<span id="cb31-14"><a href="#cb31-14"></a>  <span class="fu">sort</span>() <span class="sc">%&gt;%</span></span>
<span id="cb31-15"><a href="#cb31-15"></a>  <span class="fu">round</span>(., <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>       0%       25%       50%       75%      Mean       95%       99%      100% 
     6.20     87.99    138.68    247.29    256.30    764.44   1763.00 306296.00 </code></pre>
</div>
</div>
<p>The least risky policy has an expected value of 6.2 and 50% of the policies have an expected value less than 140. Fewer than 1% of the policies have a risk larger than 2000, but the riskiest policy has an expected value of about 300,000. Since this is a simple main effects model, it’s easy enough to see which term(s) contribute towards these very high values for the top-10 policies with the largest pure premium values</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1"></a><span class="co"># get the term-wise contribution to the prediction on the</span></span>
<span id="cb33-2"><a href="#cb33-2"></a><span class="co"># link scale for the top k largest predictions</span></span>
<span id="cb33-3"><a href="#cb33-3"></a>top_10_largest_policy_predictions <span class="ot">&lt;-</span> fitted_values <span class="sc">%&gt;%</span></span>
<span id="cb33-4"><a href="#cb33-4"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(.fitted)) <span class="sc">%&gt;%</span></span>
<span id="cb33-5"><a href="#cb33-5"></a>  <span class="fu">slice_head</span>(<span class="at">n =</span> <span class="dv">10</span>)</span>
<span id="cb33-6"><a href="#cb33-6"></a></span>
<span id="cb33-7"><a href="#cb33-7"></a>top_10_largest_policy_predictions <span class="sc">%&gt;%</span> </span>
<span id="cb33-8"><a href="#cb33-8"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<colgroup>
<col style="width: 5%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 3%">
<col style="width: 6%">
<col style="width: 5%">
<col style="width: 6%">
<col style="width: 8%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 5%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 7%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;">IDpol</th>
<th style="text-align: right;">ClaimNb</th>
<th style="text-align: right;">Exposure</th>
<th style="text-align: left;">Area</th>
<th style="text-align: left;">VehPower</th>
<th style="text-align: right;">VehAge</th>
<th style="text-align: right;">DrivAge</th>
<th style="text-align: right;">BonusMalus</th>
<th style="text-align: left;">VehBrand</th>
<th style="text-align: left;">VehGas</th>
<th style="text-align: right;">Density</th>
<th style="text-align: left;">Region</th>
<th style="text-align: right;">ClaimAmount</th>
<th style="text-align: right;">pure_premium</th>
<th style="text-align: right;">.fitted</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">41847</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0.24</td>
<td style="text-align: left;">C</td>
<td style="text-align: left;">7</td>
<td style="text-align: right;">12</td>
<td style="text-align: right;">60</td>
<td style="text-align: right;">228</td>
<td style="text-align: left;">B1</td>
<td style="text-align: left;">Regular</td>
<td style="text-align: right;">300</td>
<td style="text-align: left;">R53</td>
<td style="text-align: right;">1128.12</td>
<td style="text-align: right;">4700.500</td>
<td style="text-align: right;">306296.00</td>
</tr>
<tr class="even">
<td style="text-align: right;">70558</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0.30</td>
<td style="text-align: left;">E</td>
<td style="text-align: left;">6</td>
<td style="text-align: right;">12</td>
<td style="text-align: right;">24</td>
<td style="text-align: right;">195</td>
<td style="text-align: left;">B1</td>
<td style="text-align: left;">Regular</td>
<td style="text-align: right;">3103</td>
<td style="text-align: left;">R82</td>
<td style="text-align: right;">0.00</td>
<td style="text-align: right;">0.000</td>
<td style="text-align: right;">75259.17</td>
</tr>
<tr class="odd">
<td style="text-align: right;">40910</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0.60</td>
<td style="text-align: left;">B</td>
<td style="text-align: left;">12</td>
<td style="text-align: right;">19</td>
<td style="text-align: right;">39</td>
<td style="text-align: right;">156</td>
<td style="text-align: left;">B11</td>
<td style="text-align: left;">Regular</td>
<td style="text-align: right;">95</td>
<td style="text-align: left;">R82</td>
<td style="text-align: right;">0.00</td>
<td style="text-align: right;">0.000</td>
<td style="text-align: right;">23306.65</td>
</tr>
<tr class="even">
<td style="text-align: right;">89044</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0.39</td>
<td style="text-align: left;">E</td>
<td style="text-align: left;">4</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">26</td>
<td style="text-align: right;">173</td>
<td style="text-align: left;">B1</td>
<td style="text-align: left;">Regular</td>
<td style="text-align: right;">3744</td>
<td style="text-align: left;">R93</td>
<td style="text-align: right;">0.00</td>
<td style="text-align: right;">0.000</td>
<td style="text-align: right;">22336.77</td>
</tr>
<tr class="odd">
<td style="text-align: right;">62898</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: left;">E</td>
<td style="text-align: left;">7</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">80</td>
<td style="text-align: right;">173</td>
<td style="text-align: left;">B2</td>
<td style="text-align: left;">Regular</td>
<td style="text-align: right;">3688</td>
<td style="text-align: left;">R82</td>
<td style="text-align: right;">1128.12</td>
<td style="text-align: right;">1128.120</td>
<td style="text-align: right;">20961.85</td>
</tr>
<tr class="even">
<td style="text-align: right;">113887</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0.26</td>
<td style="text-align: left;">D</td>
<td style="text-align: left;">6</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">28</td>
<td style="text-align: right;">156</td>
<td style="text-align: left;">B1</td>
<td style="text-align: left;">Regular</td>
<td style="text-align: right;">1943</td>
<td style="text-align: left;">R24</td>
<td style="text-align: right;">1128.12</td>
<td style="text-align: right;">4338.923</td>
<td style="text-align: right;">18147.85</td>
</tr>
<tr class="odd">
<td style="text-align: right;">41513</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: left;">D</td>
<td style="text-align: left;">5</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">30</td>
<td style="text-align: right;">196</td>
<td style="text-align: left;">B2</td>
<td style="text-align: left;">Regular</td>
<td style="text-align: right;">1284</td>
<td style="text-align: left;">R25</td>
<td style="text-align: right;">1830.85</td>
<td style="text-align: right;">1830.850</td>
<td style="text-align: right;">17029.99</td>
</tr>
<tr class="even">
<td style="text-align: right;">102276</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0.75</td>
<td style="text-align: left;">E</td>
<td style="text-align: left;">6</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">25</td>
<td style="text-align: right;">156</td>
<td style="text-align: left;">B3</td>
<td style="text-align: left;">Diesel</td>
<td style="text-align: right;">3021</td>
<td style="text-align: left;">R53</td>
<td style="text-align: right;">0.00</td>
<td style="text-align: right;">0.000</td>
<td style="text-align: right;">16095.04</td>
</tr>
<tr class="odd">
<td style="text-align: right;">32880</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: left;">C</td>
<td style="text-align: left;">4</td>
<td style="text-align: right;">17</td>
<td style="text-align: right;">47</td>
<td style="text-align: right;">177</td>
<td style="text-align: left;">B2</td>
<td style="text-align: left;">Regular</td>
<td style="text-align: right;">105</td>
<td style="text-align: left;">R24</td>
<td style="text-align: right;">0.00</td>
<td style="text-align: right;">0.000</td>
<td style="text-align: right;">14837.72</td>
</tr>
<tr class="even">
<td style="text-align: right;">58572</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0.05</td>
<td style="text-align: left;">E</td>
<td style="text-align: left;">7</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">21</td>
<td style="text-align: right;">156</td>
<td style="text-align: left;">B1</td>
<td style="text-align: left;">Regular</td>
<td style="text-align: right;">4762</td>
<td style="text-align: left;">R93</td>
<td style="text-align: right;">0.00</td>
<td style="text-align: right;">0.000</td>
<td style="text-align: right;">14193.21</td>
</tr>
</tbody>
</table>
</div>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1"></a>top_10_largest_policy_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(</span>
<span id="cb34-2"><a href="#cb34-2"></a>  <span class="at">object =</span> main_effects_glm, </span>
<span id="cb34-3"><a href="#cb34-3"></a>  <span class="at">newdata =</span> top_10_largest_policy_predictions, </span>
<span id="cb34-4"><a href="#cb34-4"></a>  <span class="at">type =</span> <span class="st">"terms"</span></span>
<span id="cb34-5"><a href="#cb34-5"></a>)</span>
<span id="cb34-6"><a href="#cb34-6"></a></span>
<span id="cb34-7"><a href="#cb34-7"></a><span class="co"># convert the 'terms' data frame to tibble and add constant value</span></span>
<span id="cb34-8"><a href="#cb34-8"></a><span class="co"># then pivot to get the exp(cumsum()) for each policy (i.e. row)</span></span>
<span id="cb34-9"><a href="#cb34-9"></a><span class="co"># then pivot back</span></span>
<span id="cb34-10"><a href="#cb34-10"></a><span class="co"># there's probably some neat function that does </span></span>
<span id="cb34-11"><a href="#cb34-11"></a><span class="co"># this in fewer lines of code</span></span>
<span id="cb34-12"><a href="#cb34-12"></a>top_10_largest_policy_predictions <span class="sc">%&gt;%</span></span>
<span id="cb34-13"><a href="#cb34-13"></a>  <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span></span>
<span id="cb34-14"><a href="#cb34-14"></a>  <span class="fu">mutate</span>(</span>
<span id="cb34-15"><a href="#cb34-15"></a>    <span class="at">id =</span> <span class="fu">row_number</span>(),</span>
<span id="cb34-16"><a href="#cb34-16"></a>    <span class="co"># for the calculation of the constant value, see this</span></span>
<span id="cb34-17"><a href="#cb34-17"></a>    <span class="co"># https://stackoverflow.com/questions/37963904/what-does-predict-glm-type-terms-actually-do</span></span>
<span id="cb34-18"><a href="#cb34-18"></a>    <span class="at">constant =</span> <span class="fu">attr</span>(top_10_largest_policy_predictions, <span class="st">"constant"</span>),</span>
<span id="cb34-19"><a href="#cb34-19"></a>    <span class="at">.before =</span> <span class="dv">0</span></span>
<span id="cb34-20"><a href="#cb34-20"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb34-21"><a href="#cb34-21"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="sc">-</span>id) <span class="sc">%&gt;%</span></span>
<span id="cb34-22"><a href="#cb34-22"></a>  <span class="fu">group_by</span>(id) <span class="sc">%&gt;%</span></span>
<span id="cb34-23"><a href="#cb34-23"></a>  <span class="fu">mutate</span>(<span class="at">value =</span> <span class="fu">exp</span>(<span class="fu">cumsum</span>(value))) <span class="sc">%&gt;%</span></span>
<span id="cb34-24"><a href="#cb34-24"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb34-25"><a href="#cb34-25"></a>  <span class="fu">pivot_wider</span>(<span class="at">id_cols =</span> id, <span class="at">names_from =</span> name, <span class="at">values_from =</span> value) <span class="sc">%&gt;%</span></span>
<span id="cb34-26"><a href="#cb34-26"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="at">.cols =</span> <span class="fu">everything</span>(), <span class="at">.fns =</span> round)) <span class="sc">%&gt;%</span> </span>
<span id="cb34-27"><a href="#cb34-27"></a>  <span class="fu">select</span>(<span class="sc">-</span>id) <span class="sc">%&gt;%</span></span>
<span id="cb34-28"><a href="#cb34-28"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<colgroup>
<col style="width: 11%">
<col style="width: 6%">
<col style="width: 11%">
<col style="width: 8%">
<col style="width: 10%">
<col style="width: 13%">
<col style="width: 11%">
<col style="width: 8%">
<col style="width: 10%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;">constant</th>
<th style="text-align: right;">Area</th>
<th style="text-align: right;">VehPower</th>
<th style="text-align: right;">VehAge</th>
<th style="text-align: right;">DrivAge</th>
<th style="text-align: right;">BonusMalus</th>
<th style="text-align: right;">VehBrand</th>
<th style="text-align: right;">VehGas</th>
<th style="text-align: right;">Density</th>
<th style="text-align: right;">Region</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">157</td>
<td style="text-align: right;">169</td>
<td style="text-align: right;">141</td>
<td style="text-align: right;">125</td>
<td style="text-align: right;">142</td>
<td style="text-align: right;">188272</td>
<td style="text-align: right;">216443</td>
<td style="text-align: right;">218766</td>
<td style="text-align: right;">230584</td>
<td style="text-align: right;">306296</td>
</tr>
<tr class="even">
<td style="text-align: right;">157</td>
<td style="text-align: right;">216</td>
<td style="text-align: right;">311</td>
<td style="text-align: right;">274</td>
<td style="text-align: right;">234</td>
<td style="text-align: right;">75132</td>
<td style="text-align: right;">86374</td>
<td style="text-align: right;">87300</td>
<td style="text-align: right;">81568</td>
<td style="text-align: right;">75259</td>
</tr>
<tr class="odd">
<td style="text-align: right;">157</td>
<td style="text-align: right;">116</td>
<td style="text-align: right;">275</td>
<td style="text-align: right;">201</td>
<td style="text-align: right;">193</td>
<td style="text-align: right;">11582</td>
<td style="text-align: right;">23503</td>
<td style="text-align: right;">23755</td>
<td style="text-align: right;">25260</td>
<td style="text-align: right;">23307</td>
</tr>
<tr class="even">
<td style="text-align: right;">157</td>
<td style="text-align: right;">216</td>
<td style="text-align: right;">143</td>
<td style="text-align: right;">134</td>
<td style="text-align: right;">116</td>
<td style="text-align: right;">14426</td>
<td style="text-align: right;">16585</td>
<td style="text-align: right;">16763</td>
<td style="text-align: right;">15236</td>
<td style="text-align: right;">22337</td>
</tr>
<tr class="odd">
<td style="text-align: right;">157</td>
<td style="text-align: right;">216</td>
<td style="text-align: right;">180</td>
<td style="text-align: right;">168</td>
<td style="text-align: right;">223</td>
<td style="text-align: right;">27859</td>
<td style="text-align: right;">24670</td>
<td style="text-align: right;">24935</td>
<td style="text-align: right;">22719</td>
<td style="text-align: right;">20962</td>
</tr>
<tr class="even">
<td style="text-align: right;">157</td>
<td style="text-align: right;">153</td>
<td style="text-align: right;">220</td>
<td style="text-align: right;">254</td>
<td style="text-align: right;">224</td>
<td style="text-align: right;">13433</td>
<td style="text-align: right;">15443</td>
<td style="text-align: right;">15609</td>
<td style="text-align: right;">15330</td>
<td style="text-align: right;">18148</td>
</tr>
<tr class="odd">
<td style="text-align: right;">157</td>
<td style="text-align: right;">153</td>
<td style="text-align: right;">126</td>
<td style="text-align: right;">142</td>
<td style="text-align: right;">127</td>
<td style="text-align: right;">42714</td>
<td style="text-align: right;">37826</td>
<td style="text-align: right;">38231</td>
<td style="text-align: right;">38627</td>
<td style="text-align: right;">17030</td>
</tr>
<tr class="even">
<td style="text-align: right;">157</td>
<td style="text-align: right;">216</td>
<td style="text-align: right;">311</td>
<td style="text-align: right;">306</td>
<td style="text-align: right;">262</td>
<td style="text-align: right;">15756</td>
<td style="text-align: right;">13100</td>
<td style="text-align: right;">12922</td>
<td style="text-align: right;">12117</td>
<td style="text-align: right;">16095</td>
</tr>
<tr class="odd">
<td style="text-align: right;">157</td>
<td style="text-align: right;">169</td>
<td style="text-align: right;">112</td>
<td style="text-align: right;">87</td>
<td style="text-align: right;">89</td>
<td style="text-align: right;">13175</td>
<td style="text-align: right;">11667</td>
<td style="text-align: right;">11792</td>
<td style="text-align: right;">12534</td>
<td style="text-align: right;">14838</td>
</tr>
<tr class="even">
<td style="text-align: right;">157</td>
<td style="text-align: right;">216</td>
<td style="text-align: right;">180</td>
<td style="text-align: right;">192</td>
<td style="text-align: right;">160</td>
<td style="text-align: right;">9577</td>
<td style="text-align: right;">11010</td>
<td style="text-align: right;">11128</td>
<td style="text-align: right;">9681</td>
<td style="text-align: right;">14193</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Looking at the contribution of each term for a given policy shows that high values of <code>BonusMalus</code> (with a coefficient of 0.043 on the log scale) has the largest impact on pushing up the predicted pure premiums. Obviously, for more complex models, SHAP plots would provide similar information in terms of identifying features that contribute to very high (or low) predicted values for the policies of interest.</p>
<p>The distribution of fitted values can be visualized too</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1"></a>fitted_values <span class="sc">%&gt;%</span></span>
<span id="cb35-2"><a href="#cb35-2"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> .fitted)) <span class="sc">+</span></span>
<span id="cb35-3"><a href="#cb35-3"></a>  <span class="fu">stat_ecdf</span>() <span class="sc">+</span></span>
<span id="cb35-4"><a href="#cb35-4"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> mu, <span class="at">color =</span> <span class="st">"orange"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb35-5"><a href="#cb35-5"></a>  <span class="fu">annotate</span>(<span class="at">geom =</span> <span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">200</span>, <span class="at">y =</span> <span class="fl">0.8</span>, <span class="at">color =</span> <span class="st">"orange"</span>,</span>
<span id="cb35-6"><a href="#cb35-6"></a>           <span class="at">label =</span> <span class="st">"Marginal mean: 217.8"</span>, <span class="at">hjust =</span> <span class="st">"right"</span>) <span class="sc">+</span></span>
<span id="cb35-7"><a href="#cb35-7"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> mean_fitted, <span class="at">color =</span> <span class="st">"red4"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb35-8"><a href="#cb35-8"></a>  <span class="fu">annotate</span>(<span class="at">geom =</span> <span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">275</span>, <span class="at">y =</span> <span class="fl">0.5</span>, <span class="at">color =</span> <span class="st">"red4"</span>,</span>
<span id="cb35-9"><a href="#cb35-9"></a>           <span class="at">label =</span> <span class="st">"Fitted values mean: 256.3"</span>, <span class="at">hjust =</span> <span class="st">"left"</span>) <span class="sc">+</span></span>
<span id="cb35-10"><a href="#cb35-10"></a>  <span class="fu">scale_x_log10</span>(</span>
<span id="cb35-11"><a href="#cb35-11"></a>    <span class="at">breaks =</span> scales<span class="sc">::</span><span class="fu">trans_breaks</span>(<span class="st">"log10"</span>, <span class="cf">function</span>(x) <span class="dv">10</span><span class="sc">^</span>x),</span>
<span id="cb35-12"><a href="#cb35-12"></a>    <span class="at">labels =</span> scales<span class="sc">::</span><span class="fu">trans_format</span>(<span class="st">"log10"</span>, scales<span class="sc">::</span><span class="fu">math_format</span>(<span class="dv">10</span><span class="sc">^</span>.x))</span>
<span id="cb35-13"><a href="#cb35-13"></a>  ) <span class="sc">+</span></span>
<span id="cb35-14"><a href="#cb35-14"></a>  <span class="fu">annotation_logticks</span>(<span class="at">sides =</span> <span class="st">"b"</span>) <span class="sc">+</span></span>
<span id="cb35-15"><a href="#cb35-15"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span>percent) <span class="sc">+</span></span>
<span id="cb35-16"><a href="#cb35-16"></a>  <span class="fu">xlab</span>(<span class="st">"Fitted pure premium values"</span>) <span class="sc">+</span></span>
<span id="cb35-17"><a href="#cb35-17"></a>  <span class="fu">ylab</span>(<span class="st">"Empirical distribution function"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-22-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The overall mean from the intercept only model and the mean of the fitted values don’t coincide, which I wasn’t expecting given the <a href="https://en.wikipedia.org/wiki/Law_of_total_expectation"><em>law of iterated expectation</em></a> (LIE) where <span class="math inline">\(E[Y] = E[E[Y | X]]\)</span> holds. After puzzling over this for a bit and looking around on the internet, this seems to be due to the use of the non-canonical log-link function <span class="math inline">\(g(\mu) = \text{log}(\mu)\)</span>. Using the canonical link function for a Tweedie distribution <span class="math inline">\(g(\mu) = \mu^{(1 - p)} / (1-p)\)</span> results in LIE holding, but attempting to fit the main effects model with the canonical link fails in R.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1"></a>main_effects_glm <span class="sc">%&gt;%</span> </span>
<span id="cb36-2"><a href="#cb36-2"></a>  <span class="fu">update</span>(</span>
<span id="cb36-3"><a href="#cb36-3"></a>    <span class="co"># the default link function is the canonical link function</span></span>
<span id="cb36-4"><a href="#cb36-4"></a>    <span class="at">family =</span> statmod<span class="sc">::</span><span class="fu">tweedie</span>(<span class="at">var.power =</span> <span class="fl">1.6</span>)</span>
<span id="cb36-5"><a href="#cb36-5"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>Error: no valid set of coefficients has been found: please supply starting values</code></pre>
</div>
</div>
<p>The disadvantages of using the canonical link for Tweedie models are numerical instability, and interpretation issues (since risks are not multiplicative as a function of predictors).</p>
<p>For simulating the sampling distribution of total claims across the policies, the same approach as the one from the parametric bootstrap section can be applied using the usual Pearson estimate of scale <span class="math inline">\(\phi\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1"></a>phi_glm <span class="ot">&lt;-</span> main_effects_glm <span class="sc">%&gt;%</span> </span>
<span id="cb38-2"><a href="#cb38-2"></a>  <span class="fu">summary</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb38-3"><a href="#cb38-3"></a>  <span class="fu">pluck</span>(<span class="st">"dispersion"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb38-4"><a href="#cb38-4"></a>  <span class="fu">print</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4529.461</code></pre>
</div>
</div>
<p>The estimated value of <span class="math inline">\(\hat\phi_{\text{main}} \approx 4529\)</span> is much smaller compared to the intercept-only model with value <span class="math inline">\(\hat\phi_{\text{int}} \approx 25966\)</span>. Sampling 10,000 datasets of size 60,000 with policy-specific conditional means from the individual model <span class="math inline">\(\hat\mu_i\)</span>’s and <span class="math inline">\(\hat\phi_{\text{main}}\)</span> and summing the values for each dataset now gives estimates ranging from 9 million to 52 million. The maximum possible claim amount is much much higher here compared to the 35 million from the collective model.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1"></a><span class="co"># simulate 10,000 times the total claim amounts for the full year of exposure</span></span>
<span id="cb40-2"><a href="#cb40-2"></a><span class="co"># using the fitted means</span></span>
<span id="cb40-3"><a href="#cb40-3"></a><span class="co"># predicted_totals_from_glm &lt;- map_dbl(.x = 1:10000, .f = ~ {</span></span>
<span id="cb40-4"><a href="#cb40-4"></a><span class="co">#   if(.x %% 100 == 0) {</span></span>
<span id="cb40-5"><a href="#cb40-5"></a><span class="co">#     print(.x)</span></span>
<span id="cb40-6"><a href="#cb40-6"></a><span class="co">#   }</span></span>
<span id="cb40-7"><a href="#cb40-7"></a><span class="co">#   set.seed(.x)</span></span>
<span id="cb40-8"><a href="#cb40-8"></a><span class="co">#   sum(tweedie::rtweedie(60000, mu = fitted_values$.fitted, </span></span>
<span id="cb40-9"><a href="#cb40-9"></a><span class="co">#                         phi = phi_glm, power = 1.6))</span></span>
<span id="cb40-10"><a href="#cb40-10"></a><span class="co"># })</span></span>
<span id="cb40-11"><a href="#cb40-11"></a><span class="co">#</span></span>
<span id="cb40-12"><a href="#cb40-12"></a><span class="co"># saveRDS(predicted_totals_from_glm,</span></span>
<span id="cb40-13"><a href="#cb40-13"></a><span class="co">#         file = "predicted_totals_from_glm.rds")</span></span>
<span id="cb40-14"><a href="#cb40-14"></a></span>
<span id="cb40-15"><a href="#cb40-15"></a>predicted_totals_from_glm <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(</span>
<span id="cb40-16"><a href="#cb40-16"></a>  <span class="at">file =</span> <span class="st">"predicted_totals_from_glm.rds"</span></span>
<span id="cb40-17"><a href="#cb40-17"></a>)</span>
<span id="cb40-18"><a href="#cb40-18"></a></span>
<span id="cb40-19"><a href="#cb40-19"></a><span class="fu">summary</span>(predicted_totals_from_glm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
 9179960 13812465 15097242 15442905 16590660 52011640 </code></pre>
</div>
</div>
<p>Sample statistics for the observed data with exposure <span class="math inline">\(w_i\)</span> can be compared with the statistics from the intercept-only and main-effects GLMs as a form of PPC. Looking at the summary statistics for the main effects model, there are more policies with non-zero claims (266 on average) compared with the PPC from the intercept only model (28 on average), but still very far off from the 3051 that are in the observed data.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1"></a><span class="co"># quick check of sampling dist of statistics</span></span>
<span id="cb42-2"><a href="#cb42-2"></a><span class="co"># ppc_glm_obs_exposure &lt;- map(</span></span>
<span id="cb42-3"><a href="#cb42-3"></a><span class="co">#   .x = 1:1000,</span></span>
<span id="cb42-4"><a href="#cb42-4"></a><span class="co">#   .f = ~ {</span></span>
<span id="cb42-5"><a href="#cb42-5"></a><span class="co">#     if(.x %% 50 == 0) {</span></span>
<span id="cb42-6"><a href="#cb42-6"></a><span class="co">#       print(.x)</span></span>
<span id="cb42-7"><a href="#cb42-7"></a><span class="co">#     }</span></span>
<span id="cb42-8"><a href="#cb42-8"></a><span class="co">#     set.seed(.x)</span></span>
<span id="cb42-9"><a href="#cb42-9"></a><span class="co">#     draw &lt;- (fitted_values$Exposure *</span></span>
<span id="cb42-10"><a href="#cb42-10"></a><span class="co">#                tweedie::rtweedie(60000,</span></span>
<span id="cb42-11"><a href="#cb42-11"></a><span class="co">#                                  mu = fitted_values$.fitted,</span></span>
<span id="cb42-12"><a href="#cb42-12"></a><span class="co">#                                  phi = phi_glm, power = 1.6))</span></span>
<span id="cb42-13"><a href="#cb42-13"></a><span class="co">#</span></span>
<span id="cb42-14"><a href="#cb42-14"></a><span class="co">#     tibble(prop_zero = mean(draw == 0), sample_total = sum(draw),</span></span>
<span id="cb42-15"><a href="#cb42-15"></a><span class="co">#            sample_max = max(draw), n_nonzero = sum(draw &gt; 0))</span></span>
<span id="cb42-16"><a href="#cb42-16"></a><span class="co">#   }) %&gt;%</span></span>
<span id="cb42-17"><a href="#cb42-17"></a><span class="co">#   list_rbind()</span></span>
<span id="cb42-18"><a href="#cb42-18"></a><span class="co">#</span></span>
<span id="cb42-19"><a href="#cb42-19"></a><span class="co"># saveRDS(ppc_glm_obs_exposure, file = "ppc_glm_obs_exposure.rds")</span></span>
<span id="cb42-20"><a href="#cb42-20"></a></span>
<span id="cb42-21"><a href="#cb42-21"></a>ppc_glm_obs_exposure <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="at">file =</span> <span class="st">"ppc_glm_obs_exposure.rds"</span>)</span>
<span id="cb42-22"><a href="#cb42-22"></a></span>
<span id="cb42-23"><a href="#cb42-23"></a><span class="co"># function to convert the output of summary.data.frame() to a tibble</span></span>
<span id="cb42-24"><a href="#cb42-24"></a>tidy_df_summary <span class="ot">&lt;-</span> <span class="cf">function</span>(data) {</span>
<span id="cb42-25"><a href="#cb42-25"></a>  data <span class="sc">%&gt;%</span></span>
<span id="cb42-26"><a href="#cb42-26"></a>    <span class="fu">summary</span>() <span class="sc">%&gt;%</span></span>
<span id="cb42-27"><a href="#cb42-27"></a>    <span class="fu">as.data.frame</span>() <span class="sc">%&gt;%</span></span>
<span id="cb42-28"><a href="#cb42-28"></a>    <span class="fu">separate</span>(<span class="at">col =</span> Freq, <span class="at">into =</span> <span class="fu">c</span>(<span class="st">"Statistic"</span>, <span class="st">"Value"</span>), <span class="at">sep =</span> <span class="st">":"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb42-29"><a href="#cb42-29"></a>    <span class="fu">select</span>(<span class="sc">-</span>Var1) <span class="sc">%&gt;%</span></span>
<span id="cb42-30"><a href="#cb42-30"></a>    <span class="fu">rename</span>(<span class="at">Column =</span> Var2) <span class="sc">%&gt;%</span></span>
<span id="cb42-31"><a href="#cb42-31"></a>    <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> Statistic, <span class="at">values_from =</span> Value) <span class="sc">%&gt;%</span></span>
<span id="cb42-32"><a href="#cb42-32"></a>    <span class="fu">mutate</span>(</span>
<span id="cb42-33"><a href="#cb42-33"></a>      <span class="at">Column =</span> <span class="fu">str_trim</span>(Column, <span class="at">side =</span> <span class="st">"left"</span>),</span>
<span id="cb42-34"><a href="#cb42-34"></a>      <span class="fu">across</span>(</span>
<span id="cb42-35"><a href="#cb42-35"></a>        <span class="at">.cols =</span> <span class="fu">where</span>(is.character),</span>
<span id="cb42-36"><a href="#cb42-36"></a>        <span class="at">.fns =</span> <span class="sc">~</span> <span class="fu">str_trim</span>(.x, <span class="at">side =</span> <span class="st">"both"</span>)</span>
<span id="cb42-37"><a href="#cb42-37"></a>      )</span>
<span id="cb42-38"><a href="#cb42-38"></a>    )</span>
<span id="cb42-39"><a href="#cb42-39"></a>}</span>
<span id="cb42-40"><a href="#cb42-40"></a></span>
<span id="cb42-41"><a href="#cb42-41"></a><span class="fu">list</span>(</span>
<span id="cb42-42"><a href="#cb42-42"></a>  <span class="st">"Intercept"</span> <span class="ot">=</span> ppc_obs_exposure,</span>
<span id="cb42-43"><a href="#cb42-43"></a>  <span class="st">"Main effects"</span> <span class="ot">=</span> ppc_glm_obs_exposure,</span>
<span id="cb42-44"><a href="#cb42-44"></a>  <span class="st">"Observed"</span> <span class="ot">=</span> sample_statistics_obs_exposure</span>
<span id="cb42-45"><a href="#cb42-45"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb42-46"><a href="#cb42-46"></a>  <span class="fu">imap</span>(</span>
<span id="cb42-47"><a href="#cb42-47"></a>    <span class="at">.f =</span> <span class="sc">~</span> {</span>
<span id="cb42-48"><a href="#cb42-48"></a>      .x <span class="sc">%&gt;%</span></span>
<span id="cb42-49"><a href="#cb42-49"></a>        <span class="fu">tidy_df_summary</span>() <span class="sc">%&gt;%</span></span>
<span id="cb42-50"><a href="#cb42-50"></a>        <span class="fu">mutate</span>(<span class="at">Method =</span> .y, <span class="at">.before =</span> <span class="dv">1</span>)</span>
<span id="cb42-51"><a href="#cb42-51"></a>    }</span>
<span id="cb42-52"><a href="#cb42-52"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb42-53"><a href="#cb42-53"></a>  <span class="fu">list_rbind</span>() <span class="sc">%&gt;%</span></span>
<span id="cb42-54"><a href="#cb42-54"></a>  <span class="fu">mutate</span>(</span>
<span id="cb42-55"><a href="#cb42-55"></a>    <span class="at">Method =</span> <span class="fu">factor</span>(Method, </span>
<span id="cb42-56"><a href="#cb42-56"></a>                    <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"Observed"</span>, <span class="st">"Intercept"</span>, <span class="st">"Main effects"</span>))</span>
<span id="cb42-57"><a href="#cb42-57"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb42-58"><a href="#cb42-58"></a>  <span class="fu">arrange</span>(Column, Method) <span class="sc">%&gt;%</span> </span>
<span id="cb42-59"><a href="#cb42-59"></a>  <span class="fu">relocate</span>(Column, <span class="at">.before =</span> Method) <span class="sc">%&gt;%</span> </span>
<span id="cb42-60"><a href="#cb42-60"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<colgroup>
<col style="width: 17%">
<col style="width: 17%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Column</th>
<th style="text-align: left;">Method</th>
<th style="text-align: left;">Min.</th>
<th style="text-align: left;">1st Qu.</th>
<th style="text-align: left;">Median</th>
<th style="text-align: left;">Mean</th>
<th style="text-align: left;">3rd Qu.</th>
<th style="text-align: left;">Max.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">n_nonzero</td>
<td style="text-align: left;">Observed</td>
<td style="text-align: left;">3051</td>
<td style="text-align: left;">3051</td>
<td style="text-align: left;">3051</td>
<td style="text-align: left;">3051</td>
<td style="text-align: left;">3051</td>
<td style="text-align: left;">3051</td>
</tr>
<tr class="even">
<td style="text-align: left;">n_nonzero</td>
<td style="text-align: left;">Intercept</td>
<td style="text-align: left;">12.00</td>
<td style="text-align: left;">25.00</td>
<td style="text-align: left;">28.00</td>
<td style="text-align: left;">28.61</td>
<td style="text-align: left;">32.00</td>
<td style="text-align: left;">50.00</td>
</tr>
<tr class="odd">
<td style="text-align: left;">n_nonzero</td>
<td style="text-align: left;">Main effects</td>
<td style="text-align: left;">218.0</td>
<td style="text-align: left;">255.8</td>
<td style="text-align: left;">265.0</td>
<td style="text-align: left;">266.1</td>
<td style="text-align: left;">277.0</td>
<td style="text-align: left;">312.0</td>
</tr>
<tr class="even">
<td style="text-align: left;">prop_zero</td>
<td style="text-align: left;">Observed</td>
<td style="text-align: left;">0.9492</td>
<td style="text-align: left;">0.9492</td>
<td style="text-align: left;">0.9492</td>
<td style="text-align: left;">0.9492</td>
<td style="text-align: left;">0.9492</td>
<td style="text-align: left;">0.9492</td>
</tr>
<tr class="odd">
<td style="text-align: left;">prop_zero</td>
<td style="text-align: left;">Intercept</td>
<td style="text-align: left;">0.9992</td>
<td style="text-align: left;">0.9995</td>
<td style="text-align: left;">0.9995</td>
<td style="text-align: left;">0.9995</td>
<td style="text-align: left;">0.9996</td>
<td style="text-align: left;">0.9998</td>
</tr>
<tr class="even">
<td style="text-align: left;">prop_zero</td>
<td style="text-align: left;">Main effects</td>
<td style="text-align: left;">0.9948</td>
<td style="text-align: left;">0.9954</td>
<td style="text-align: left;">0.9956</td>
<td style="text-align: left;">0.9956</td>
<td style="text-align: left;">0.9957</td>
<td style="text-align: left;">0.9964</td>
</tr>
<tr class="odd">
<td style="text-align: left;">sample_max</td>
<td style="text-align: left;">Observed</td>
<td style="text-align: left;">1404186</td>
<td style="text-align: left;">1404186</td>
<td style="text-align: left;">1404186</td>
<td style="text-align: left;">1404186</td>
<td style="text-align: left;">1404186</td>
<td style="text-align: left;">1404186</td>
</tr>
<tr class="even">
<td style="text-align: left;">sample_max</td>
<td style="text-align: left;">Intercept</td>
<td style="text-align: left;">265332</td>
<td style="text-align: left;">918290</td>
<td style="text-align: left;">1172482</td>
<td style="text-align: left;">1248649</td>
<td style="text-align: left;">1486689</td>
<td style="text-align: left;">4658137</td>
</tr>
<tr class="odd">
<td style="text-align: left;">sample_max</td>
<td style="text-align: left;">Main effects</td>
<td style="text-align: left;">165327</td>
<td style="text-align: left;">348857</td>
<td style="text-align: left;">479910</td>
<td style="text-align: left;">633731</td>
<td style="text-align: left;">693709</td>
<td style="text-align: left;">4569095</td>
</tr>
<tr class="even">
<td style="text-align: left;">sample_total</td>
<td style="text-align: left;">Observed</td>
<td style="text-align: left;">7507466</td>
<td style="text-align: left;">7507466</td>
<td style="text-align: left;">7507466</td>
<td style="text-align: left;">7507466</td>
<td style="text-align: left;">7507466</td>
<td style="text-align: left;">7507466</td>
</tr>
<tr class="odd">
<td style="text-align: left;">sample_total</td>
<td style="text-align: left;">Intercept</td>
<td style="text-align: left;">1515008</td>
<td style="text-align: left;">5966878</td>
<td style="text-align: left;">7341226</td>
<td style="text-align: left;">7506283</td>
<td style="text-align: left;">8903769</td>
<td style="text-align: left;">17569471</td>
</tr>
<tr class="even">
<td style="text-align: left;">sample_total</td>
<td style="text-align: left;">Main effects</td>
<td style="text-align: left;">4374107</td>
<td style="text-align: left;">6851961</td>
<td style="text-align: left;">7530698</td>
<td style="text-align: left;">7630616</td>
<td style="text-align: left;">8274916</td>
<td style="text-align: left;">12929669</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>The maximum claim amounts are much smaller — mean of 633k vs 1.4 mil in the observed data and 1.24 mil on average from the intercept-only PPC model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1"></a><span class="fu">list</span>(</span>
<span id="cb43-2"><a href="#cb43-2"></a>  <span class="st">"Intercept"</span> <span class="ot">=</span> ppc_obs_exposure, </span>
<span id="cb43-3"><a href="#cb43-3"></a>  <span class="st">"Main effects"</span> <span class="ot">=</span> ppc_glm_obs_exposure</span>
<span id="cb43-4"><a href="#cb43-4"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb43-5"><a href="#cb43-5"></a>  <span class="fu">map</span>(<span class="at">.f =</span> <span class="sc">~</span> {</span>
<span id="cb43-6"><a href="#cb43-6"></a>    .x <span class="sc">%&gt;%</span></span>
<span id="cb43-7"><a href="#cb43-7"></a>      <span class="fu">mutate</span>(<span class="at">sample_gt_obs_max =</span> sample_max <span class="sc">&lt;=</span> <span class="fl">1404185.52</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb43-8"><a href="#cb43-8"></a>      <span class="fu">pull</span>(sample_gt_obs_max) <span class="sc">%&gt;%</span></span>
<span id="cb43-9"><a href="#cb43-9"></a>      <span class="fu">mean</span>()</span>
<span id="cb43-10"><a href="#cb43-10"></a>  })</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$Intercept
[1] 0.6975

$`Main effects`
[1] 0.94</code></pre>
</div>
</div>
<p>For the intercept-only GLM, the observed maximum is larger than 70% of the maxima from the sampled datasets, compared to 94% of the maxima from the sampled datasets using the fitted values from the main effects GLM. In an ideal scenario, this should be about 50%.</p>
<p>The sample totals are all within about +/- 150k of each other.</p>
<p>Ten datasets are simulated, and only the policies with non-zero claim amounts are retained. The eCDF for each of these datasets are visually compared with the observed data. Since the model predicts a larger number of policies with non-zero claims, the distribution functions are smoother, and these functions are closer to the function for the observed sample (but still a very poor fit for the observed data).</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1"></a><span class="fu">map</span>(</span>
<span id="cb45-2"><a href="#cb45-2"></a>  <span class="at">.x =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,</span>
<span id="cb45-3"><a href="#cb45-3"></a>  <span class="at">.f =</span> <span class="sc">~</span> {</span>
<span id="cb45-4"><a href="#cb45-4"></a>    <span class="fu">set.seed</span>(.x)</span>
<span id="cb45-5"><a href="#cb45-5"></a>    draw <span class="ot">&lt;-</span> (fitted_values<span class="sc">$</span>Exposure <span class="sc">*</span></span>
<span id="cb45-6"><a href="#cb45-6"></a>               tweedie<span class="sc">::</span><span class="fu">rtweedie</span>(<span class="dv">60000</span>,</span>
<span id="cb45-7"><a href="#cb45-7"></a>                                 <span class="at">mu =</span> fitted_values<span class="sc">$</span>.fitted,</span>
<span id="cb45-8"><a href="#cb45-8"></a>                                 <span class="at">phi =</span> phi_glm, <span class="at">power =</span> <span class="fl">1.6</span>))</span>
<span id="cb45-9"><a href="#cb45-9"></a>    <span class="fu">tibble</span>(<span class="at">sim_id =</span> .x, <span class="at">y =</span> draw, <span class="at">grp =</span> <span class="st">"Simulated"</span>)</span>
<span id="cb45-10"><a href="#cb45-10"></a>  }) <span class="sc">%&gt;%</span></span>
<span id="cb45-11"><a href="#cb45-11"></a>  <span class="fu">list_rbind</span>() <span class="sc">%&gt;%</span></span>
<span id="cb45-12"><a href="#cb45-12"></a>  <span class="fu">bind_rows</span>(</span>
<span id="cb45-13"><a href="#cb45-13"></a>    .,</span>
<span id="cb45-14"><a href="#cb45-14"></a>    claims <span class="sc">%&gt;%</span></span>
<span id="cb45-15"><a href="#cb45-15"></a>      <span class="fu">mutate</span>(<span class="at">sim_id =</span> <span class="dv">100</span>, <span class="at">grp =</span> <span class="st">"Observed"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb45-16"><a href="#cb45-16"></a>      <span class="fu">select</span>(sim_id, <span class="at">y =</span> ClaimAmount, grp)</span>
<span id="cb45-17"><a href="#cb45-17"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb45-18"><a href="#cb45-18"></a>  <span class="fu">filter</span>(y <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb45-19"><a href="#cb45-19"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> y, <span class="at">group =</span> sim_id, <span class="at">color =</span> grp)) <span class="sc">+</span></span>
<span id="cb45-20"><a href="#cb45-20"></a>  <span class="fu">stat_ecdf</span>() <span class="sc">+</span></span>
<span id="cb45-21"><a href="#cb45-21"></a>  <span class="fu">xlab</span>(<span class="st">"Policies with non-zero claim amounts (log10 scale)"</span>) <span class="sc">+</span></span>
<span id="cb45-22"><a href="#cb45-22"></a>  <span class="fu">ylab</span>(<span class="st">"Empirical distribution function"</span>) <span class="sc">+</span></span>
<span id="cb45-23"><a href="#cb45-23"></a>  <span class="fu">scale_x_log10</span>(</span>
<span id="cb45-24"><a href="#cb45-24"></a>    <span class="at">breaks =</span> scales<span class="sc">::</span><span class="fu">trans_breaks</span>(<span class="st">"log10"</span>, <span class="cf">function</span>(x) <span class="dv">10</span><span class="sc">^</span>x),</span>
<span id="cb45-25"><a href="#cb45-25"></a>    <span class="at">labels =</span> scales<span class="sc">::</span><span class="fu">trans_format</span>(<span class="st">"log10"</span>, scales<span class="sc">::</span><span class="fu">math_format</span>(<span class="dv">10</span><span class="sc">^</span>.x))</span>
<span id="cb45-26"><a href="#cb45-26"></a>  ) <span class="sc">+</span></span>
<span id="cb45-27"><a href="#cb45-27"></a>  <span class="fu">annotation_logticks</span>(<span class="at">sides =</span> <span class="st">"b"</span>) <span class="sc">+</span></span>
<span id="cb45-28"><a href="#cb45-28"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span>percent) <span class="sc">+</span></span>
<span id="cb45-29"><a href="#cb45-29"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb45-30"><a href="#cb45-30"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Simulated"</span> <span class="ot">=</span> <span class="st">"gray70"</span>, <span class="st">"Observed"</span> <span class="ot">=</span> <span class="st">"Black"</span>)</span>
<span id="cb45-31"><a href="#cb45-31"></a>  ) <span class="sc">+</span></span>
<span id="cb45-32"><a href="#cb45-32"></a>  <span class="fu">theme</span>(</span>
<span id="cb45-33"><a href="#cb45-33"></a>    <span class="at">legend.title =</span> <span class="fu">element_blank</span>(), </span>
<span id="cb45-34"><a href="#cb45-34"></a>    <span class="at">legend.position =</span> <span class="st">"inside"</span>,</span>
<span id="cb45-35"><a href="#cb45-35"></a>    <span class="at">legend.position.inside =</span> <span class="fu">c</span>(<span class="fl">0.9</span>, <span class="fl">0.2</span>)</span>
<span id="cb45-36"><a href="#cb45-36"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-28-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="all-the-distributions-together" class="level2">
<h2 class="anchored" data-anchor-id="all-the-distributions-together">All the distributions together</h2>
<p>Finally, all the different estimates for the distribution of next year’s total claim amounts can be visualized together. First, the eCDFs are plotted together</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1"></a>distributions_of_total_claims <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(</span>
<span id="cb46-2"><a href="#cb46-2"></a>  <span class="fu">tibble</span>(</span>
<span id="cb46-3"><a href="#cb46-3"></a>    <span class="at">method =</span> <span class="st">"Parametric Bootstrap (Tweedie MLE)"</span>,</span>
<span id="cb46-4"><a href="#cb46-4"></a>    <span class="at">total_claim_amount_in_millions =</span> predicted_totals_for_unit_exposure</span>
<span id="cb46-5"><a href="#cb46-5"></a>  ),</span>
<span id="cb46-6"><a href="#cb46-6"></a>  <span class="fu">tibble</span>(</span>
<span id="cb46-7"><a href="#cb46-7"></a>    <span class="at">method =</span> <span class="st">"Nonparametric Bootstrap (Tweedie GLM)"</span>,</span>
<span id="cb46-8"><a href="#cb46-8"></a>    <span class="at">total_claim_amount_in_millions =</span> posterior_distribution_samples_for_total_claims<span class="sc">$</span>total</span>
<span id="cb46-9"><a href="#cb46-9"></a>  ),</span>
<span id="cb46-10"><a href="#cb46-10"></a>  <span class="fu">tibble</span>(</span>
<span id="cb46-11"><a href="#cb46-11"></a>    <span class="at">method =</span> <span class="st">"Closed-form Tweedie Distribution for Weighted Mean"</span>,</span>
<span id="cb46-12"><a href="#cb46-12"></a>    <span class="at">total_claim_amount_in_millions =</span> predicted_totals_tweedie_sampling_dist</span>
<span id="cb46-13"><a href="#cb46-13"></a>  ),</span>
<span id="cb46-14"><a href="#cb46-14"></a>  <span class="fu">tibble</span>(</span>
<span id="cb46-15"><a href="#cb46-15"></a>    <span class="at">method =</span> <span class="st">"Main Effects Tweedie GLM"</span>,</span>
<span id="cb46-16"><a href="#cb46-16"></a>    <span class="at">total_claim_amount_in_millions =</span> predicted_totals_from_glm</span>
<span id="cb46-17"><a href="#cb46-17"></a>  )</span>
<span id="cb46-18"><a href="#cb46-18"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb46-19"><a href="#cb46-19"></a>  <span class="fu">mutate</span>(</span>
<span id="cb46-20"><a href="#cb46-20"></a>    <span class="at">total_claim_amount_in_millions =</span> total_claim_amount_in_millions <span class="sc">/</span> <span class="fl">1e6</span></span>
<span id="cb46-21"><a href="#cb46-21"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb46-22"><a href="#cb46-22"></a>  <span class="fu">bind_rows</span>(nonparametric_bootstrap_totals, .)</span>
<span id="cb46-23"><a href="#cb46-23"></a></span>
<span id="cb46-24"><a href="#cb46-24"></a><span class="co"># order the methods by increasing values of the ranges</span></span>
<span id="cb46-25"><a href="#cb46-25"></a>method_order <span class="ot">&lt;-</span> distributions_of_total_claims <span class="sc">%&gt;%</span></span>
<span id="cb46-26"><a href="#cb46-26"></a>  <span class="fu">group_by</span>(method) <span class="sc">%&gt;%</span></span>
<span id="cb46-27"><a href="#cb46-27"></a>  <span class="fu">summarise</span>(<span class="at">range =</span> <span class="fu">diff</span>(<span class="fu">range</span>(total_claim_amount_in_millions))) <span class="sc">%&gt;%</span></span>
<span id="cb46-28"><a href="#cb46-28"></a>  <span class="fu">arrange</span>(range) <span class="sc">%&gt;%</span></span>
<span id="cb46-29"><a href="#cb46-29"></a>  <span class="co">#print() %&gt;%</span></span>
<span id="cb46-30"><a href="#cb46-30"></a>  <span class="fu">pull</span>(method)</span>
<span id="cb46-31"><a href="#cb46-31"></a></span>
<span id="cb46-32"><a href="#cb46-32"></a>distributions_of_total_claims <span class="ot">&lt;-</span> distributions_of_total_claims <span class="sc">%&gt;%</span> </span>
<span id="cb46-33"><a href="#cb46-33"></a>  <span class="fu">mutate</span>(</span>
<span id="cb46-34"><a href="#cb46-34"></a>    <span class="at">method =</span> <span class="fu">factor</span>(method, <span class="at">levels =</span> method_order)</span>
<span id="cb46-35"><a href="#cb46-35"></a>  )</span>
<span id="cb46-36"><a href="#cb46-36"></a></span>
<span id="cb46-37"><a href="#cb46-37"></a>totals_plot <span class="ot">&lt;-</span> distributions_of_total_claims <span class="sc">%&gt;%</span></span>
<span id="cb46-38"><a href="#cb46-38"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb46-39"><a href="#cb46-39"></a>  <span class="fu">stat_ecdf</span>(<span class="fu">aes</span>(<span class="at">x =</span> total_claim_amount_in_millions,</span>
<span id="cb46-40"><a href="#cb46-40"></a>                <span class="at">linetype =</span> method, <span class="at">group =</span> method), <span class="at">pad =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb46-41"><a href="#cb46-41"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> (<span class="fl">6e4</span> <span class="sc">*</span> expected_claim_amount) <span class="sc">/</span> <span class="fl">1e6</span>,</span>
<span id="cb46-42"><a href="#cb46-42"></a>             <span class="at">color =</span> <span class="st">"orange"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb46-43"><a href="#cb46-43"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span><span class="fu">label_percent</span>()) <span class="sc">+</span></span>
<span id="cb46-44"><a href="#cb46-44"></a>  <span class="fu">xlab</span>(glue<span class="sc">::</span><span class="fu">glue</span>(<span class="st">"Plausible values for the following "</span>, </span>
<span id="cb46-45"><a href="#cb46-45"></a>                  <span class="st">"year's total claim amount in millions, "</span>, </span>
<span id="cb46-46"><a href="#cb46-46"></a>                  <span class="st">"assuming unit exposure"</span>, </span>
<span id="cb46-47"><a href="#cb46-47"></a>                  <span class="st">"</span><span class="sc">\n</span><span class="st">(Estimate from the full sample in orange)"</span>,</span>
<span id="cb46-48"><a href="#cb46-48"></a>                  <span class="st">"</span><span class="sc">\n</span><span class="st">(Mean of each distribution in black)"</span>)) <span class="sc">+</span></span>
<span id="cb46-49"><a href="#cb46-49"></a>  <span class="fu">ylab</span>(<span class="st">"Empirical distribution function"</span>)<span class="sc">+</span></span>
<span id="cb46-50"><a href="#cb46-50"></a>  <span class="fu">theme</span>(</span>
<span id="cb46-51"><a href="#cb46-51"></a>    <span class="at">legend.position =</span> <span class="st">"bottom"</span>,</span>
<span id="cb46-52"><a href="#cb46-52"></a>    <span class="at">legend.title =</span> <span class="fu">element_blank</span>()</span>
<span id="cb46-53"><a href="#cb46-53"></a>  )</span>
<span id="cb46-54"><a href="#cb46-54"></a></span>
<span id="cb46-55"><a href="#cb46-55"></a>totals_plot <span class="sc">+</span> </span>
<span id="cb46-56"><a href="#cb46-56"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">3</span>, <span class="dv">54</span>, <span class="dv">3</span>)) <span class="sc">+</span> </span>
<span id="cb46-57"><a href="#cb46-57"></a>  <span class="fu">guides</span>(<span class="at">linetype =</span> <span class="fu">guide_legend</span>(<span class="at">nrow =</span> <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-29-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>and then plotted separately as well, with the expected total (217.8 x 60,000) in orange and the mean of the totals for each method overlaid as a black vertical line</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1"></a>totals_plot <span class="sc">+</span></span>
<span id="cb47-2"><a href="#cb47-2"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span><span class="fu">factor</span>(method, <span class="at">levels =</span> method_order), <span class="at">ncol =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb47-3"><a href="#cb47-3"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>) <span class="sc">+</span></span>
<span id="cb47-4"><a href="#cb47-4"></a>  <span class="fu">geom_vline</span>(</span>
<span id="cb47-5"><a href="#cb47-5"></a>    <span class="at">data =</span> distributions_of_total_claims <span class="sc">%&gt;%</span></span>
<span id="cb47-6"><a href="#cb47-6"></a>      <span class="fu">summarize</span>(<span class="at">m =</span> <span class="fu">mean</span>(total_claim_amount_in_millions), <span class="at">.by =</span> <span class="st">"method"</span>),</span>
<span id="cb47-7"><a href="#cb47-7"></a>    <span class="fu">aes</span>(<span class="at">xintercept =</span> m, <span class="at">group =</span> method, <span class="at">linetype =</span> method)</span>
<span id="cb47-8"><a href="#cb47-8"></a>  ) <span class="sc">+</span></span>
<span id="cb47-9"><a href="#cb47-9"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">3</span>, <span class="dv">54</span>, <span class="dv">6</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-30-1.png" class="img-fluid figure-img" width="1050"></p>
</figure>
</div>
</div>
</div>
<p>If every policy is to have the same premium, then the closed-form Tweedie distribution or the joint bootstrap distribution <span class="math inline">\((\hat\mu_{\text{int}, b}, \hat\phi_{\text{int}, b})_{b = 1}^{10,000}\)</span> can be used for simulating plausible values for the following year’s total claim amounts.</p>
<p>For setting premiums at the policy level, plausible values for next year’s claim amount for a specific policy can be sampled using the fitted means <span class="math inline">\(\hat\mu_i\)</span> from the main-effects GLM.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<p>I’ve skimmed (parts of some of) these references, but I’m including all the ones I encountered in case I need to come back to them in the future.</p>
<section id="auto-claims-data" class="level3">
<h3 class="anchored" data-anchor-id="auto-claims-data">Auto Claims Data</h3>
<ul>
<li><p><a href="https://dutangc.github.io/CASdatasets/reference/freMTPL.html" class="uri">CASdatasets - freMTPL</a></p></li>
<li><p>Noll, Alexander and Salzmann, Robert and Wuthrich, Mario V., Case Study: French Motor Third-Party Liability Claims (March 4, 2020). Available at SSRN: <a href="https://ssrn.com/abstract=3164764" class="uri">https://ssrn.com/abstract=3164764</a> or <a href="https://dx.doi.org/10.2139/ssrn.3164764">http://dx.doi.org/10.2139/ssrn.3164764</a></p></li>
</ul>
</section>
<section id="bootstrapping" class="level3">
<h3 class="anchored" data-anchor-id="bootstrapping">Bootstrapping</h3>
<ul>
<li><p><a href="https://stats.stackexchange.com/questions/63999/how-to-interpret-multimodal-distribution-of-bootstrapped-correlation">Cross Validated - how to interpret multimodal distribution of bootstrapped correlation</a></p></li>
<li><p><a href="https://stats.stackexchange.com/questions/181350/bootstrapping-vs-bayesian-bootstrapping-conceptually" class="uri">Cross Validated - bootstrapping vs bayesian bootstrapping conceptually</a></p></li>
<li><p><a href="https://mc-stan.org/docs/stan-users-guide/posterior-predictive-checks.html" class="uri">https://mc-stan.org/docs/stan-users-guide/posterior-predictive-checks.html</a></p></li>
<li><p><a href="https://stats.stackexchange.com/questions/475631/difference-between-sampling-a-population-vs-bootstrapping" class="uri">Cross Validated - difference between sampling a population vs bootstrapping</a></p></li>
<li><p><a href="https://www.sumsar.net/blog/2015/04/the-non-parametric-bootstrap-as-a-bayesian-model/" class="uri">https://www.sumsar.net/blog/2015/04/the-non-parametric-bootstrap-as-a-bayesian-model/</a></p></li>
<li><p><a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)" class="uri">Bootstrapping - Wikipedia</a></p></li>
</ul>
</section>
<section id="tweedie-models-1" class="level3">
<h3 class="anchored" data-anchor-id="tweedie-models-1">Tweedie Models</h3>
<ul>
<li><p>Denuit, Michel, Arthur Charpentier, and Julien Trufin. “Autocalibration and Tweedie-dominance for insurance pricing with machine learning.” <em>Insurance: Mathematics and Economics</em> 101 (2021): 485-497. ArXiv link - <a href="https://arxiv.org/abs/2103.03635" class="uri">https://arxiv.org/abs/2103.03635</a></p>
<ul>
<li>This paper is for calibrating boosted tree models fit by minimizing deviance instead of maximizing likelihood</li>
</ul></li>
<li><p>Yang, Yi, Wei Qian, and Hui Zou. “Insurance premium prediction via gradient tree-boosted Tweedie compound Poisson models.” <em>Journal of Business &amp; Economic Statistics</em> 36.3 (2018): 456-470. ArXiv link - <a href="https://arxiv.org/abs/1508.06378" class="uri">https://arxiv.org/abs/1508.06378</a></p></li>
<li><p>Delong, Ł., Lindholm, M. &amp; Wüthrich, M.V. Making Tweedie’s compound Poisson model more accessible. <em>Eur. Actuar. J.</em> <strong>11</strong>, 185–226 (2021). https://doi.org/10.1007/s13385-021-00264-3</p></li>
<li><p>Zhang, Y. Likelihood-based and Bayesian methods for Tweedie compound Poisson linear mixed models. <em>Stat Comput</em> <strong>23</strong>, 743–757 (2013). https://doi.org/10.1007/s11222-012-9343-7</p></li>
<li><p><a href="https://www.casact.org/sites/default/files/old/affiliates_bace_0419_loss_cost_modeling.pdf">These slides</a> comparing Tweedie vs Quasi-Poisson models</p></li>
<li><p><a href="https://lorentzen.ch/index.php/2024/06/03/a-tweedie-trilogy-part-i-frequency-and-aggregration-invariance/" class="uri">https://lorentzen.ch/index.php/2024/06/03/a-tweedie-trilogy-part-i-frequency-and-aggregration-invariance/</a></p></li>
<li><p><a href="https://lorentzen.ch/index.php/2024/06/10/a-tweedie-trilogy-part-ii-offsets/" class="uri">https://lorentzen.ch/index.php/2024/06/10/a-tweedie-trilogy-part-ii-offsets/</a></p></li>
<li><p><a href="https://en.wikipedia.org/wiki/Tweedie_distribution" class="uri">Tweedie distribution - Wikipedia</a></p></li>
<li><p><a href="https://en.wikipedia.org/wiki/Exponential_dispersion_model">Exponential dispersion model - Wikipedia</a></p></li>
</ul>
</section>
<section id="books" class="level3">
<h3 class="anchored" data-anchor-id="books">Books</h3>
<ul>
<li><p>Dunn, Peter K., and Gordon K. Smyth. <em>Generalized linear models with examples in R</em>. Vol. 53. New York: Springer, 2018.</p></li>
<li><p>Davison, Anthony Christopher, and David Victor Hinkley. <em>Bootstrap methods and their application</em>. No.&nbsp;1. Cambridge university press, 1997.</p></li>
<li><p>Kaas, R. <em>Modern Actuarial Risk Theory</em>. Springer, 2008.</p></li>
<li><p>Ohlsson, Esbjörn, and Björn Johansson. <em>Non-life insurance pricing with generalized linear models</em>. Vol. 174. Berlin: Springer, 2010.</p></li>
<li><p>Klugman, Stuart A., Harry H. Panjer, and Gordon E. Willmot. <em>Loss models: from data to decisions</em>. Vol. 715. John Wiley &amp; Sons, 2012.</p></li>
</ul>
</section>
</section>
<section id="appendix-claims-data" class="level2">
<h2 class="anchored" data-anchor-id="appendix-claims-data">Appendix: Claims Data</h2>
<p>The data I’m using for most of this post — except for the last section — is a subset of 60,000 policies from the full claims dataset, which contains about 680,000 policies. The full data here is the version from OpenML (<a href="https://www.openml.org/d/41214">frequency</a>, <a href="https://www.openml.org/d/41215">severity</a>), and information on this dataset can be found in the <a href="https://dutangc.github.io/CASdatasets/reference/freMTPL.html">documentation</a> for the R package <code>CASdatasets</code>, where it’s called <code>freMTPL2freq</code> (frequency) and <code>freMTPL2sev</code> (severity). For reasons I haven’t figured out, the number of rows differ very slightly between these two datasets. The R script I used for combining the full dataset can be found <a href="https://github.com/ad1729/ad1729.github.io/tree/master/posts/fitting-tweedie-models-to-claims-data/process_claims_data.R">here</a>.</p>
<p>An exploratory data analysis on the full dataset can be found in <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3164764">this paper</a>.</p>


<!-- -->

</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/akshat\.blog");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="ad1729/ad1729.github.io" data-repo-id="R_kgDOHvxVCQ" data-category="Announcements" data-category-id="DIC_kwDOHvxVCc4CdwZG" data-mapping="title" data-reactions-enabled="0" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark_dimmed"><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb48" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb48-1"><a href="#cb48-1"></a><span class="co">---</span></span>
<span id="cb48-2"><a href="#cb48-2"></a><span class="an">title:</span><span class="co"> "Sampling from the poor man's posterior distribution of parameters from models fitted to claims data"</span></span>
<span id="cb48-3"><a href="#cb48-3"></a><span class="an">date:</span><span class="co"> "2025-01-05"</span></span>
<span id="cb48-4"><a href="#cb48-4"></a><span class="an">date-modified:</span><span class="co"> "2025-01-06"</span></span>
<span id="cb48-5"><a href="#cb48-5"></a><span class="an">categories:</span><span class="co"> [Bayesian, Bootstrap, Insurance, R, Tweedie]</span></span>
<span id="cb48-6"><a href="#cb48-6"></a><span class="an">image:</span><span class="co"> "tweedie_bootstrap_plot.png"</span></span>
<span id="cb48-7"><a href="#cb48-7"></a><span class="an">code-fold:</span><span class="co"> true</span></span>
<span id="cb48-8"><a href="#cb48-8"></a><span class="co">---</span></span>
<span id="cb48-9"><a href="#cb48-9"></a></span>
<span id="cb48-10"><a href="#cb48-10"></a>This post is about fitting a handful of different models to a subset of a popular car-insurance claims data available online. Plausible future data values can be simulated from the fitted models and used for downstream tasks. Simulated values from the fitted models can also be compared with the actual observed data as a sanity check.</span>
<span id="cb48-11"><a href="#cb48-11"></a></span>
<span id="cb48-12"><a href="#cb48-12"></a>I've never worked in the field of insurance, but I've been wanting to dive into Tweedie models for a while, since non-negative (response) variables with lots of zeroes and positive skew are pretty common and show up in many diverse disciplines such across the social sciences, insurance, biology, etc.</span>
<span id="cb48-13"><a href="#cb48-13"></a></span>
<span id="cb48-14"><a href="#cb48-14"></a>What piqued my interest in insurance data is that the response variable can additionally have very large "outliers". In other fields, outliers resulting from corrupted data or measurement errors can be discarded from the analysis, or robust estimators / loss functions can be used for modelling. However, in such settings, it may not necessarily make sense to discard such values because they likely represent the true cost of damages from accidents<span class="ot">[^1]</span> — which an insurer may be on the hook for.</span>
<span id="cb48-15"><a href="#cb48-15"></a></span>
<span id="cb48-16"><a href="#cb48-16"></a><span class="ot">[^1]: </span>"Well actually, ..." - some actuary probably</span>
<span id="cb48-17"><a href="#cb48-17"></a></span>
<span id="cb48-18"><a href="#cb48-18"></a>This is also a bit of an unusual post in the sense that I'm using ideas I've encountered in Bayesian statistics but with frequentist methods. Sure, I could just fit Bayesian models, but that's not the point here. To wrap my head around the ideas utilized in this post, I'm keeping things relatively simple by eschewing more complex predictive models like (my favourite) boosted trees, and using a single model for the data instead of *hurdle* models that split the response variable into a zero and a non-zero part and model them separately.</span>
<span id="cb48-19"><a href="#cb48-19"></a></span>
<span id="cb48-20"><a href="#cb48-20"></a>Before going further, I'm going to load some packages and the claims data used for this post.</span>
<span id="cb48-21"><a href="#cb48-21"></a></span>
<span id="cb48-24"><a href="#cb48-24"></a><span class="in">```{r}</span></span>
<span id="cb48-25"><a href="#cb48-25"></a><span class="co">#| code-fold: false</span></span>
<span id="cb48-26"><a href="#cb48-26"></a></span>
<span id="cb48-27"><a href="#cb48-27"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb48-28"><a href="#cb48-28"></a><span class="co"># functions from these packages are used via namespace::fun() </span></span>
<span id="cb48-29"><a href="#cb48-29"></a><span class="co"># library(tweedie)</span></span>
<span id="cb48-30"><a href="#cb48-30"></a><span class="co"># library(magrittr, include.only = "%$%") # importing the exposition pipe</span></span>
<span id="cb48-31"><a href="#cb48-31"></a><span class="co"># library(glue)</span></span>
<span id="cb48-32"><a href="#cb48-32"></a><span class="co"># library(scales)</span></span>
<span id="cb48-33"><a href="#cb48-33"></a><span class="co"># library(broom)</span></span>
<span id="cb48-34"><a href="#cb48-34"></a><span class="co"># library(boot)</span></span>
<span id="cb48-35"><a href="#cb48-35"></a><span class="co"># library(ggExtra)</span></span>
<span id="cb48-36"><a href="#cb48-36"></a><span class="co"># library(statmod)</span></span>
<span id="cb48-37"><a href="#cb48-37"></a></span>
<span id="cb48-38"><a href="#cb48-38"></a><span class="fu">theme_set</span>(<span class="fu">theme_bw</span>())</span>
<span id="cb48-39"><a href="#cb48-39"></a></span>
<span id="cb48-40"><a href="#cb48-40"></a>claims <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"claims_subset.csv"</span>, <span class="at">show_col_types =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb48-41"><a href="#cb48-41"></a>  <span class="fu">glimpse</span>()</span>
<span id="cb48-42"><a href="#cb48-42"></a><span class="in">```</span></span>
<span id="cb48-43"><a href="#cb48-43"></a></span>
<span id="cb48-44"><a href="#cb48-44"></a>The most important variables are <span class="in">`IDpol`</span> — which uniquely identifies individual policies (denoted with a subscript $i$), <span class="in">`Exposure`</span> — which indicates the duration (in years) that the policy is in effect (denoted by $w_i$), and <span class="in">`ClaimAmount`</span> — which is the total monetary amount of the claims filed by each policyholder (denoted by $z_i$). Some of the other variables will be later used for building richer models.</span>
<span id="cb48-45"><a href="#cb48-45"></a></span>
<span id="cb48-46"><a href="#cb48-46"></a>Looking at the deciles of the exposure distribution for these 60,000 policies</span>
<span id="cb48-47"><a href="#cb48-47"></a></span>
<span id="cb48-50"><a href="#cb48-50"></a><span class="in">```{r}</span></span>
<span id="cb48-51"><a href="#cb48-51"></a><span class="co">#| code-fold: false</span></span>
<span id="cb48-52"><a href="#cb48-52"></a></span>
<span id="cb48-53"><a href="#cb48-53"></a>claims <span class="sc">%&gt;%</span> </span>
<span id="cb48-54"><a href="#cb48-54"></a>  <span class="fu">pull</span>(Exposure) <span class="sc">%&gt;%</span> </span>
<span id="cb48-55"><a href="#cb48-55"></a>  <span class="fu">quantile</span>(., <span class="at">probs =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb48-56"><a href="#cb48-56"></a>  <span class="fu">as_tibble</span>(<span class="at">rownames =</span> <span class="st">"percentile"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb48-57"><a href="#cb48-57"></a>  <span class="fu">print</span>(<span class="at">n =</span> <span class="cn">Inf</span>)</span>
<span id="cb48-58"><a href="#cb48-58"></a><span class="in">```</span></span>
<span id="cb48-59"><a href="#cb48-59"></a></span>
<span id="cb48-60"><a href="#cb48-60"></a>many of the values are less than one, which means those policies were in effect for less than a year. All of these are non-zero as they should be, but more than 60% have a duration of less than one year. The smallest exposure is for a day, since $1/365 \approx 0.02739$.</span>
<span id="cb48-61"><a href="#cb48-61"></a></span>
<span id="cb48-62"><a href="#cb48-62"></a>Assuming a closed cohort — i.e., all these contracts get renewed the following year and no new contracts are issued — the goal is to predict the total claim amount for each policy for the following year. The distribution of individual claim amounts is highly skewed and has *a lot* of zeroes ($\approx 94\%$), as assessed by some quantiles</span>
<span id="cb48-63"><a href="#cb48-63"></a></span>
<span id="cb48-66"><a href="#cb48-66"></a><span class="in">```{r}</span></span>
<span id="cb48-67"><a href="#cb48-67"></a><span class="co">#| code-fold: false</span></span>
<span id="cb48-68"><a href="#cb48-68"></a></span>
<span id="cb48-69"><a href="#cb48-69"></a>claims <span class="sc">%&gt;%</span> </span>
<span id="cb48-70"><a href="#cb48-70"></a>  <span class="fu">pull</span>(ClaimAmount) <span class="sc">%&gt;%</span> </span>
<span id="cb48-71"><a href="#cb48-71"></a>  <span class="fu">quantile</span>(., <span class="at">probs =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>, <span class="fl">0.94</span>, <span class="fl">0.95</span>, <span class="fl">0.99</span>, <span class="fl">0.999</span>, <span class="fl">1.0</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb48-72"><a href="#cb48-72"></a>  <span class="fu">round</span>()</span>
<span id="cb48-73"><a href="#cb48-73"></a><span class="in">```</span></span>
<span id="cb48-74"><a href="#cb48-74"></a></span>
<span id="cb48-75"><a href="#cb48-75"></a><span class="fu">## The simplest "model"</span></span>
<span id="cb48-76"><a href="#cb48-76"></a></span>
<span id="cb48-77"><a href="#cb48-77"></a>Since I've worked in epidemiology these past few years, a natural quantity (i.e., estimand) similar to incidence rates (i.e., the number of events generated from some population divided by the total follow-up time for individuals with different follow-up durations or periods) seems to be a good starting step. This can be expressed as the sum of the individual claim amounts $z_i$ divided by the sum of policy durations $w_i$, and denoted by the expectation operator $\mathbb{E}$.</span>
<span id="cb48-78"><a href="#cb48-78"></a></span>
<span id="cb48-79"><a href="#cb48-79"></a>$$</span>
<span id="cb48-80"><a href="#cb48-80"></a>\mathbb{E}\big<span class="co">[</span><span class="ot">\text{Claim Amount}_i\big</span><span class="co">]</span> = \frac{\sum_i z_i}{\sum_i w_i}</span>
<span id="cb48-81"><a href="#cb48-81"></a>$$It's a way of equally dividing the total claims generated from some population at risk among the individuals in that population. Each of the individual claim amounts is a random variable, so is expected to vary from person to person, as well as from year to year for the same person.</span>
<span id="cb48-82"><a href="#cb48-82"></a></span>
<span id="cb48-83"><a href="#cb48-83"></a>Taking the regular (arithmetic) mean — which is the same as setting $w_i = 1$ for each individual in the formula above — underestimates the expected claim cost as many individuals are observed for less than a year. It is expected that had they been observed for the full year, their claim amounts would have been larger. A similar argument applies in the case of individuals with $w_i &gt; 1$, although in this case we'd be overestimating instead of underestimating.</span>
<span id="cb48-84"><a href="#cb48-84"></a></span>
<span id="cb48-85"><a href="#cb48-85"></a>For the data above, this comes out to about 125 per person per year assuming $w_i = 1$, and to about 218 per person per year using the observed $w_i$'s.</span>
<span id="cb48-86"><a href="#cb48-86"></a></span>
<span id="cb48-89"><a href="#cb48-89"></a><span class="in">```{r}</span></span>
<span id="cb48-90"><a href="#cb48-90"></a><span class="co">#| code-fold: false</span></span>
<span id="cb48-91"><a href="#cb48-91"></a></span>
<span id="cb48-92"><a href="#cb48-92"></a>claims <span class="sc">%&gt;%</span> </span>
<span id="cb48-93"><a href="#cb48-93"></a>  <span class="fu">summarise</span>(</span>
<span id="cb48-94"><a href="#cb48-94"></a>    <span class="at">total_amount =</span> <span class="fu">sum</span>(ClaimAmount), </span>
<span id="cb48-95"><a href="#cb48-95"></a>    <span class="at">max_claim_amount =</span> <span class="fu">max</span>(ClaimAmount),</span>
<span id="cb48-96"><a href="#cb48-96"></a>    <span class="at">n_policies =</span> <span class="fu">n</span>(), </span>
<span id="cb48-97"><a href="#cb48-97"></a>    <span class="at">person_time =</span> <span class="fu">sum</span>(Exposure), </span>
<span id="cb48-98"><a href="#cb48-98"></a>    <span class="at">mean_person_time =</span> <span class="fu">mean</span>(Exposure)</span>
<span id="cb48-99"><a href="#cb48-99"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb48-100"><a href="#cb48-100"></a>  <span class="fu">mutate</span>(</span>
<span id="cb48-101"><a href="#cb48-101"></a>    <span class="at">mean =</span> total_amount <span class="sc">/</span> n_policies, </span>
<span id="cb48-102"><a href="#cb48-102"></a>    <span class="at">avg_claim_cost =</span> total_amount <span class="sc">/</span> person_time,</span>
<span id="cb48-103"><a href="#cb48-103"></a>    <span class="fu">across</span>(<span class="at">.cols =</span> <span class="fu">everything</span>(), </span>
<span id="cb48-104"><a href="#cb48-104"></a>           <span class="at">.fns =</span> <span class="sc">~</span> <span class="fu">as.character</span>(<span class="fu">round</span>(.x, <span class="dv">4</span>)))</span>
<span id="cb48-105"><a href="#cb48-105"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb48-106"><a href="#cb48-106"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">everything</span>())</span>
<span id="cb48-107"><a href="#cb48-107"></a><span class="in">```</span></span>
<span id="cb48-108"><a href="#cb48-108"></a></span>
<span id="cb48-109"><a href="#cb48-109"></a>So now we have an estimate for the expected claim amount per person per year, even though we can expect most policies to generate zero claims, and a few policies to generate some very large claim amounts based on the observed claims distribution. This expected claim cost estimate will be used again, so it's assigned to a variable here.</span>
<span id="cb48-110"><a href="#cb48-110"></a></span>
<span id="cb48-113"><a href="#cb48-113"></a><span class="in">```{r}</span></span>
<span id="cb48-114"><a href="#cb48-114"></a><span class="co">#| code-fold: false</span></span>
<span id="cb48-115"><a href="#cb48-115"></a></span>
<span id="cb48-116"><a href="#cb48-116"></a>expected_claim_amount <span class="ot">&lt;-</span> <span class="fu">sum</span>(claims<span class="sc">$</span>ClaimAmount) <span class="sc">/</span> <span class="fu">sum</span>(claims<span class="sc">$</span>Exposure)</span>
<span id="cb48-117"><a href="#cb48-117"></a><span class="in">```</span></span>
<span id="cb48-118"><a href="#cb48-118"></a></span>
<span id="cb48-119"><a href="#cb48-119"></a>For an insurance company, they need to ensure they have enough capital reserves to be able to pay out money for these claims, which they're legally liable for. For the current year, the total claim amount across the policies was about 7.5 million, from a population that was on averaged exposed for 0.57 years. The total expected claim amount for this population with each person being observed for a full year is $217.8 \times 60,000$ which comes out to about 13 million.</span>
<span id="cb48-120"><a href="#cb48-120"></a></span>
<span id="cb48-121"><a href="#cb48-121"></a>In this case, the sample of customers constitutes the population of interest so it may not make sense to produce uncertainty estimates for this estimated total amount for the current year. However, the claim amounts can be seen as the result of a stochastic process, so superpopulation inference on this parameter can still make sense since next year's claim amounts may be expected to be similar, but not identical.</span>
<span id="cb48-122"><a href="#cb48-122"></a></span>
<span id="cb48-123"><a href="#cb48-123"></a>This is carried out here using a <span class="co">[</span><span class="ot">weird Bayesian model</span><span class="co">](https://www.sumsar.net/blog/2015/04/the-non-parametric-bootstrap-as-a-bayesian-model/)</span> (a.k.a. the nonparametric bootstrap). The following code chunk generates $B = 10,000$ resamples and calculates the expected claim amount on each resample.</span>
<span id="cb48-124"><a href="#cb48-124"></a></span>
<span id="cb48-127"><a href="#cb48-127"></a><span class="in">```{r}</span></span>
<span id="cb48-128"><a href="#cb48-128"></a>expected_claim_cost_fun <span class="ot">&lt;-</span> <span class="cf">function</span>(data, indx, ...) {</span>
<span id="cb48-129"><a href="#cb48-129"></a>  data <span class="ot">&lt;-</span> data[indx, ]</span>
<span id="cb48-130"><a href="#cb48-130"></a></span>
<span id="cb48-131"><a href="#cb48-131"></a>  expected_value <span class="ot">&lt;-</span> <span class="fu">sum</span>(data<span class="sc">$</span>ClaimAmount) <span class="sc">/</span> <span class="fu">sum</span>(data<span class="sc">$</span>Exposure)</span>
<span id="cb48-132"><a href="#cb48-132"></a></span>
<span id="cb48-133"><a href="#cb48-133"></a>  <span class="co"># this is the single / largest outlier in the data</span></span>
<span id="cb48-134"><a href="#cb48-134"></a>  outlier_counts <span class="ot">&lt;-</span> <span class="fu">nrow</span>(data[data<span class="sc">$</span>ClaimAmount <span class="sc">==</span> <span class="fl">1404185.52</span>, ])</span>
<span id="cb48-135"><a href="#cb48-135"></a></span>
<span id="cb48-136"><a href="#cb48-136"></a>  <span class="fu">return</span>(<span class="fu">c</span>(expected_value, outlier_counts))</span>
<span id="cb48-137"><a href="#cb48-137"></a>}</span>
<span id="cb48-138"><a href="#cb48-138"></a></span>
<span id="cb48-139"><a href="#cb48-139"></a>boot_fun <span class="ot">&lt;-</span> <span class="cf">function</span>(data, <span class="at">R =</span> <span class="dv">100</span>, <span class="at">parallel =</span> <span class="st">"snow"</span>) {</span>
<span id="cb48-140"><a href="#cb48-140"></a>  <span class="fu">stopifnot</span>(parallel <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"no"</span>, <span class="st">"snow"</span>))</span>
<span id="cb48-141"><a href="#cb48-141"></a></span>
<span id="cb48-142"><a href="#cb48-142"></a>  <span class="co"># TRUE if using parallelization, otherwise FALSE</span></span>
<span id="cb48-143"><a href="#cb48-143"></a>  simple <span class="ot">&lt;-</span> parallel <span class="sc">==</span> <span class="st">"snow"</span></span>
<span id="cb48-144"><a href="#cb48-144"></a></span>
<span id="cb48-145"><a href="#cb48-145"></a>  boot<span class="sc">::</span><span class="fu">boot</span>(</span>
<span id="cb48-146"><a href="#cb48-146"></a>    <span class="at">data =</span> data,</span>
<span id="cb48-147"><a href="#cb48-147"></a>    <span class="at">statistic =</span> expected_claim_cost_fun,</span>
<span id="cb48-148"><a href="#cb48-148"></a>    <span class="at">R =</span> R,</span>
<span id="cb48-149"><a href="#cb48-149"></a>    <span class="at">sim =</span> <span class="st">"ordinary"</span>,</span>
<span id="cb48-150"><a href="#cb48-150"></a>    <span class="at">stype =</span> <span class="st">"i"</span>,</span>
<span id="cb48-151"><a href="#cb48-151"></a>    <span class="at">simple =</span> simple,</span>
<span id="cb48-152"><a href="#cb48-152"></a>    <span class="at">parallel =</span> parallel,</span>
<span id="cb48-153"><a href="#cb48-153"></a>    <span class="at">ncpus =</span> <span class="dv">18</span></span>
<span id="cb48-154"><a href="#cb48-154"></a>  )</span>
<span id="cb48-155"><a href="#cb48-155"></a>}</span>
<span id="cb48-156"><a href="#cb48-156"></a></span>
<span id="cb48-157"><a href="#cb48-157"></a><span class="co"># uncomment to run</span></span>
<span id="cb48-158"><a href="#cb48-158"></a><span class="co"># boot_fit &lt;- boot_fun(data = claims, R = 10000)</span></span>
<span id="cb48-159"><a href="#cb48-159"></a></span>
<span id="cb48-160"><a href="#cb48-160"></a><span class="co"># uncomment to save the results </span></span>
<span id="cb48-161"><a href="#cb48-161"></a><span class="co"># saveRDS(boot_fit, file = "bootstrap_expected_claim_cost.rds")</span></span>
<span id="cb48-162"><a href="#cb48-162"></a><span class="in">```</span></span>
<span id="cb48-163"><a href="#cb48-163"></a></span>
<span id="cb48-164"><a href="#cb48-164"></a>This can take a while to run (even in parallel), so saved results are read back in and used to produce the following plot of the sampling distribution of the expected claim amount.</span>
<span id="cb48-165"><a href="#cb48-165"></a></span>
<span id="cb48-168"><a href="#cb48-168"></a><span class="in">```{r}</span></span>
<span id="cb48-169"><a href="#cb48-169"></a>boot_fit <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"bootstrap_expected_claim_cost.rds"</span>)</span>
<span id="cb48-170"><a href="#cb48-170"></a></span>
<span id="cb48-171"><a href="#cb48-171"></a><span class="co"># convert the results into a data frame</span></span>
<span id="cb48-172"><a href="#cb48-172"></a>boot_dist <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb48-173"><a href="#cb48-173"></a>  <span class="at">expected_claim_cost =</span> boot_fit<span class="sc">$</span>t[, <span class="dv">1</span>],</span>
<span id="cb48-174"><a href="#cb48-174"></a>  <span class="at">outlier_counts =</span> boot_fit<span class="sc">$</span>t[, <span class="dv">2</span>],</span>
<span id="cb48-175"><a href="#cb48-175"></a>  <span class="co"># used for coloring / facetting plots</span></span>
<span id="cb48-176"><a href="#cb48-176"></a>  <span class="co">#`Outlier counts` = paste0(boot_fit$t[, 2], " replicates")</span></span>
<span id="cb48-177"><a href="#cb48-177"></a>  <span class="st">`</span><span class="at">Outlier counts</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">factor</span>(boot_fit<span class="sc">$</span>t[, <span class="dv">2</span>])</span>
<span id="cb48-178"><a href="#cb48-178"></a>)</span>
<span id="cb48-179"><a href="#cb48-179"></a></span>
<span id="cb48-180"><a href="#cb48-180"></a>boot_dist <span class="sc">%&gt;%</span></span>
<span id="cb48-181"><a href="#cb48-181"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> expected_claim_cost)) <span class="sc">+</span></span>
<span id="cb48-182"><a href="#cb48-182"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">100</span>) <span class="sc">+</span></span>
<span id="cb48-183"><a href="#cb48-183"></a>  <span class="fu">geom_vline</span>(</span>
<span id="cb48-184"><a href="#cb48-184"></a>    <span class="at">xintercept =</span> expected_claim_amount, </span>
<span id="cb48-185"><a href="#cb48-185"></a>    <span class="at">color =</span> <span class="st">"orange"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span></span>
<span id="cb48-186"><a href="#cb48-186"></a>  ) <span class="sc">+</span></span>
<span id="cb48-187"><a href="#cb48-187"></a>  <span class="fu">xlab</span>(</span>
<span id="cb48-188"><a href="#cb48-188"></a>    glue<span class="sc">::</span><span class="fu">glue</span>(<span class="st">"Bootstrap distribution of expected "</span>, </span>
<span id="cb48-189"><a href="#cb48-189"></a>               <span class="st">"exposure-adjusted claim amount "</span>, </span>
<span id="cb48-190"><a href="#cb48-190"></a>               <span class="st">"per person per year"</span>, </span>
<span id="cb48-191"><a href="#cb48-191"></a>               <span class="st">"</span><span class="sc">\n</span><span class="st">(Estimate from the full sample in orange)"</span>)</span>
<span id="cb48-192"><a href="#cb48-192"></a>  ) <span class="sc">+</span></span>
<span id="cb48-193"><a href="#cb48-193"></a>  <span class="fu">ylab</span>(<span class="st">"Count"</span>)</span>
<span id="cb48-194"><a href="#cb48-194"></a><span class="in">```</span></span>
<span id="cb48-195"><a href="#cb48-195"></a></span>
<span id="cb48-196"><a href="#cb48-196"></a>That's an unusual looking bootstrap distribution. Googling led me to <span class="co">[</span><span class="ot">this stackexchange thread</span><span class="co">](https://stats.stackexchange.com/questions/63999/how-to-interpret-multimodal-distribution-of-bootstrapped-correlation)</span> which indicates similar behaviour arising due to outlier(s) and small sample sizes. Policies with the largest top-6 claim amounts are</span>
<span id="cb48-197"><a href="#cb48-197"></a></span>
<span id="cb48-200"><a href="#cb48-200"></a><span class="in">```{r}</span></span>
<span id="cb48-201"><a href="#cb48-201"></a>claims <span class="sc">%&gt;%</span> </span>
<span id="cb48-202"><a href="#cb48-202"></a>  <span class="fu">select</span>(ClaimAmount) <span class="sc">%&gt;%</span> </span>
<span id="cb48-203"><a href="#cb48-203"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(ClaimAmount)) <span class="sc">%&gt;%</span> </span>
<span id="cb48-204"><a href="#cb48-204"></a>  <span class="fu">slice_head</span>(<span class="at">n =</span> <span class="dv">6</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb48-205"><a href="#cb48-205"></a>  <span class="fu">pull</span>(ClaimAmount)</span>
<span id="cb48-206"><a href="#cb48-206"></a><span class="in">```</span></span>
<span id="cb48-207"><a href="#cb48-207"></a></span>
<span id="cb48-208"><a href="#cb48-208"></a>of which the largest at 1.4 million is roughly 8 times larger than the next largest value. It is interesting that despite having a large sample size of 60,000 (or 34,500 policy-years), this outlier is large enough relative to the sample size to cause the multimodality seen here.</span>
<span id="cb48-209"><a href="#cb48-209"></a></span>
<span id="cb48-210"><a href="#cb48-210"></a>The function used to calculate the expected claim amount on each bootstrap sample can be modified to also count the number of times the maximum value from the original sample shows up in each bootstrap sample. The bootstrap distribution is plotted again but this time colored by the number of times the maximum amount shows up in a replicate.</span>
<span id="cb48-211"><a href="#cb48-211"></a></span>
<span id="cb48-214"><a href="#cb48-214"></a><span class="in">```{r}</span></span>
<span id="cb48-215"><a href="#cb48-215"></a>boot_dist <span class="sc">%&gt;%</span></span>
<span id="cb48-216"><a href="#cb48-216"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> expected_claim_cost,</span>
<span id="cb48-217"><a href="#cb48-217"></a>             <span class="at">fill =</span> <span class="st">`</span><span class="at">Outlier counts</span><span class="st">`</span>)) <span class="sc">+</span></span>
<span id="cb48-218"><a href="#cb48-218"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">100</span>) <span class="sc">+</span></span>
<span id="cb48-219"><a href="#cb48-219"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> expected_claim_amount, <span class="at">color =</span> <span class="st">"gray40"</span>,</span>
<span id="cb48-220"><a href="#cb48-220"></a>             <span class="at">linewidth =</span> <span class="fl">1.2</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb48-221"><a href="#cb48-221"></a>  <span class="fu">xlab</span>(</span>
<span id="cb48-222"><a href="#cb48-222"></a>    glue<span class="sc">::</span><span class="fu">glue</span>(<span class="st">"Bootstrap distribution of expected "</span>, </span>
<span id="cb48-223"><a href="#cb48-223"></a>               <span class="st">"exposure-adjusted claim amount "</span>, </span>
<span id="cb48-224"><a href="#cb48-224"></a>               <span class="st">"per person per year"</span>, </span>
<span id="cb48-225"><a href="#cb48-225"></a>               <span class="st">"</span><span class="sc">\n</span><span class="st">(Estimate from the full sample in gray)"</span>)</span>
<span id="cb48-226"><a href="#cb48-226"></a>  ) <span class="sc">+</span></span>
<span id="cb48-227"><a href="#cb48-227"></a>  <span class="fu">ylab</span>(<span class="st">"Count"</span>) <span class="sc">+</span> </span>
<span id="cb48-228"><a href="#cb48-228"></a>  <span class="fu">theme</span>(</span>
<span id="cb48-229"><a href="#cb48-229"></a>    <span class="at">legend.position =</span> <span class="st">"inside"</span>,</span>
<span id="cb48-230"><a href="#cb48-230"></a>    <span class="co">#legend.background = element_blank(),</span></span>
<span id="cb48-231"><a href="#cb48-231"></a>    <span class="at">legend.position.inside =</span> <span class="fu">c</span>(<span class="fl">0.88</span>, <span class="fl">0.65</span>)</span>
<span id="cb48-232"><a href="#cb48-232"></a>  )</span>
<span id="cb48-233"><a href="#cb48-233"></a><span class="in">```</span></span>
<span id="cb48-234"><a href="#cb48-234"></a></span>
<span id="cb48-235"><a href="#cb48-235"></a>So this makes sense. Resamples with more repeats of the maximum claim amount have higher expected claim cost amounts.</span>
<span id="cb48-236"><a href="#cb48-236"></a></span>
<span id="cb48-237"><a href="#cb48-237"></a>Since the total claim amount for the following year is of interest, the bootstrap distribution can be multiplied by the number of policy holders to get a distribution of plausible values for the total claim amount for this population — which is expected to be around 13 million, but could be anywhere between 8 million to 28 million.</span>
<span id="cb48-238"><a href="#cb48-238"></a></span>
<span id="cb48-241"><a href="#cb48-241"></a><span class="in">```{r}</span></span>
<span id="cb48-242"><a href="#cb48-242"></a>nonparametric_bootstrap_totals <span class="ot">&lt;-</span> boot_dist <span class="sc">%&gt;%</span></span>
<span id="cb48-243"><a href="#cb48-243"></a>  <span class="fu">mutate</span>(</span>
<span id="cb48-244"><a href="#cb48-244"></a>    <span class="at">total_claim_amount =</span> <span class="dv">60000</span> <span class="sc">*</span> expected_claim_cost,</span>
<span id="cb48-245"><a href="#cb48-245"></a>    <span class="at">total_claim_amount_in_millions =</span> total_claim_amount <span class="sc">/</span> <span class="fl">1e6</span>,</span>
<span id="cb48-246"><a href="#cb48-246"></a>    <span class="at">method =</span> <span class="st">"Nonparametric Bootstrap (Weighted mean)"</span></span>
<span id="cb48-247"><a href="#cb48-247"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb48-248"><a href="#cb48-248"></a>  <span class="fu">select</span>(method, total_claim_amount_in_millions)</span>
<span id="cb48-249"><a href="#cb48-249"></a></span>
<span id="cb48-250"><a href="#cb48-250"></a>nonparametric_bootstrap_totals <span class="sc">%&gt;%</span></span>
<span id="cb48-251"><a href="#cb48-251"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> total_claim_amount_in_millions)) <span class="sc">+</span></span>
<span id="cb48-252"><a href="#cb48-252"></a>  <span class="fu">stat_ecdf</span>(<span class="at">pad =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb48-253"><a href="#cb48-253"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> (<span class="fl">6e4</span> <span class="sc">*</span> expected_claim_amount) <span class="sc">/</span> <span class="fl">1e6</span>,</span>
<span id="cb48-254"><a href="#cb48-254"></a>             <span class="at">color =</span> <span class="st">"orange"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb48-255"><a href="#cb48-255"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">8</span>, <span class="dv">30</span>, <span class="dv">2</span>)) <span class="sc">+</span></span>
<span id="cb48-256"><a href="#cb48-256"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span><span class="fu">label_percent</span>()) <span class="sc">+</span></span>
<span id="cb48-257"><a href="#cb48-257"></a>  <span class="fu">xlab</span>(</span>
<span id="cb48-258"><a href="#cb48-258"></a>    glue<span class="sc">::</span><span class="fu">glue</span>(<span class="st">"Plausible values for the "</span>, </span>
<span id="cb48-259"><a href="#cb48-259"></a>                <span class="st">"following year's</span><span class="sc">\n</span><span class="st">total claim "</span>, </span>
<span id="cb48-260"><a href="#cb48-260"></a>                <span class="st">"amount assuming unit exposure (in millions)"</span>, </span>
<span id="cb48-261"><a href="#cb48-261"></a>               <span class="st">"</span><span class="sc">\n</span><span class="st">(Estimate from the full sample in orange)"</span>)</span>
<span id="cb48-262"><a href="#cb48-262"></a>  ) <span class="sc">+</span></span>
<span id="cb48-263"><a href="#cb48-263"></a>  <span class="fu">ylab</span>(</span>
<span id="cb48-264"><a href="#cb48-264"></a>    glue<span class="sc">::</span><span class="fu">glue</span>(<span class="st">"Empirical distribution function of the</span><span class="sc">\n</span><span class="st">"</span>, </span>
<span id="cb48-265"><a href="#cb48-265"></a>               <span class="st">"bootstrap distribution of total claim amounts"</span>)</span>
<span id="cb48-266"><a href="#cb48-266"></a>  )</span>
<span id="cb48-267"><a href="#cb48-267"></a><span class="in">```</span></span>
<span id="cb48-268"><a href="#cb48-268"></a></span>
<span id="cb48-269"><a href="#cb48-269"></a>The empirical (cumulative) distribution function (EDF or eCDF) for the bootstrap distribution of the total claim amount from the population under unit exposure is shown above. The strong multimodality shows up as bumps in the eCDF but these seem pretty minor.</span>
<span id="cb48-270"><a href="#cb48-270"></a></span>
<span id="cb48-271"><a href="#cb48-271"></a>This approach ignores all the predictors in the data, and assumes that everyone has the same risk and spreads out that risk across every individual equally. However, it's expected that the risk may differ across factors such as driver's age, car model characteristics, region, etc. For this, we need more advanced approaches in the form of regression models.</span>
<span id="cb48-272"><a href="#cb48-272"></a></span>
<span id="cb48-273"><a href="#cb48-273"></a><span class="fu">## Tweedie models</span></span>
<span id="cb48-274"><a href="#cb48-274"></a></span>
<span id="cb48-275"><a href="#cb48-275"></a>A common probability model used to model claims data — the <span class="co">[</span><span class="ot">Tweedie distribution</span><span class="co">](https://en.wikipedia.org/wiki/Tweedie_distribution)</span> — is characterized by the power-law mean-variance relationship $\text{Var}<span class="co">[</span><span class="ot">Y_i</span><span class="co">]</span> \propto \mathbb{E}<span class="co">[</span><span class="ot">Y_i</span><span class="co">]</span> ^ p$ where the variance $\text{Var}<span class="co">[</span><span class="ot">Y_i</span><span class="co">]</span>$ is proportional to the mean $\mathbb{E}<span class="co">[</span><span class="ot">Y_i</span><span class="co">]</span>$. The Tweedie distribution with $p \in (1, 2)$ — also known as the compound Poisson(-gamma) distribution — is commonly used to model the total cost of claims from an insurance policy. In the insurance world, it can be derived at the policy level as a model of Poisson claim frequency with the sum of claim amounts (i.e., claim severity) coming from a gamma distribution.</span>
<span id="cb48-276"><a href="#cb48-276"></a></span>
<span id="cb48-277"><a href="#cb48-277"></a>The Tweedie distribution has three parameters — mean ($\mu &gt; 0$), dispersion ($\sigma &gt; 0$) which functions as the constant of proportionality, and variance function power $p \in (-\infty, 0] \cup [1, \infty)$. Restricting to $p \in (1, 2)$ make sense here since we have policies with zero claim amounts in the data and $p \notin(1, 2)$ is not suitable for modelling data with exact zeroes. The extreme of $p = 1$ corresponds to a Poisson distribution (which has support on non-negative integers), and $p = 2$ corresponds to a gamma distribution (which has support on positive real numbers). Special cases are also the Gaussian distribution ($p = 0$), and the inverse-Gaussian distribution ($p = 3$).</span>
<span id="cb48-278"><a href="#cb48-278"></a></span>
<span id="cb48-279"><a href="#cb48-279"></a>Section 4 of <span class="co">[</span><span class="ot">this paper</span><span class="co">](https://arxiv.org/abs/1508.06378)</span> has the clearest distinction I've seen between three related random variables for the $i^{th}$ policy — $Z_i$ is the observed total claim amount with exposure $w_i$ (we have $z_i$'s in our data), $Y_i = Z_i / w_i \sim \text{Tweedie}(\mu_i, \phi / w_i, p)$ is a derived quantity known as the *pure premium* under exposure $w_i$, and $Y^*_i \sim \text{Tweedie}(\mu_i, \phi, p)$ is the pure premium under unit exposure (so $w_i = 1$) which satisfies the mean-variance relationship $\text{Var}[Y_i^*] = \phi \mathbb{E}[Y_i^*]^p$. I'm treating $\phi$ as a constant here, but it can be modelled as a function of covariates, as is done in <span class="co">[</span><span class="ot">this paper</span><span class="co">](https://link.springer.com/article/10.1007/s13385-021-00264-3)</span> for example.</span>
<span id="cb48-280"><a href="#cb48-280"></a></span>
<span id="cb48-281"><a href="#cb48-281"></a>What tripped me up while writing a <span class="co">[</span><span class="ot">previous post</span><span class="co">](../tweedie-with-identity-link-and-offset/index.qmd)</span><span class="ot">[^2]</span> on this topic was that I kept trying to take the weighted mean of the $z_i$ values instead of the $y_i$ values and getting different results compared with the ratio $\sum_i z_i / \sum_i w_i$ when they should've been identical. Taking the weighted mean of the $y_i$ values leads to the same estimate as the ratio of these sums because the $w_i$'s cancel out in the numerator.</span>
<span id="cb48-282"><a href="#cb48-282"></a></span>
<span id="cb48-283"><a href="#cb48-283"></a><span class="ot">[^2]: </span>To be fair, I'd read the Yang et al. paper for that post too, but had overlooked that (subtle?) distinction.</span>
<span id="cb48-284"><a href="#cb48-284"></a></span>
<span id="cb48-285"><a href="#cb48-285"></a><span class="fu">### Intercept-only regression</span></span>
<span id="cb48-286"><a href="#cb48-286"></a></span>
<span id="cb48-287"><a href="#cb48-287"></a>There are two ways of accounting for the varying exposures in a model. The first method uses pure premium $y_i$ as the response variable and the exposure $w_i$'s are passed as weights to the fitting functions. The second method uses the observed amount $z_i$ with $w_i$ as an offset (i.e., a variable in the model with a fixed coefficient of 1). For the Tweedie model with $p \in (1, 2)$, these two methods result in different parameter estimates (compared to the Poisson regression case where they give the same estimates). I'm sticking with the first approach here since more modelling packages across languages support model weights compared with offsets.</span>
<span id="cb48-288"><a href="#cb48-288"></a></span>
<span id="cb48-289"><a href="#cb48-289"></a>The following code fits an intercept-only Tweedie *generalized linear model* (GLM) with pure premium as the response variable and exposure as weights, and uses an identity link (<span class="in">`link.power = 1`</span>). For this simple model, the link function shouldn't really matter for the parameter estimate for the mean $\mu$. The variance power is taken to be $p = 1.6$ throughout. This is very close to the chosen value for $p$ from calling <span class="in">`tweedie::tweedie.profile()`</span> using the model offset formulation described in the previous paragraph. I couldn't get this function to work for the pure premium model with weights because the log-likelihood estimates were (negative) infinite for all $p$, and $p = 1.8$ was the value that minimized the Tweedie deviance (including on simulated data with known $\mu$, $\phi$, and $p = 1.6$).</span>
<span id="cb48-290"><a href="#cb48-290"></a></span>
<span id="cb48-293"><a href="#cb48-293"></a><span class="in">```{r}</span></span>
<span id="cb48-294"><a href="#cb48-294"></a><span class="co">#| code-fold: false</span></span>
<span id="cb48-295"><a href="#cb48-295"></a></span>
<span id="cb48-296"><a href="#cb48-296"></a>tweedie_intercept_only <span class="ot">&lt;-</span> <span class="fu">glm</span>(</span>
<span id="cb48-297"><a href="#cb48-297"></a>  <span class="fu">I</span>(ClaimAmount <span class="sc">/</span> Exposure) <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb48-298"><a href="#cb48-298"></a>  <span class="at">weights =</span> Exposure,</span>
<span id="cb48-299"><a href="#cb48-299"></a>  <span class="at">data =</span> claims,</span>
<span id="cb48-300"><a href="#cb48-300"></a>  <span class="co"># using link.power = 1 implies identity link for the mean parameter mu</span></span>
<span id="cb48-301"><a href="#cb48-301"></a>  <span class="at">family =</span> statmod<span class="sc">::</span><span class="fu">tweedie</span>(<span class="at">var.power =</span> <span class="fl">1.6</span>, <span class="at">link.power =</span> <span class="dv">1</span>)</span>
<span id="cb48-302"><a href="#cb48-302"></a>)</span>
<span id="cb48-303"><a href="#cb48-303"></a></span>
<span id="cb48-304"><a href="#cb48-304"></a><span class="fu">summary</span>(tweedie_intercept_only)</span>
<span id="cb48-305"><a href="#cb48-305"></a><span class="in">```</span></span>
<span id="cb48-306"><a href="#cb48-306"></a></span>
<span id="cb48-307"><a href="#cb48-307"></a>So our best guess for the distribution of $Y_i^*$'s from the Tweedie class of models is $\text{Tweedie}(\mu = 217.78..., \phi = 25966.83..., p = 1.6...)$ (where the ellipses indicate truncation). These estimates for $\hat\mu_{\text{int}}$ and $\hat\phi_{\text{int}}$ will be used again, so they're stored as variables.</span>
<span id="cb48-308"><a href="#cb48-308"></a></span>
<span id="cb48-311"><a href="#cb48-311"></a><span class="in">```{r}</span></span>
<span id="cb48-312"><a href="#cb48-312"></a><span class="co">#| code-fold: false</span></span>
<span id="cb48-313"><a href="#cb48-313"></a></span>
<span id="cb48-314"><a href="#cb48-314"></a>mu <span class="ot">&lt;-</span> <span class="fu">coef</span>(tweedie_intercept_only)</span>
<span id="cb48-315"><a href="#cb48-315"></a>phi <span class="ot">&lt;-</span> tweedie_intercept_only <span class="sc">%&gt;%</span> </span>
<span id="cb48-316"><a href="#cb48-316"></a>  <span class="fu">summary</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb48-317"><a href="#cb48-317"></a>  <span class="fu">pluck</span>(<span class="st">"dispersion"</span>)</span>
<span id="cb48-318"><a href="#cb48-318"></a><span class="in">```</span></span>
<span id="cb48-319"><a href="#cb48-319"></a></span>
<span id="cb48-320"><a href="#cb48-320"></a><span class="fu">### Parametric Bootstrap</span></span>
<span id="cb48-321"><a href="#cb48-321"></a></span>
<span id="cb48-322"><a href="#cb48-322"></a>One way of getting a distribution for the statistic of interest $T$ is the use of the parametric bootstrap. This involves drawing $B$ samples each of size $n$ from the fitted model, computing the statistic for each of the $B$ samples, and using this as an estimate of the sampling distribution from which summary statistics (e.g. mean, quantiles, sd, etc.) can be computed.</span>
<span id="cb48-323"><a href="#cb48-323"></a></span>
<span id="cb48-324"><a href="#cb48-324"></a>The observed statistics — such as the number of claims with amounts <span class="sc">\&gt;</span> 0, the total claim amounts, and the largest claim amount — from the one sample of $z_i$'s that we have can be compared with the sampling distribution from the parametric bootstrap using the observed exposures $w_i$.</span>
<span id="cb48-325"><a href="#cb48-325"></a></span>
<span id="cb48-326"><a href="#cb48-326"></a>The following code carries this out with $B = 10,000$ where for each $b$ we draw a vector of $n$ claim amounts $Z_{i, b}$ and the statistic $\hat{T_b}$ is computed. $Z_{i, b}$ is drawn as $Z_{i, b} \sim w_i \times \text{Tweedie}(\hat\mu_{\text{int}}, \hat\phi_{\text{int}} / w_i, 1.6)$.</span>
<span id="cb48-327"><a href="#cb48-327"></a></span>
<span id="cb48-330"><a href="#cb48-330"></a><span class="in">```{r}</span></span>
<span id="cb48-331"><a href="#cb48-331"></a><span class="co"># how well does the model fit the data?</span></span>
<span id="cb48-332"><a href="#cb48-332"></a><span class="co"># a form of posterior predictive checking</span></span>
<span id="cb48-333"><a href="#cb48-333"></a><span class="co"># ppc_obs_exposure &lt;- map(</span></span>
<span id="cb48-334"><a href="#cb48-334"></a><span class="co">#   .x = 1:10000,</span></span>
<span id="cb48-335"><a href="#cb48-335"></a><span class="co">#   .f = ~ {</span></span>
<span id="cb48-336"><a href="#cb48-336"></a><span class="co">#     if(.x %% 100 == 0) {</span></span>
<span id="cb48-337"><a href="#cb48-337"></a><span class="co">#       print(.x)</span></span>
<span id="cb48-338"><a href="#cb48-338"></a><span class="co">#     }</span></span>
<span id="cb48-339"><a href="#cb48-339"></a><span class="co">#     set.seed(.x)</span></span>
<span id="cb48-340"><a href="#cb48-340"></a><span class="co">#     draw &lt;- claims$Exposure * tweedie::rtweedie(60000, mu = mu,</span></span>
<span id="cb48-341"><a href="#cb48-341"></a><span class="co">#                                                 phi = phi / claims$Exposure,</span></span>
<span id="cb48-342"><a href="#cb48-342"></a><span class="co">#                                                 power = 1.6)</span></span>
<span id="cb48-343"><a href="#cb48-343"></a><span class="co">#     tibble(prop_zero = mean(draw == 0), sample_total = sum(draw),</span></span>
<span id="cb48-344"><a href="#cb48-344"></a><span class="co">#            sample_max = max(draw), n_nonzero = sum(draw &gt; 0))</span></span>
<span id="cb48-345"><a href="#cb48-345"></a><span class="co">#   }) %&gt;%</span></span>
<span id="cb48-346"><a href="#cb48-346"></a><span class="co">#   list_rbind()</span></span>
<span id="cb48-347"><a href="#cb48-347"></a><span class="co">#</span></span>
<span id="cb48-348"><a href="#cb48-348"></a><span class="co"># saveRDS(ppc_obs_exposure, file = "ppc_obs_exposure.rds")</span></span>
<span id="cb48-349"><a href="#cb48-349"></a></span>
<span id="cb48-350"><a href="#cb48-350"></a><span class="co"># code takes a while to run, so we can read in the saved results</span></span>
<span id="cb48-351"><a href="#cb48-351"></a>ppc_obs_exposure <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="at">file =</span> <span class="st">"ppc_obs_exposure.rds"</span>)</span>
<span id="cb48-352"><a href="#cb48-352"></a></span>
<span id="cb48-353"><a href="#cb48-353"></a><span class="co"># summary statistics on the observed data</span></span>
<span id="cb48-354"><a href="#cb48-354"></a>sample_statistics_obs_exposure <span class="ot">&lt;-</span> claims <span class="sc">%&gt;%</span></span>
<span id="cb48-355"><a href="#cb48-355"></a>  <span class="fu">summarise</span>(</span>
<span id="cb48-356"><a href="#cb48-356"></a>    <span class="at">prop_zero =</span> <span class="fu">mean</span>(ClaimAmount <span class="sc">==</span> <span class="dv">0</span>),</span>
<span id="cb48-357"><a href="#cb48-357"></a>    <span class="at">sample_total =</span> <span class="fu">sum</span>(ClaimAmount),</span>
<span id="cb48-358"><a href="#cb48-358"></a>    <span class="at">sample_max =</span> <span class="fu">max</span>(ClaimAmount),</span>
<span id="cb48-359"><a href="#cb48-359"></a>    <span class="at">n_nonzero =</span> <span class="fu">sum</span>(ClaimAmount <span class="sc">&gt;</span> <span class="dv">0</span>)</span>
<span id="cb48-360"><a href="#cb48-360"></a>  )</span>
<span id="cb48-361"><a href="#cb48-361"></a></span>
<span id="cb48-362"><a href="#cb48-362"></a><span class="co"># combine the ppc data and the original sample data</span></span>
<span id="cb48-363"><a href="#cb48-363"></a>plot_data_obs_exposure <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(</span>
<span id="cb48-364"><a href="#cb48-364"></a>  ppc_obs_exposure <span class="sc">%&gt;%</span> </span>
<span id="cb48-365"><a href="#cb48-365"></a>    <span class="fu">mutate</span>(<span class="at">group =</span> <span class="st">"sampled"</span>, <span class="at">.before =</span> <span class="dv">0</span>),</span>
<span id="cb48-366"><a href="#cb48-366"></a>  sample_statistics_obs_exposure <span class="sc">%&gt;%</span> </span>
<span id="cb48-367"><a href="#cb48-367"></a>    <span class="fu">mutate</span>(<span class="at">group =</span> <span class="st">"observed"</span>, <span class="at">.before =</span> <span class="dv">0</span>)</span>
<span id="cb48-368"><a href="#cb48-368"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb48-369"><a href="#cb48-369"></a>  <span class="fu">mutate</span>(</span>
<span id="cb48-370"><a href="#cb48-370"></a>    <span class="fu">across</span>(<span class="fu">c</span>(sample_total, sample_max), <span class="sc">~</span> .x <span class="sc">/</span> <span class="fl">1e6</span>),</span>
<span id="cb48-371"><a href="#cb48-371"></a>    <span class="at">prop_zero =</span> <span class="dv">100</span> <span class="sc">*</span> prop_zero</span>
<span id="cb48-372"><a href="#cb48-372"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb48-373"><a href="#cb48-373"></a>  <span class="fu">rename</span>(</span>
<span id="cb48-374"><a href="#cb48-374"></a>    <span class="st">`</span><span class="at">% of policies with zero claims</span><span class="st">`</span> <span class="ot">=</span> prop_zero,</span>
<span id="cb48-375"><a href="#cb48-375"></a>    <span class="st">`</span><span class="at">Number of policies with non zero claim amounts</span><span class="st">`</span> <span class="ot">=</span> n_nonzero,</span>
<span id="cb48-376"><a href="#cb48-376"></a>    <span class="st">`</span><span class="at">Maximum claim amount (in millions)</span><span class="st">`</span> <span class="ot">=</span> sample_max,</span>
<span id="cb48-377"><a href="#cb48-377"></a>    <span class="st">`</span><span class="at">Total claim amount (in millions)</span><span class="st">`</span> <span class="ot">=</span> sample_total</span>
<span id="cb48-378"><a href="#cb48-378"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb48-379"><a href="#cb48-379"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="sc">-</span>group, <span class="at">names_to =</span> <span class="st">"statistic"</span>, <span class="at">values_to =</span> <span class="st">"values"</span>)</span>
<span id="cb48-380"><a href="#cb48-380"></a></span>
<span id="cb48-381"><a href="#cb48-381"></a><span class="co"># mean of the posterior predictive distribution values</span></span>
<span id="cb48-382"><a href="#cb48-382"></a>ppc_mean_obs_exposure <span class="ot">&lt;-</span> plot_data_obs_exposure <span class="sc">%&gt;%</span></span>
<span id="cb48-383"><a href="#cb48-383"></a>  <span class="fu">filter</span>(group <span class="sc">==</span> <span class="st">"sampled"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb48-384"><a href="#cb48-384"></a>  <span class="fu">summarise</span>(<span class="at">values =</span> <span class="fu">mean</span>(values), <span class="at">.by =</span> statistic) <span class="sc">%&gt;%</span></span>
<span id="cb48-385"><a href="#cb48-385"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="at">.cols =</span> <span class="fu">where</span>(is.numeric), </span>
<span id="cb48-386"><a href="#cb48-386"></a>                <span class="at">.fns =</span> <span class="sc">~</span> <span class="fu">round</span>(.x, <span class="dv">2</span>)))</span>
<span id="cb48-387"><a href="#cb48-387"></a></span>
<span id="cb48-388"><a href="#cb48-388"></a><span class="co"># compare these visually</span></span>
<span id="cb48-389"><a href="#cb48-389"></a>plot_data_obs_exposure <span class="sc">%&gt;%</span></span>
<span id="cb48-390"><a href="#cb48-390"></a>  <span class="fu">filter</span>(group <span class="sc">==</span> <span class="st">"sampled"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb48-391"><a href="#cb48-391"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> values, <span class="at">group =</span> statistic)) <span class="sc">+</span></span>
<span id="cb48-392"><a href="#cb48-392"></a>  <span class="fu">stat_ecdf</span>(<span class="at">pad =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb48-393"><a href="#cb48-393"></a>  <span class="co"># plot the sample statistic</span></span>
<span id="cb48-394"><a href="#cb48-394"></a>  <span class="fu">geom_vline</span>(<span class="at">data =</span> <span class="fu">filter</span>(plot_data_obs_exposure,</span>
<span id="cb48-395"><a href="#cb48-395"></a>                           group <span class="sc">==</span> <span class="st">"observed"</span>),</span>
<span id="cb48-396"><a href="#cb48-396"></a>             <span class="fu">aes</span>(<span class="at">xintercept =</span> values, <span class="at">group =</span> statistic),</span>
<span id="cb48-397"><a href="#cb48-397"></a>             <span class="at">color =</span> <span class="st">"orange"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb48-398"><a href="#cb48-398"></a>  <span class="co"># plot the distribution means</span></span>
<span id="cb48-399"><a href="#cb48-399"></a>  <span class="fu">geom_vline</span>(<span class="at">data =</span> ppc_mean_obs_exposure,</span>
<span id="cb48-400"><a href="#cb48-400"></a>             <span class="fu">aes</span>(<span class="at">xintercept =</span> values, <span class="at">group =</span> statistic),</span>
<span id="cb48-401"><a href="#cb48-401"></a>             <span class="at">color =</span> <span class="st">"red4"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb48-402"><a href="#cb48-402"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> statistic, <span class="at">scales =</span> <span class="st">"free"</span>) <span class="sc">+</span></span>
<span id="cb48-403"><a href="#cb48-403"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span><span class="fu">label_percent</span>()) <span class="sc">+</span></span>
<span id="cb48-404"><a href="#cb48-404"></a>  <span class="fu">xlab</span>(glue<span class="sc">::</span><span class="fu">glue</span>(<span class="st">"Statistics from the observed data (in orange);"</span>,</span>
<span id="cb48-405"><a href="#cb48-405"></a>                  <span class="st">"</span><span class="sc">\n</span><span class="st">mean of means from the simulated datasets (in red)"</span>)) <span class="sc">+</span></span>
<span id="cb48-406"><a href="#cb48-406"></a>  <span class="fu">ylab</span>(<span class="st">"Empirical distribution function"</span>)</span>
<span id="cb48-407"><a href="#cb48-407"></a><span class="in">```</span></span>
<span id="cb48-408"><a href="#cb48-408"></a></span>
<span id="cb48-409"><a href="#cb48-409"></a>What's really interesting about this plot is that the proportion (and number) of policies with zero claim amounts is really far from the observed proportion (number) of 95% (3000) vs the mean of the sampling distribution (99% and 29). On the other hand, the observed and average total claim amounts are virtually indistinguishable, and the average maximum claim amount isn't too far off from the observed maximum claim amount.</span>
<span id="cb48-410"><a href="#cb48-410"></a></span>
<span id="cb48-411"><a href="#cb48-411"></a>Given that the statistic of interest has been the total claim amount across the policies, this doesn't seem to be a bad approach, even though the EDFs of the sampled $Z_{i, b} &gt; 0$'s from the model (10 datasets shown in gray) look pretty far off from the observed distribution of $Z_{i, \text{obs}} &gt; 0$'s (observed claim amounts in black)</span>
<span id="cb48-412"><a href="#cb48-412"></a></span>
<span id="cb48-415"><a href="#cb48-415"></a><span class="in">```{r}</span></span>
<span id="cb48-416"><a href="#cb48-416"></a><span class="co"># plot eCDFs of sampled datasets with the observed data</span></span>
<span id="cb48-417"><a href="#cb48-417"></a><span class="fu">map</span>(</span>
<span id="cb48-418"><a href="#cb48-418"></a>  <span class="at">.x =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,</span>
<span id="cb48-419"><a href="#cb48-419"></a>  <span class="at">.f =</span> <span class="sc">~</span> {</span>
<span id="cb48-420"><a href="#cb48-420"></a>    <span class="fu">set.seed</span>(.x)</span>
<span id="cb48-421"><a href="#cb48-421"></a>    draw <span class="ot">&lt;-</span> claims<span class="sc">$</span>Exposure <span class="sc">*</span> tweedie<span class="sc">::</span><span class="fu">rtweedie</span>(<span class="dv">60000</span>, <span class="at">mu =</span> mu,</span>
<span id="cb48-422"><a href="#cb48-422"></a>                                                <span class="at">phi =</span> phi <span class="sc">/</span> claims<span class="sc">$</span>Exposure,</span>
<span id="cb48-423"><a href="#cb48-423"></a>                                                <span class="at">power =</span> <span class="fl">1.6</span>)</span>
<span id="cb48-424"><a href="#cb48-424"></a>    <span class="fu">tibble</span>(<span class="at">sim_id =</span> .x, <span class="at">y =</span> draw, <span class="at">grp =</span> <span class="st">"Simulated"</span>)</span>
<span id="cb48-425"><a href="#cb48-425"></a>  }) <span class="sc">%&gt;%</span></span>
<span id="cb48-426"><a href="#cb48-426"></a>  <span class="fu">list_rbind</span>() <span class="sc">%&gt;%</span></span>
<span id="cb48-427"><a href="#cb48-427"></a>  <span class="fu">bind_rows</span>(</span>
<span id="cb48-428"><a href="#cb48-428"></a>    .,</span>
<span id="cb48-429"><a href="#cb48-429"></a>    claims <span class="sc">%&gt;%</span></span>
<span id="cb48-430"><a href="#cb48-430"></a>      <span class="fu">mutate</span>(<span class="at">sim_id =</span> <span class="dv">100</span>, <span class="at">grp =</span> <span class="st">"Observed"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb48-431"><a href="#cb48-431"></a>      <span class="fu">select</span>(sim_id, <span class="at">y =</span> ClaimAmount, grp)</span>
<span id="cb48-432"><a href="#cb48-432"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb48-433"><a href="#cb48-433"></a>  <span class="fu">filter</span>(y <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb48-434"><a href="#cb48-434"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> y, <span class="at">group =</span> sim_id, <span class="at">color =</span> grp)) <span class="sc">+</span></span>
<span id="cb48-435"><a href="#cb48-435"></a>  <span class="fu">stat_ecdf</span>() <span class="sc">+</span></span>
<span id="cb48-436"><a href="#cb48-436"></a>  <span class="fu">xlab</span>(<span class="st">"Policies with non-zero claim amounts (log10 scale)"</span>) <span class="sc">+</span></span>
<span id="cb48-437"><a href="#cb48-437"></a>  <span class="fu">ylab</span>(<span class="st">"Empirical distribution function"</span>) <span class="sc">+</span></span>
<span id="cb48-438"><a href="#cb48-438"></a>  <span class="fu">scale_x_log10</span>(</span>
<span id="cb48-439"><a href="#cb48-439"></a>    <span class="at">breaks =</span> scales<span class="sc">::</span><span class="fu">trans_breaks</span>(<span class="st">"log10"</span>, <span class="cf">function</span>(x) <span class="dv">10</span><span class="sc">^</span>x),</span>
<span id="cb48-440"><a href="#cb48-440"></a>    <span class="at">labels =</span> scales<span class="sc">::</span><span class="fu">trans_format</span>(<span class="st">"log10"</span>, scales<span class="sc">::</span><span class="fu">math_format</span>(<span class="dv">10</span><span class="sc">^</span>.x))</span>
<span id="cb48-441"><a href="#cb48-441"></a>  ) <span class="sc">+</span></span>
<span id="cb48-442"><a href="#cb48-442"></a>  <span class="fu">annotation_logticks</span>(<span class="at">sides =</span> <span class="st">"b"</span>) <span class="sc">+</span></span>
<span id="cb48-443"><a href="#cb48-443"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span>percent) <span class="sc">+</span></span>
<span id="cb48-444"><a href="#cb48-444"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb48-445"><a href="#cb48-445"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Simulated"</span> <span class="ot">=</span> <span class="st">"gray70"</span>, <span class="st">"Observed"</span> <span class="ot">=</span> <span class="st">"Black"</span>)</span>
<span id="cb48-446"><a href="#cb48-446"></a>  ) <span class="sc">+</span></span>
<span id="cb48-447"><a href="#cb48-447"></a>  <span class="fu">theme</span>(</span>
<span id="cb48-448"><a href="#cb48-448"></a>    <span class="at">legend.title =</span> <span class="fu">element_blank</span>(), </span>
<span id="cb48-449"><a href="#cb48-449"></a>    <span class="at">legend.position =</span> <span class="st">"inside"</span>,</span>
<span id="cb48-450"><a href="#cb48-450"></a>    <span class="at">legend.position.inside =</span> <span class="fu">c</span>(<span class="fl">0.9</span>, <span class="fl">0.2</span>)</span>
<span id="cb48-451"><a href="#cb48-451"></a>  )</span>
<span id="cb48-452"><a href="#cb48-452"></a><span class="in">```</span></span>
<span id="cb48-453"><a href="#cb48-453"></a></span>
<span id="cb48-454"><a href="#cb48-454"></a>Simulated claim amounts are orders of magnitude larger than the observed claim amounts, which is how the totals are very similar despite the very different sample sizes of policies with non-zero claim amounts. The very low number of non-zero claim amounts in the simulated datasets is what leads to the jaggedness of the distribution functions.</span>
<span id="cb48-455"><a href="#cb48-455"></a></span>
<span id="cb48-456"><a href="#cb48-456"></a>If the goal is to have accurate estimates for the proportion of non-zero claims, then a hurdle model mentioned earlier would be a better approach. The observed distribution has a pretty big jump at 1128.12 which shows up 1169 times in the data, so a mixture model might be more appropriate if want to have a model with approximately the same eCDF.</span>
<span id="cb48-457"><a href="#cb48-457"></a></span>
<span id="cb48-458"><a href="#cb48-458"></a>This approach of comparing the statistics on samples drawn from the model vs the statistics from the observed sample is the concept of <span class="co">[</span><span class="ot">*posterior predictive checking*</span><span class="co">](https://mc-stan.org/docs/stan-users-guide/posterior-predictive-checks.html)</span> (PPC). If the model adequately describes the data generating process, the distribution of all the statistics from sampled datasets should be approximately centered at the observed statistics.</span>
<span id="cb48-459"><a href="#cb48-459"></a></span>
<span id="cb48-460"><a href="#cb48-460"></a>For next year's claim amount, we can repeat the same step with a slight modification — sample $Y_{i, b}^* \sim \text{Tweedie}(\hat\mu_{\text{int}}, \hat\phi_{\text{int}}, p = 1.6)$ and calculate $\hat{T_b} = \sum_i Y_{i, b}^*$ which ranges from about 4 to 27.5 million.</span>
<span id="cb48-461"><a href="#cb48-461"></a></span>
<span id="cb48-464"><a href="#cb48-464"></a><span class="in">```{r}</span></span>
<span id="cb48-465"><a href="#cb48-465"></a><span class="co"># predicted_totals_for_unit_exposure &lt;- map_dbl(.x = 1:10000, .f = ~ {</span></span>
<span id="cb48-466"><a href="#cb48-466"></a><span class="co">#   if(.x %% 100 == 0) {</span></span>
<span id="cb48-467"><a href="#cb48-467"></a><span class="co">#     print(.x)</span></span>
<span id="cb48-468"><a href="#cb48-468"></a><span class="co">#   }</span></span>
<span id="cb48-469"><a href="#cb48-469"></a><span class="co">#   set.seed(.x)</span></span>
<span id="cb48-470"><a href="#cb48-470"></a><span class="co">#   sum(tweedie::rtweedie(60000, mu = mu, phi = phi, power = 1.6))</span></span>
<span id="cb48-471"><a href="#cb48-471"></a><span class="co"># })</span></span>
<span id="cb48-472"><a href="#cb48-472"></a><span class="co">#</span></span>
<span id="cb48-473"><a href="#cb48-473"></a><span class="co"># saveRDS(predicted_totals_for_unit_exposure,</span></span>
<span id="cb48-474"><a href="#cb48-474"></a><span class="co">#         file = "predicted_totals_for_unit_exposure.rds")</span></span>
<span id="cb48-475"><a href="#cb48-475"></a></span>
<span id="cb48-476"><a href="#cb48-476"></a>predicted_totals_for_unit_exposure <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(</span>
<span id="cb48-477"><a href="#cb48-477"></a>  <span class="at">file =</span> <span class="st">"predicted_totals_for_unit_exposure.rds"</span></span>
<span id="cb48-478"><a href="#cb48-478"></a>)</span>
<span id="cb48-479"><a href="#cb48-479"></a></span>
<span id="cb48-480"><a href="#cb48-480"></a><span class="fu">summary</span>(predicted_totals_for_unit_exposure)</span>
<span id="cb48-481"><a href="#cb48-481"></a><span class="in">```</span></span>
<span id="cb48-482"><a href="#cb48-482"></a></span>
<span id="cb48-483"><a href="#cb48-483"></a><span class="fu">### Nonparametric Bootstrap</span></span>
<span id="cb48-484"><a href="#cb48-484"></a></span>
<span id="cb48-485"><a href="#cb48-485"></a>The parametric bootstrap uses the point estimate to simulate new samples. From a Bayesian point of view, this corresponds to using the Dirac delta posterior distribution with a spike at the point estimate $(\hat\mu_{\text{int}}, \hat\phi_{\text{int}})$ and ignoring the uncertainty in the parameter estimates by treating it as zero. This section extends the parametric bootstrap approach by accounting for the uncertainty in the $(\hat\mu_{\text{int}}, \hat\phi_{\text{int}})$ values.</span>
<span id="cb48-486"><a href="#cb48-486"></a></span>
<span id="cb48-487"><a href="#cb48-487"></a>In the first stage, a separate Tweedie model is fit to each bootstrapped sample from the original data and the estimated $(\hat\mu_{\text{int}, b}, \hat\phi_{\text{int}, b})_{b = 1}^{10,000}$ pairs are collected. These 10,000 pairs are a sample from the "poor man's" posterior distribution for these parameters and are visualized here</span>
<span id="cb48-488"><a href="#cb48-488"></a></span>
<span id="cb48-491"><a href="#cb48-491"></a><span class="in">```{r}</span></span>
<span id="cb48-492"><a href="#cb48-492"></a><span class="co">#| warning: false</span></span>
<span id="cb48-493"><a href="#cb48-493"></a></span>
<span id="cb48-494"><a href="#cb48-494"></a><span class="co"># bootstrap and get the joint distribution of (mu, phi)</span></span>
<span id="cb48-495"><a href="#cb48-495"></a><span class="co"># bootstrap_mu_phi &lt;- map_dfr(</span></span>
<span id="cb48-496"><a href="#cb48-496"></a><span class="co">#   .x = 1:10000,</span></span>
<span id="cb48-497"><a href="#cb48-497"></a><span class="co">#   .f = ~ {</span></span>
<span id="cb48-498"><a href="#cb48-498"></a><span class="co">#     if(.x %% 100 == 0) {</span></span>
<span id="cb48-499"><a href="#cb48-499"></a><span class="co">#       print(.x)</span></span>
<span id="cb48-500"><a href="#cb48-500"></a><span class="co">#     }</span></span>
<span id="cb48-501"><a href="#cb48-501"></a><span class="co">#     set.seed(.x)</span></span>
<span id="cb48-502"><a href="#cb48-502"></a><span class="co">#     data &lt;- claims %&gt;%</span></span>
<span id="cb48-503"><a href="#cb48-503"></a><span class="co">#       slice_sample(n = 60000, replace = TRUE)</span></span>
<span id="cb48-504"><a href="#cb48-504"></a><span class="co">#     outlier_counts &lt;- nrow(data[data$ClaimAmount == 1404185.52, ])</span></span>
<span id="cb48-505"><a href="#cb48-505"></a><span class="co">#     mod &lt;- data %&gt;%</span></span>
<span id="cb48-506"><a href="#cb48-506"></a><span class="co">#       glm(</span></span>
<span id="cb48-507"><a href="#cb48-507"></a><span class="co">#         I(ClaimAmount / Exposure) ~ 1,</span></span>
<span id="cb48-508"><a href="#cb48-508"></a><span class="co">#         weights = Exposure,</span></span>
<span id="cb48-509"><a href="#cb48-509"></a><span class="co">#         data = .,</span></span>
<span id="cb48-510"><a href="#cb48-510"></a><span class="co">#         family = statmod::tweedie(var.power = 1.6, link.power = 0)</span></span>
<span id="cb48-511"><a href="#cb48-511"></a><span class="co">#       )</span></span>
<span id="cb48-512"><a href="#cb48-512"></a><span class="co">#</span></span>
<span id="cb48-513"><a href="#cb48-513"></a><span class="co">#     tibble(</span></span>
<span id="cb48-514"><a href="#cb48-514"></a><span class="co">#       mu = exp(coef(mod)),</span></span>
<span id="cb48-515"><a href="#cb48-515"></a><span class="co">#       phi = summary(mod)$dispersion,</span></span>
<span id="cb48-516"><a href="#cb48-516"></a><span class="co">#       outlier_counts = outlier_counts</span></span>
<span id="cb48-517"><a href="#cb48-517"></a><span class="co">#     )</span></span>
<span id="cb48-518"><a href="#cb48-518"></a><span class="co">#   }</span></span>
<span id="cb48-519"><a href="#cb48-519"></a><span class="co"># )</span></span>
<span id="cb48-520"><a href="#cb48-520"></a><span class="co">#</span></span>
<span id="cb48-521"><a href="#cb48-521"></a><span class="co"># saveRDS(bootstrap_mu_phi, file = "bootstrap_mu_phi.rds")</span></span>
<span id="cb48-522"><a href="#cb48-522"></a></span>
<span id="cb48-523"><a href="#cb48-523"></a>bootstrap_mu_phi <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"bootstrap_mu_phi.rds"</span>)</span>
<span id="cb48-524"><a href="#cb48-524"></a></span>
<span id="cb48-525"><a href="#cb48-525"></a>mu_phi_plot <span class="ot">&lt;-</span> bootstrap_mu_phi <span class="sc">%&gt;%</span></span>
<span id="cb48-526"><a href="#cb48-526"></a>  <span class="fu">mutate</span>(<span class="st">`</span><span class="at">Outlier counts</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">factor</span>(outlier_counts)) <span class="sc">%&gt;%</span></span>
<span id="cb48-527"><a href="#cb48-527"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> phi, <span class="at">color =</span> <span class="st">`</span><span class="at">Outlier counts</span><span class="st">`</span>)) <span class="sc">+</span></span>
<span id="cb48-528"><a href="#cb48-528"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb48-529"><a href="#cb48-529"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> <span class="fu">tibble</span>(<span class="at">mu =</span> mu, <span class="at">phi =</span> phi),</span>
<span id="cb48-530"><a href="#cb48-530"></a>             <span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> phi),</span>
<span id="cb48-531"><a href="#cb48-531"></a>             <span class="at">color =</span> <span class="st">"gray20"</span>, <span class="at">size =</span> <span class="dv">5</span>, <span class="at">inherit.aes =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb48-532"><a href="#cb48-532"></a>  <span class="fu">labs</span>(</span>
<span id="cb48-533"><a href="#cb48-533"></a>    <span class="at">x =</span> glue<span class="sc">::</span><span class="fu">glue</span>(<span class="st">"Mean (\u03bc)</span><span class="sc">\n</span><span class="st">"</span>, </span>
<span id="cb48-534"><a href="#cb48-534"></a>                   <span class="st">"Point estimates for mean and"</span>, </span>
<span id="cb48-535"><a href="#cb48-535"></a>                   <span class="st">" dispersion from the full sample "</span>,</span>
<span id="cb48-536"><a href="#cb48-536"></a>                   <span class="st">"shown in black"</span>),</span>
<span id="cb48-537"><a href="#cb48-537"></a>    <span class="at">y =</span> <span class="st">"Dispersion (\u03d5)"</span></span>
<span id="cb48-538"><a href="#cb48-538"></a>  ) <span class="sc">+</span></span>
<span id="cb48-539"><a href="#cb48-539"></a>  <span class="fu">theme</span>(</span>
<span id="cb48-540"><a href="#cb48-540"></a>    <span class="at">legend.position =</span> <span class="st">"inside"</span>,</span>
<span id="cb48-541"><a href="#cb48-541"></a>    <span class="at">legend.background =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb48-542"><a href="#cb48-542"></a>    <span class="at">legend.position.inside =</span> <span class="fu">c</span>(<span class="fl">0.8</span>, <span class="fl">0.18</span>)</span>
<span id="cb48-543"><a href="#cb48-543"></a>  ) <span class="sc">+</span></span>
<span id="cb48-544"><a href="#cb48-544"></a>  <span class="fu">guides</span>(<span class="at">color =</span> <span class="fu">guide_legend</span>(<span class="at">nrow =</span> <span class="dv">2</span>))</span>
<span id="cb48-545"><a href="#cb48-545"></a></span>
<span id="cb48-546"><a href="#cb48-546"></a><span class="co"># this thorws warnings that bins are ignored, but </span></span>
<span id="cb48-547"><a href="#cb48-547"></a><span class="co"># the correct behaviour is observed anyway</span></span>
<span id="cb48-548"><a href="#cb48-548"></a>ggExtra<span class="sc">::</span><span class="fu">ggMarginal</span>(</span>
<span id="cb48-549"><a href="#cb48-549"></a>  <span class="at">p =</span> mu_phi_plot, <span class="at">type =</span> <span class="st">"densigram"</span>, </span>
<span id="cb48-550"><a href="#cb48-550"></a>  <span class="at">xparams =</span> <span class="fu">list</span>(<span class="at">bins =</span> <span class="dv">100</span>), </span>
<span id="cb48-551"><a href="#cb48-551"></a>  <span class="at">yparams =</span> <span class="fu">list</span>(<span class="at">bins =</span> <span class="dv">100</span>)</span>
<span id="cb48-552"><a href="#cb48-552"></a>)</span>
<span id="cb48-553"><a href="#cb48-553"></a><span class="in">```</span></span>
<span id="cb48-554"><a href="#cb48-554"></a></span>
<span id="cb48-555"><a href="#cb48-555"></a>The clustering of points was initially a bit puzzling. The marginal density for the mean (top) is the same as the multimodal bootstrap distribution from a few sections above. The density for dispersion seems to be a lot less well-behaved. Coloring by the number of times that the original sample maximum claim amount is sampled in the bootstrap datasets, it's clear that the frequency of occurrence is largely responsible for the clustering observed here.</span>
<span id="cb48-556"><a href="#cb48-556"></a></span>
<span id="cb48-557"><a href="#cb48-557"></a>In the second stage, a random pair $(\hat\mu_{\text{int}, b}, \hat\phi_{\text{int}, b})$ is drawn first, followed by drawing $n$ values $Y_{i, b}^* \sim \text{Tweedie}(\hat\mu_{\text{int}, b}, \hat\phi_{\text{int}, b}, p = 1.6)$, and summing these to get an estimate of the total claim amount $\hat{T_b}$.</span>
<span id="cb48-558"><a href="#cb48-558"></a></span>
<span id="cb48-559"><a href="#cb48-559"></a>It is expected that accounting for uncertainty in the estimation of $(\hat\mu_{\text{int}}, \hat\phi_{\text{int}})$ should lead to thicker tails for the distribution of $\hat{T_b}$'s. The right tail now extends beyond 28 million and goes up to 34 million.</span>
<span id="cb48-560"><a href="#cb48-560"></a></span>
<span id="cb48-563"><a href="#cb48-563"></a><span class="in">```{r}</span></span>
<span id="cb48-564"><a href="#cb48-564"></a><span class="co"># sample Y_i from the posterior predictive distribution and sum them</span></span>
<span id="cb48-565"><a href="#cb48-565"></a><span class="co"># do this 10k times to get the posterior distribution</span></span>
<span id="cb48-566"><a href="#cb48-566"></a><span class="co"># posterior_distribution_samples_for_total_claims &lt;- map(</span></span>
<span id="cb48-567"><a href="#cb48-567"></a><span class="co">#   .x = 1:10000,</span></span>
<span id="cb48-568"><a href="#cb48-568"></a><span class="co">#   .f = ~ {</span></span>
<span id="cb48-569"><a href="#cb48-569"></a><span class="co">#     if(.x %% 100 == 0) {</span></span>
<span id="cb48-570"><a href="#cb48-570"></a><span class="co">#       print(.x)</span></span>
<span id="cb48-571"><a href="#cb48-571"></a><span class="co">#     }</span></span>
<span id="cb48-572"><a href="#cb48-572"></a><span class="co">#     set.seed(.x)</span></span>
<span id="cb48-573"><a href="#cb48-573"></a><span class="co">#     draw &lt;- bootstrap_mu_phi %&gt;%</span></span>
<span id="cb48-574"><a href="#cb48-574"></a><span class="co">#       slice_sample(n = 1)</span></span>
<span id="cb48-575"><a href="#cb48-575"></a><span class="co">#</span></span>
<span id="cb48-576"><a href="#cb48-576"></a><span class="co">#     set.seed(.x)</span></span>
<span id="cb48-577"><a href="#cb48-577"></a><span class="co">#     sum_values &lt;- draw %$%</span></span>
<span id="cb48-578"><a href="#cb48-578"></a><span class="co">#       tweedie::rtweedie(n = 60000, mu = mu, phi = phi, power = 1.6) %&gt;%</span></span>
<span id="cb48-579"><a href="#cb48-579"></a><span class="co">#       sum()</span></span>
<span id="cb48-580"><a href="#cb48-580"></a><span class="co">#</span></span>
<span id="cb48-581"><a href="#cb48-581"></a><span class="co">#     draw %&gt;%</span></span>
<span id="cb48-582"><a href="#cb48-582"></a><span class="co">#       mutate(total = sum_values)</span></span>
<span id="cb48-583"><a href="#cb48-583"></a><span class="co">#   }</span></span>
<span id="cb48-584"><a href="#cb48-584"></a><span class="co"># ) %&gt;%</span></span>
<span id="cb48-585"><a href="#cb48-585"></a><span class="co">#   list_rbind()</span></span>
<span id="cb48-586"><a href="#cb48-586"></a><span class="co">#</span></span>
<span id="cb48-587"><a href="#cb48-587"></a><span class="co"># saveRDS(posterior_distribution_samples_for_total_claims,</span></span>
<span id="cb48-588"><a href="#cb48-588"></a><span class="co">#         file = "posterior_distribution_samples_for_total_claims.rds")</span></span>
<span id="cb48-589"><a href="#cb48-589"></a></span>
<span id="cb48-590"><a href="#cb48-590"></a>posterior_distribution_samples_for_total_claims <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(</span>
<span id="cb48-591"><a href="#cb48-591"></a>  <span class="at">file =</span> <span class="st">"posterior_distribution_samples_for_total_claims.rds"</span></span>
<span id="cb48-592"><a href="#cb48-592"></a>)</span>
<span id="cb48-593"><a href="#cb48-593"></a></span>
<span id="cb48-594"><a href="#cb48-594"></a><span class="fu">summary</span>(posterior_distribution_samples_for_total_claims)</span>
<span id="cb48-595"><a href="#cb48-595"></a><span class="in">```</span></span>
<span id="cb48-596"><a href="#cb48-596"></a></span>
<span id="cb48-597"><a href="#cb48-597"></a><span class="fu">### Using properties of EDMs</span></span>
<span id="cb48-598"><a href="#cb48-598"></a></span>
<span id="cb48-599"><a href="#cb48-599"></a>This section uses two properties — sampling distribution of the weighted average, and scale invariance — of <span class="co">[</span><span class="ot">exponential dispersion models</span><span class="co">](https://en.wikipedia.org/wiki/Exponential_dispersion_model)</span> (EDMs) of which Tweedie distributions are a special case.</span>
<span id="cb48-600"><a href="#cb48-600"></a></span>
<span id="cb48-601"><a href="#cb48-601"></a>The main statistic of interest has been the weighted mean $T_{wm}$ of the pure premium values ($Y_i = Z_i / w_i$)</span>
<span id="cb48-602"><a href="#cb48-602"></a></span>
<span id="cb48-603"><a href="#cb48-603"></a>$$</span>
<span id="cb48-604"><a href="#cb48-604"></a>T_{wm} = w_{\bullet}^{-1} \sum_{i = 1}^n w_i Y_i</span>
<span id="cb48-605"><a href="#cb48-605"></a>$$</span>
<span id="cb48-606"><a href="#cb48-606"></a></span>
<span id="cb48-607"><a href="#cb48-607"></a>where $w_{\bullet} = \sum_i w_i$ is the sum of the exposures. If $Y_i \sim \text{Tweedie}(\mu, \phi / w_i, p)$, then the sampling distribution of the weighted mean is also a Tweedie distribution with the same mean but with the dispersion $\phi$ scaled by the total exposure, i.e., $T_{wm} \sim \text{Tweedie}(\mu, \phi / w_{\bullet}, p)$.</span>
<span id="cb48-608"><a href="#cb48-608"></a></span>
<span id="cb48-609"><a href="#cb48-609"></a>The scale invariance property says that</span>
<span id="cb48-610"><a href="#cb48-610"></a></span>
<span id="cb48-611"><a href="#cb48-611"></a>$$</span>
<span id="cb48-612"><a href="#cb48-612"></a>c \text{Tweedie}(\mu, \phi, p) = \text{Tweedie}(c \mu, c^{2-p} \phi, p)</span>
<span id="cb48-613"><a href="#cb48-613"></a>$$</span>
<span id="cb48-614"><a href="#cb48-614"></a></span>
<span id="cb48-615"><a href="#cb48-615"></a>Combining these two and setting $c = 60,000$ since we're interested in the total claim amount across the policies, we can write</span>
<span id="cb48-616"><a href="#cb48-616"></a></span>
<span id="cb48-617"><a href="#cb48-617"></a>$$</span>
<span id="cb48-618"><a href="#cb48-618"></a>T_\text{total} \sim \text{Tweedie}(60000 \mu, 60000^{2-p} \phi / w_{\bullet}, p)</span>
<span id="cb48-619"><a href="#cb48-619"></a>$$</span>
<span id="cb48-620"><a href="#cb48-620"></a></span>
<span id="cb48-621"><a href="#cb48-621"></a>This is much simpler and faster than the parametric bootstrap (for the weighted mean $T_{wm}$) since we don't need to sample the vector of $Y_{i, b}^*$'s as an intermediate step<span class="ot">[^3]</span>.</span>
<span id="cb48-622"><a href="#cb48-622"></a></span>
<span id="cb48-623"><a href="#cb48-623"></a><span class="ot">[^3]: </span>Of course the parametric bootstrap is much more general, so it's not really a fair comparison.</span>
<span id="cb48-624"><a href="#cb48-624"></a></span>
<span id="cb48-627"><a href="#cb48-627"></a><span class="in">```{r}</span></span>
<span id="cb48-628"><a href="#cb48-628"></a><span class="co">#| code-fold: false</span></span>
<span id="cb48-629"><a href="#cb48-629"></a></span>
<span id="cb48-630"><a href="#cb48-630"></a>total_exposure <span class="ot">&lt;-</span> claims <span class="sc">%&gt;%</span> </span>
<span id="cb48-631"><a href="#cb48-631"></a>  <span class="fu">pull</span>(Exposure) <span class="sc">%&gt;%</span> </span>
<span id="cb48-632"><a href="#cb48-632"></a>  <span class="fu">sum</span>()</span>
<span id="cb48-633"><a href="#cb48-633"></a></span>
<span id="cb48-634"><a href="#cb48-634"></a><span class="fu">set.seed</span>(<span class="dv">43</span>)</span>
<span id="cb48-635"><a href="#cb48-635"></a>predicted_totals_tweedie_sampling_dist <span class="ot">&lt;-</span> tweedie<span class="sc">::</span><span class="fu">rtweedie</span>(</span>
<span id="cb48-636"><a href="#cb48-636"></a>  <span class="at">n =</span> <span class="dv">10000</span>,</span>
<span id="cb48-637"><a href="#cb48-637"></a>  <span class="at">mu =</span> <span class="dv">60000</span> <span class="sc">*</span> mu,</span>
<span id="cb48-638"><a href="#cb48-638"></a>  <span class="at">phi =</span> ((<span class="dv">60000</span> <span class="sc">^</span> (<span class="dv">2</span> <span class="sc">-</span> <span class="fl">1.6</span>)) <span class="sc">*</span> phi) <span class="sc">/</span> total_exposure,</span>
<span id="cb48-639"><a href="#cb48-639"></a>  <span class="at">power =</span> <span class="fl">1.6</span></span>
<span id="cb48-640"><a href="#cb48-640"></a>)</span>
<span id="cb48-641"><a href="#cb48-641"></a></span>
<span id="cb48-642"><a href="#cb48-642"></a>predicted_totals_tweedie_sampling_dist <span class="sc">%&gt;%</span> <span class="fu">summary</span>()</span>
<span id="cb48-643"><a href="#cb48-643"></a><span class="in">```</span></span>
<span id="cb48-644"><a href="#cb48-644"></a></span>
<span id="cb48-645"><a href="#cb48-645"></a><span class="fu">### GLM with predictors</span></span>
<span id="cb48-646"><a href="#cb48-646"></a></span>
<span id="cb48-647"><a href="#cb48-647"></a>So far, we've ignored all other variables in the data that provide information at the level of the policyholder, and modelled the marginal distribution of the pure premiums. Using this so-called *collective* model can be contrasted with the *individual* model where information at the policy level can be used for modelling individual risk.</span>
<span id="cb48-648"><a href="#cb48-648"></a></span>
<span id="cb48-649"><a href="#cb48-649"></a>The simplest extension to the intercept-only model is the *main effects* model which includes all the additional variables at the policy level in the model</span>
<span id="cb48-650"><a href="#cb48-650"></a></span>
<span id="cb48-651"><a href="#cb48-651"></a>$$</span>
<span id="cb48-652"><a href="#cb48-652"></a>\begin{align*}</span>
<span id="cb48-653"><a href="#cb48-653"></a>Y_i &amp;\sim \text{Tweedie}(\mu_i = \text{exp}(\text{log}(E<span class="co">[</span><span class="ot">Y_i</span><span class="co">]</span>)), \phi, p) <span class="sc">\\</span></span>
<span id="cb48-654"><a href="#cb48-654"></a>\text{log}(E<span class="co">[</span><span class="ot">Y_i</span><span class="co">]</span>) &amp;= \beta_0 + \beta_1 x_{i, 1} + \dots + \beta_p x_{i, p}</span>
<span id="cb48-655"><a href="#cb48-655"></a>\end{align*}</span>
<span id="cb48-656"><a href="#cb48-656"></a>$$</span>
<span id="cb48-657"><a href="#cb48-657"></a></span>
<span id="cb48-658"><a href="#cb48-658"></a>For simplicity, linearity and additivity of the predictors are assumed on the log scale, which leads to a multiplicative model on the original scale. This has the additional advantage of ensuring that the expected values can never be less than 0 (since $\mu &gt; 0$). Using boosted trees (e.g. LightGBM) would be a natural next step for improvement as they can model interactions, carry out variable selection by dropping terms that don't impact risk, don't impose functional form restrictions, etc. and can lead to more accurate predictions.</span>
<span id="cb48-659"><a href="#cb48-659"></a></span>
<span id="cb48-660"><a href="#cb48-660"></a>The following code fits a Tweedie GLM to the pure premium values $y_i$ with exposure weights $w_i$ using the log link (<span class="in">`link.power = 0`</span>) and fixing $p = 1.6$.</span>
<span id="cb48-661"><a href="#cb48-661"></a></span>
<span id="cb48-664"><a href="#cb48-664"></a><span class="in">```{r}</span></span>
<span id="cb48-665"><a href="#cb48-665"></a><span class="co">#| code-fold: false</span></span>
<span id="cb48-666"><a href="#cb48-666"></a></span>
<span id="cb48-667"><a href="#cb48-667"></a>claims_modelling <span class="ot">&lt;-</span> claims <span class="sc">%&gt;%</span></span>
<span id="cb48-668"><a href="#cb48-668"></a>  <span class="fu">mutate</span>(</span>
<span id="cb48-669"><a href="#cb48-669"></a>    <span class="fu">across</span>(<span class="fu">c</span>(Area, VehPower, VehBrand, VehGas, Region), <span class="sc">~</span> <span class="fu">as.factor</span>(.x)),</span>
<span id="cb48-670"><a href="#cb48-670"></a>    <span class="at">pure_premium =</span> ClaimAmount <span class="sc">/</span> Exposure</span>
<span id="cb48-671"><a href="#cb48-671"></a>  )</span>
<span id="cb48-672"><a href="#cb48-672"></a></span>
<span id="cb48-673"><a href="#cb48-673"></a>main_effects_glm <span class="ot">&lt;-</span> <span class="fu">glm</span>(</span>
<span id="cb48-674"><a href="#cb48-674"></a>  pure_premium <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> Area <span class="sc">+</span> VehPower <span class="sc">+</span> VehAge <span class="sc">+</span> DrivAge</span>
<span id="cb48-675"><a href="#cb48-675"></a>  <span class="sc">+</span> BonusMalus <span class="sc">+</span> VehBrand <span class="sc">+</span> VehGas <span class="sc">+</span> Density <span class="sc">+</span> Region,</span>
<span id="cb48-676"><a href="#cb48-676"></a>  <span class="at">weights =</span> Exposure,</span>
<span id="cb48-677"><a href="#cb48-677"></a>  <span class="at">data =</span> claims_modelling,</span>
<span id="cb48-678"><a href="#cb48-678"></a>  <span class="at">family =</span> statmod<span class="sc">::</span><span class="fu">tweedie</span>(<span class="at">var.power =</span> <span class="fl">1.6</span>, <span class="at">link.power =</span> <span class="dv">0</span>)</span>
<span id="cb48-679"><a href="#cb48-679"></a>)</span>
<span id="cb48-680"><a href="#cb48-680"></a><span class="in">```</span></span>
<span id="cb48-681"><a href="#cb48-681"></a></span>
<span id="cb48-682"><a href="#cb48-682"></a>Given the increase in complexity of this model and to eventually try more complex models, it would be good to switch to cross-validation to see how well this model performs on unseen data. I'll get to this in a future post.</span>
<span id="cb48-683"><a href="#cb48-683"></a></span>
<span id="cb48-684"><a href="#cb48-684"></a>It can be informative to explore the fitted values.</span>
<span id="cb48-685"><a href="#cb48-685"></a></span>
<span id="cb48-688"><a href="#cb48-688"></a><span class="in">```{r}</span></span>
<span id="cb48-689"><a href="#cb48-689"></a>fitted_values <span class="ot">&lt;-</span> main_effects_glm <span class="sc">%&gt;%</span></span>
<span id="cb48-690"><a href="#cb48-690"></a>  broom<span class="sc">::</span><span class="fu">augment</span>(<span class="at">newdata =</span> claims_modelling, <span class="at">type.predict =</span> <span class="st">"response"</span>)</span>
<span id="cb48-691"><a href="#cb48-691"></a></span>
<span id="cb48-692"><a href="#cb48-692"></a>mean_fitted <span class="ot">&lt;-</span> fitted_values <span class="sc">%&gt;%</span></span>
<span id="cb48-693"><a href="#cb48-693"></a>  <span class="fu">pull</span>(<span class="st">".fitted"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb48-694"><a href="#cb48-694"></a>  <span class="fu">mean</span>()</span>
<span id="cb48-695"><a href="#cb48-695"></a></span>
<span id="cb48-696"><a href="#cb48-696"></a>fitted_values <span class="sc">%&gt;%</span></span>
<span id="cb48-697"><a href="#cb48-697"></a>  <span class="fu">pull</span>(.fitted) <span class="sc">%&gt;%</span></span>
<span id="cb48-698"><a href="#cb48-698"></a>  <span class="fu">quantile</span>(</span>
<span id="cb48-699"><a href="#cb48-699"></a>    <span class="at">probs =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">0.95</span>, <span class="fl">0.99</span>, <span class="fl">1.0</span>)</span>
<span id="cb48-700"><a href="#cb48-700"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb48-701"><a href="#cb48-701"></a>  <span class="fu">c</span>(., <span class="st">"Mean"</span> <span class="ot">=</span> mean_fitted) <span class="sc">%&gt;%</span></span>
<span id="cb48-702"><a href="#cb48-702"></a>  <span class="fu">sort</span>() <span class="sc">%&gt;%</span></span>
<span id="cb48-703"><a href="#cb48-703"></a>  <span class="fu">round</span>(., <span class="dv">2</span>)</span>
<span id="cb48-704"><a href="#cb48-704"></a><span class="in">```</span></span>
<span id="cb48-705"><a href="#cb48-705"></a></span>
<span id="cb48-706"><a href="#cb48-706"></a>The least risky policy has an expected value of 6.2 and 50% of the policies have an expected value less than 140. Fewer than 1% of the policies have a risk larger than 2000, but the riskiest policy has an expected value of about 300,000. Since this is a simple main effects model, it's easy enough to see which term(s) contribute towards these very high values for the top-10 policies with the largest pure premium values</span>
<span id="cb48-707"><a href="#cb48-707"></a></span>
<span id="cb48-710"><a href="#cb48-710"></a><span class="in">```{r}</span></span>
<span id="cb48-711"><a href="#cb48-711"></a><span class="co">#| code-fold: false</span></span>
<span id="cb48-712"><a href="#cb48-712"></a></span>
<span id="cb48-713"><a href="#cb48-713"></a><span class="co"># get the term-wise contribution to the prediction on the</span></span>
<span id="cb48-714"><a href="#cb48-714"></a><span class="co"># link scale for the top k largest predictions</span></span>
<span id="cb48-715"><a href="#cb48-715"></a>top_10_largest_policy_predictions <span class="ot">&lt;-</span> fitted_values <span class="sc">%&gt;%</span></span>
<span id="cb48-716"><a href="#cb48-716"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(.fitted)) <span class="sc">%&gt;%</span></span>
<span id="cb48-717"><a href="#cb48-717"></a>  <span class="fu">slice_head</span>(<span class="at">n =</span> <span class="dv">10</span>)</span>
<span id="cb48-718"><a href="#cb48-718"></a></span>
<span id="cb48-719"><a href="#cb48-719"></a>top_10_largest_policy_predictions <span class="sc">%&gt;%</span> </span>
<span id="cb48-720"><a href="#cb48-720"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span>
<span id="cb48-721"><a href="#cb48-721"></a></span>
<span id="cb48-722"><a href="#cb48-722"></a>top_10_largest_policy_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(</span>
<span id="cb48-723"><a href="#cb48-723"></a>  <span class="at">object =</span> main_effects_glm, </span>
<span id="cb48-724"><a href="#cb48-724"></a>  <span class="at">newdata =</span> top_10_largest_policy_predictions, </span>
<span id="cb48-725"><a href="#cb48-725"></a>  <span class="at">type =</span> <span class="st">"terms"</span></span>
<span id="cb48-726"><a href="#cb48-726"></a>)</span>
<span id="cb48-727"><a href="#cb48-727"></a></span>
<span id="cb48-728"><a href="#cb48-728"></a><span class="co"># convert the 'terms' data frame to tibble and add constant value</span></span>
<span id="cb48-729"><a href="#cb48-729"></a><span class="co"># then pivot to get the exp(cumsum()) for each policy (i.e. row)</span></span>
<span id="cb48-730"><a href="#cb48-730"></a><span class="co"># then pivot back</span></span>
<span id="cb48-731"><a href="#cb48-731"></a><span class="co"># there's probably some neat function that does </span></span>
<span id="cb48-732"><a href="#cb48-732"></a><span class="co"># this in fewer lines of code</span></span>
<span id="cb48-733"><a href="#cb48-733"></a>top_10_largest_policy_predictions <span class="sc">%&gt;%</span></span>
<span id="cb48-734"><a href="#cb48-734"></a>  <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span></span>
<span id="cb48-735"><a href="#cb48-735"></a>  <span class="fu">mutate</span>(</span>
<span id="cb48-736"><a href="#cb48-736"></a>    <span class="at">id =</span> <span class="fu">row_number</span>(),</span>
<span id="cb48-737"><a href="#cb48-737"></a>    <span class="co"># for the calculation of the constant value, see this</span></span>
<span id="cb48-738"><a href="#cb48-738"></a>    <span class="co"># https://stackoverflow.com/questions/37963904/what-does-predict-glm-type-terms-actually-do</span></span>
<span id="cb48-739"><a href="#cb48-739"></a>    <span class="at">constant =</span> <span class="fu">attr</span>(top_10_largest_policy_predictions, <span class="st">"constant"</span>),</span>
<span id="cb48-740"><a href="#cb48-740"></a>    <span class="at">.before =</span> <span class="dv">0</span></span>
<span id="cb48-741"><a href="#cb48-741"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb48-742"><a href="#cb48-742"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="sc">-</span>id) <span class="sc">%&gt;%</span></span>
<span id="cb48-743"><a href="#cb48-743"></a>  <span class="fu">group_by</span>(id) <span class="sc">%&gt;%</span></span>
<span id="cb48-744"><a href="#cb48-744"></a>  <span class="fu">mutate</span>(<span class="at">value =</span> <span class="fu">exp</span>(<span class="fu">cumsum</span>(value))) <span class="sc">%&gt;%</span></span>
<span id="cb48-745"><a href="#cb48-745"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb48-746"><a href="#cb48-746"></a>  <span class="fu">pivot_wider</span>(<span class="at">id_cols =</span> id, <span class="at">names_from =</span> name, <span class="at">values_from =</span> value) <span class="sc">%&gt;%</span></span>
<span id="cb48-747"><a href="#cb48-747"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="at">.cols =</span> <span class="fu">everything</span>(), <span class="at">.fns =</span> round)) <span class="sc">%&gt;%</span> </span>
<span id="cb48-748"><a href="#cb48-748"></a>  <span class="fu">select</span>(<span class="sc">-</span>id) <span class="sc">%&gt;%</span></span>
<span id="cb48-749"><a href="#cb48-749"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span>
<span id="cb48-750"><a href="#cb48-750"></a><span class="in">```</span></span>
<span id="cb48-751"><a href="#cb48-751"></a></span>
<span id="cb48-752"><a href="#cb48-752"></a>Looking at the contribution of each term for a given policy shows that high values of <span class="in">`BonusMalus`</span> (with a coefficient of <span class="in">`{r} round(coef(main_effects_glm)["BonusMalus"], 3)`</span> on the log scale) has the largest impact on pushing up the predicted pure premiums. Obviously, for more complex models, SHAP plots would provide similar information in terms of identifying features that contribute to very high (or low) predicted values for the policies of interest.</span>
<span id="cb48-753"><a href="#cb48-753"></a></span>
<span id="cb48-754"><a href="#cb48-754"></a>The distribution of fitted values can be visualized too</span>
<span id="cb48-755"><a href="#cb48-755"></a></span>
<span id="cb48-758"><a href="#cb48-758"></a><span class="in">```{r}</span></span>
<span id="cb48-759"><a href="#cb48-759"></a>fitted_values <span class="sc">%&gt;%</span></span>
<span id="cb48-760"><a href="#cb48-760"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> .fitted)) <span class="sc">+</span></span>
<span id="cb48-761"><a href="#cb48-761"></a>  <span class="fu">stat_ecdf</span>() <span class="sc">+</span></span>
<span id="cb48-762"><a href="#cb48-762"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> mu, <span class="at">color =</span> <span class="st">"orange"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb48-763"><a href="#cb48-763"></a>  <span class="fu">annotate</span>(<span class="at">geom =</span> <span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">200</span>, <span class="at">y =</span> <span class="fl">0.8</span>, <span class="at">color =</span> <span class="st">"orange"</span>,</span>
<span id="cb48-764"><a href="#cb48-764"></a>           <span class="at">label =</span> <span class="st">"Marginal mean: 217.8"</span>, <span class="at">hjust =</span> <span class="st">"right"</span>) <span class="sc">+</span></span>
<span id="cb48-765"><a href="#cb48-765"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> mean_fitted, <span class="at">color =</span> <span class="st">"red4"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb48-766"><a href="#cb48-766"></a>  <span class="fu">annotate</span>(<span class="at">geom =</span> <span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">275</span>, <span class="at">y =</span> <span class="fl">0.5</span>, <span class="at">color =</span> <span class="st">"red4"</span>,</span>
<span id="cb48-767"><a href="#cb48-767"></a>           <span class="at">label =</span> <span class="st">"Fitted values mean: 256.3"</span>, <span class="at">hjust =</span> <span class="st">"left"</span>) <span class="sc">+</span></span>
<span id="cb48-768"><a href="#cb48-768"></a>  <span class="fu">scale_x_log10</span>(</span>
<span id="cb48-769"><a href="#cb48-769"></a>    <span class="at">breaks =</span> scales<span class="sc">::</span><span class="fu">trans_breaks</span>(<span class="st">"log10"</span>, <span class="cf">function</span>(x) <span class="dv">10</span><span class="sc">^</span>x),</span>
<span id="cb48-770"><a href="#cb48-770"></a>    <span class="at">labels =</span> scales<span class="sc">::</span><span class="fu">trans_format</span>(<span class="st">"log10"</span>, scales<span class="sc">::</span><span class="fu">math_format</span>(<span class="dv">10</span><span class="sc">^</span>.x))</span>
<span id="cb48-771"><a href="#cb48-771"></a>  ) <span class="sc">+</span></span>
<span id="cb48-772"><a href="#cb48-772"></a>  <span class="fu">annotation_logticks</span>(<span class="at">sides =</span> <span class="st">"b"</span>) <span class="sc">+</span></span>
<span id="cb48-773"><a href="#cb48-773"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span>percent) <span class="sc">+</span></span>
<span id="cb48-774"><a href="#cb48-774"></a>  <span class="fu">xlab</span>(<span class="st">"Fitted pure premium values"</span>) <span class="sc">+</span></span>
<span id="cb48-775"><a href="#cb48-775"></a>  <span class="fu">ylab</span>(<span class="st">"Empirical distribution function"</span>)</span>
<span id="cb48-776"><a href="#cb48-776"></a><span class="in">```</span></span>
<span id="cb48-777"><a href="#cb48-777"></a></span>
<span id="cb48-778"><a href="#cb48-778"></a>The overall mean from the intercept only model and the mean of the fitted values don't coincide, which I wasn't expecting given the <span class="co">[</span><span class="ot">*law of iterated expectation*</span><span class="co">](https://en.wikipedia.org/wiki/Law_of_total_expectation)</span> (LIE) where $E<span class="co">[</span><span class="ot">Y</span><span class="co">]</span> = E<span class="co">[</span><span class="ot">E[Y | X]</span><span class="co">]</span>$ holds. After puzzling over this for a bit and looking around on the internet, this seems to be due to the use of the non-canonical log-link function $g(\mu) = \text{log}(\mu)$. Using the canonical link function for a Tweedie distribution $g(\mu) = \mu^{(1 - p)} / (1-p)$ results in LIE holding, but attempting to fit the main effects model with the canonical link fails in R.</span>
<span id="cb48-779"><a href="#cb48-779"></a></span>
<span id="cb48-782"><a href="#cb48-782"></a><span class="in">```{r}</span></span>
<span id="cb48-783"><a href="#cb48-783"></a><span class="co">#| error: true</span></span>
<span id="cb48-784"><a href="#cb48-784"></a><span class="co">#| code-fold: false</span></span>
<span id="cb48-785"><a href="#cb48-785"></a></span>
<span id="cb48-786"><a href="#cb48-786"></a>main_effects_glm <span class="sc">%&gt;%</span> </span>
<span id="cb48-787"><a href="#cb48-787"></a>  <span class="fu">update</span>(</span>
<span id="cb48-788"><a href="#cb48-788"></a>    <span class="co"># the default link function is the canonical link function</span></span>
<span id="cb48-789"><a href="#cb48-789"></a>    <span class="at">family =</span> statmod<span class="sc">::</span><span class="fu">tweedie</span>(<span class="at">var.power =</span> <span class="fl">1.6</span>)</span>
<span id="cb48-790"><a href="#cb48-790"></a>  )</span>
<span id="cb48-791"><a href="#cb48-791"></a><span class="in">```</span></span>
<span id="cb48-792"><a href="#cb48-792"></a></span>
<span id="cb48-793"><a href="#cb48-793"></a>The disadvantages of using the canonical link for Tweedie models are numerical instability, and interpretation issues (since risks are not multiplicative as a function of predictors).</span>
<span id="cb48-794"><a href="#cb48-794"></a></span>
<span id="cb48-795"><a href="#cb48-795"></a>For simulating the sampling distribution of total claims across the policies, the same approach as the one from the parametric bootstrap section can be applied using the usual Pearson estimate of scale $\phi$.</span>
<span id="cb48-796"><a href="#cb48-796"></a></span>
<span id="cb48-799"><a href="#cb48-799"></a><span class="in">```{r}</span></span>
<span id="cb48-800"><a href="#cb48-800"></a><span class="co">#| code-fold: false</span></span>
<span id="cb48-801"><a href="#cb48-801"></a></span>
<span id="cb48-802"><a href="#cb48-802"></a>phi_glm <span class="ot">&lt;-</span> main_effects_glm <span class="sc">%&gt;%</span> </span>
<span id="cb48-803"><a href="#cb48-803"></a>  <span class="fu">summary</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb48-804"><a href="#cb48-804"></a>  <span class="fu">pluck</span>(<span class="st">"dispersion"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb48-805"><a href="#cb48-805"></a>  <span class="fu">print</span>()</span>
<span id="cb48-806"><a href="#cb48-806"></a><span class="in">```</span></span>
<span id="cb48-807"><a href="#cb48-807"></a></span>
<span id="cb48-808"><a href="#cb48-808"></a>The estimated value of $\hat\phi_{\text{main}} \approx 4529$ is much smaller compared to the intercept-only model with value $\hat\phi_{\text{int}} \approx 25966$. Sampling 10,000 datasets of size 60,000 with policy-specific conditional means from the individual model $\hat\mu_i$'s and $\hat\phi_{\text{main}}$ and summing the values for each dataset now gives estimates ranging from 9 million to 52 million. The maximum possible claim amount is much much higher here compared to the 35 million from the collective model.</span>
<span id="cb48-809"><a href="#cb48-809"></a></span>
<span id="cb48-812"><a href="#cb48-812"></a><span class="in">```{r}</span></span>
<span id="cb48-813"><a href="#cb48-813"></a><span class="co"># simulate 10,000 times the total claim amounts for the full year of exposure</span></span>
<span id="cb48-814"><a href="#cb48-814"></a><span class="co"># using the fitted means</span></span>
<span id="cb48-815"><a href="#cb48-815"></a><span class="co"># predicted_totals_from_glm &lt;- map_dbl(.x = 1:10000, .f = ~ {</span></span>
<span id="cb48-816"><a href="#cb48-816"></a><span class="co">#   if(.x %% 100 == 0) {</span></span>
<span id="cb48-817"><a href="#cb48-817"></a><span class="co">#     print(.x)</span></span>
<span id="cb48-818"><a href="#cb48-818"></a><span class="co">#   }</span></span>
<span id="cb48-819"><a href="#cb48-819"></a><span class="co">#   set.seed(.x)</span></span>
<span id="cb48-820"><a href="#cb48-820"></a><span class="co">#   sum(tweedie::rtweedie(60000, mu = fitted_values$.fitted, </span></span>
<span id="cb48-821"><a href="#cb48-821"></a><span class="co">#                         phi = phi_glm, power = 1.6))</span></span>
<span id="cb48-822"><a href="#cb48-822"></a><span class="co"># })</span></span>
<span id="cb48-823"><a href="#cb48-823"></a><span class="co">#</span></span>
<span id="cb48-824"><a href="#cb48-824"></a><span class="co"># saveRDS(predicted_totals_from_glm,</span></span>
<span id="cb48-825"><a href="#cb48-825"></a><span class="co">#         file = "predicted_totals_from_glm.rds")</span></span>
<span id="cb48-826"><a href="#cb48-826"></a></span>
<span id="cb48-827"><a href="#cb48-827"></a>predicted_totals_from_glm <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(</span>
<span id="cb48-828"><a href="#cb48-828"></a>  <span class="at">file =</span> <span class="st">"predicted_totals_from_glm.rds"</span></span>
<span id="cb48-829"><a href="#cb48-829"></a>)</span>
<span id="cb48-830"><a href="#cb48-830"></a></span>
<span id="cb48-831"><a href="#cb48-831"></a><span class="fu">summary</span>(predicted_totals_from_glm)</span>
<span id="cb48-832"><a href="#cb48-832"></a><span class="in">```</span></span>
<span id="cb48-833"><a href="#cb48-833"></a></span>
<span id="cb48-834"><a href="#cb48-834"></a>Sample statistics for the observed data with exposure $w_i$ can be compared with the statistics from the intercept-only and main-effects GLMs as a form of PPC. Looking at the summary statistics for the main effects model, there are more policies with non-zero claims (266 on average) compared with the PPC from the intercept only model (28 on average), but still very far off from the 3051 that are in the observed data.</span>
<span id="cb48-835"><a href="#cb48-835"></a></span>
<span id="cb48-838"><a href="#cb48-838"></a><span class="in">```{r}</span></span>
<span id="cb48-839"><a href="#cb48-839"></a><span class="co"># quick check of sampling dist of statistics</span></span>
<span id="cb48-840"><a href="#cb48-840"></a><span class="co"># ppc_glm_obs_exposure &lt;- map(</span></span>
<span id="cb48-841"><a href="#cb48-841"></a><span class="co">#   .x = 1:1000,</span></span>
<span id="cb48-842"><a href="#cb48-842"></a><span class="co">#   .f = ~ {</span></span>
<span id="cb48-843"><a href="#cb48-843"></a><span class="co">#     if(.x %% 50 == 0) {</span></span>
<span id="cb48-844"><a href="#cb48-844"></a><span class="co">#       print(.x)</span></span>
<span id="cb48-845"><a href="#cb48-845"></a><span class="co">#     }</span></span>
<span id="cb48-846"><a href="#cb48-846"></a><span class="co">#     set.seed(.x)</span></span>
<span id="cb48-847"><a href="#cb48-847"></a><span class="co">#     draw &lt;- (fitted_values$Exposure *</span></span>
<span id="cb48-848"><a href="#cb48-848"></a><span class="co">#                tweedie::rtweedie(60000,</span></span>
<span id="cb48-849"><a href="#cb48-849"></a><span class="co">#                                  mu = fitted_values$.fitted,</span></span>
<span id="cb48-850"><a href="#cb48-850"></a><span class="co">#                                  phi = phi_glm, power = 1.6))</span></span>
<span id="cb48-851"><a href="#cb48-851"></a><span class="co">#</span></span>
<span id="cb48-852"><a href="#cb48-852"></a><span class="co">#     tibble(prop_zero = mean(draw == 0), sample_total = sum(draw),</span></span>
<span id="cb48-853"><a href="#cb48-853"></a><span class="co">#            sample_max = max(draw), n_nonzero = sum(draw &gt; 0))</span></span>
<span id="cb48-854"><a href="#cb48-854"></a><span class="co">#   }) %&gt;%</span></span>
<span id="cb48-855"><a href="#cb48-855"></a><span class="co">#   list_rbind()</span></span>
<span id="cb48-856"><a href="#cb48-856"></a><span class="co">#</span></span>
<span id="cb48-857"><a href="#cb48-857"></a><span class="co"># saveRDS(ppc_glm_obs_exposure, file = "ppc_glm_obs_exposure.rds")</span></span>
<span id="cb48-858"><a href="#cb48-858"></a></span>
<span id="cb48-859"><a href="#cb48-859"></a>ppc_glm_obs_exposure <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="at">file =</span> <span class="st">"ppc_glm_obs_exposure.rds"</span>)</span>
<span id="cb48-860"><a href="#cb48-860"></a></span>
<span id="cb48-861"><a href="#cb48-861"></a><span class="co"># function to convert the output of summary.data.frame() to a tibble</span></span>
<span id="cb48-862"><a href="#cb48-862"></a>tidy_df_summary <span class="ot">&lt;-</span> <span class="cf">function</span>(data) {</span>
<span id="cb48-863"><a href="#cb48-863"></a>  data <span class="sc">%&gt;%</span></span>
<span id="cb48-864"><a href="#cb48-864"></a>    <span class="fu">summary</span>() <span class="sc">%&gt;%</span></span>
<span id="cb48-865"><a href="#cb48-865"></a>    <span class="fu">as.data.frame</span>() <span class="sc">%&gt;%</span></span>
<span id="cb48-866"><a href="#cb48-866"></a>    <span class="fu">separate</span>(<span class="at">col =</span> Freq, <span class="at">into =</span> <span class="fu">c</span>(<span class="st">"Statistic"</span>, <span class="st">"Value"</span>), <span class="at">sep =</span> <span class="st">":"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb48-867"><a href="#cb48-867"></a>    <span class="fu">select</span>(<span class="sc">-</span>Var1) <span class="sc">%&gt;%</span></span>
<span id="cb48-868"><a href="#cb48-868"></a>    <span class="fu">rename</span>(<span class="at">Column =</span> Var2) <span class="sc">%&gt;%</span></span>
<span id="cb48-869"><a href="#cb48-869"></a>    <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> Statistic, <span class="at">values_from =</span> Value) <span class="sc">%&gt;%</span></span>
<span id="cb48-870"><a href="#cb48-870"></a>    <span class="fu">mutate</span>(</span>
<span id="cb48-871"><a href="#cb48-871"></a>      <span class="at">Column =</span> <span class="fu">str_trim</span>(Column, <span class="at">side =</span> <span class="st">"left"</span>),</span>
<span id="cb48-872"><a href="#cb48-872"></a>      <span class="fu">across</span>(</span>
<span id="cb48-873"><a href="#cb48-873"></a>        <span class="at">.cols =</span> <span class="fu">where</span>(is.character),</span>
<span id="cb48-874"><a href="#cb48-874"></a>        <span class="at">.fns =</span> <span class="sc">~</span> <span class="fu">str_trim</span>(.x, <span class="at">side =</span> <span class="st">"both"</span>)</span>
<span id="cb48-875"><a href="#cb48-875"></a>      )</span>
<span id="cb48-876"><a href="#cb48-876"></a>    )</span>
<span id="cb48-877"><a href="#cb48-877"></a>}</span>
<span id="cb48-878"><a href="#cb48-878"></a></span>
<span id="cb48-879"><a href="#cb48-879"></a><span class="fu">list</span>(</span>
<span id="cb48-880"><a href="#cb48-880"></a>  <span class="st">"Intercept"</span> <span class="ot">=</span> ppc_obs_exposure,</span>
<span id="cb48-881"><a href="#cb48-881"></a>  <span class="st">"Main effects"</span> <span class="ot">=</span> ppc_glm_obs_exposure,</span>
<span id="cb48-882"><a href="#cb48-882"></a>  <span class="st">"Observed"</span> <span class="ot">=</span> sample_statistics_obs_exposure</span>
<span id="cb48-883"><a href="#cb48-883"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb48-884"><a href="#cb48-884"></a>  <span class="fu">imap</span>(</span>
<span id="cb48-885"><a href="#cb48-885"></a>    <span class="at">.f =</span> <span class="sc">~</span> {</span>
<span id="cb48-886"><a href="#cb48-886"></a>      .x <span class="sc">%&gt;%</span></span>
<span id="cb48-887"><a href="#cb48-887"></a>        <span class="fu">tidy_df_summary</span>() <span class="sc">%&gt;%</span></span>
<span id="cb48-888"><a href="#cb48-888"></a>        <span class="fu">mutate</span>(<span class="at">Method =</span> .y, <span class="at">.before =</span> <span class="dv">1</span>)</span>
<span id="cb48-889"><a href="#cb48-889"></a>    }</span>
<span id="cb48-890"><a href="#cb48-890"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb48-891"><a href="#cb48-891"></a>  <span class="fu">list_rbind</span>() <span class="sc">%&gt;%</span></span>
<span id="cb48-892"><a href="#cb48-892"></a>  <span class="fu">mutate</span>(</span>
<span id="cb48-893"><a href="#cb48-893"></a>    <span class="at">Method =</span> <span class="fu">factor</span>(Method, </span>
<span id="cb48-894"><a href="#cb48-894"></a>                    <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"Observed"</span>, <span class="st">"Intercept"</span>, <span class="st">"Main effects"</span>))</span>
<span id="cb48-895"><a href="#cb48-895"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb48-896"><a href="#cb48-896"></a>  <span class="fu">arrange</span>(Column, Method) <span class="sc">%&gt;%</span> </span>
<span id="cb48-897"><a href="#cb48-897"></a>  <span class="fu">relocate</span>(Column, <span class="at">.before =</span> Method) <span class="sc">%&gt;%</span> </span>
<span id="cb48-898"><a href="#cb48-898"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span>
<span id="cb48-899"><a href="#cb48-899"></a><span class="in">```</span></span>
<span id="cb48-900"><a href="#cb48-900"></a></span>
<span id="cb48-901"><a href="#cb48-901"></a>The maximum claim amounts are much smaller — mean of 633k vs 1.4 mil in the observed data and 1.24 mil on average from the intercept-only PPC model.</span>
<span id="cb48-902"><a href="#cb48-902"></a></span>
<span id="cb48-905"><a href="#cb48-905"></a><span class="in">```{r}</span></span>
<span id="cb48-906"><a href="#cb48-906"></a><span class="co">#| code-fold: false</span></span>
<span id="cb48-907"><a href="#cb48-907"></a></span>
<span id="cb48-908"><a href="#cb48-908"></a><span class="fu">list</span>(</span>
<span id="cb48-909"><a href="#cb48-909"></a>  <span class="st">"Intercept"</span> <span class="ot">=</span> ppc_obs_exposure, </span>
<span id="cb48-910"><a href="#cb48-910"></a>  <span class="st">"Main effects"</span> <span class="ot">=</span> ppc_glm_obs_exposure</span>
<span id="cb48-911"><a href="#cb48-911"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb48-912"><a href="#cb48-912"></a>  <span class="fu">map</span>(<span class="at">.f =</span> <span class="sc">~</span> {</span>
<span id="cb48-913"><a href="#cb48-913"></a>    .x <span class="sc">%&gt;%</span></span>
<span id="cb48-914"><a href="#cb48-914"></a>      <span class="fu">mutate</span>(<span class="at">sample_gt_obs_max =</span> sample_max <span class="sc">&lt;=</span> <span class="fl">1404185.52</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb48-915"><a href="#cb48-915"></a>      <span class="fu">pull</span>(sample_gt_obs_max) <span class="sc">%&gt;%</span></span>
<span id="cb48-916"><a href="#cb48-916"></a>      <span class="fu">mean</span>()</span>
<span id="cb48-917"><a href="#cb48-917"></a>  })</span>
<span id="cb48-918"><a href="#cb48-918"></a><span class="in">```</span></span>
<span id="cb48-919"><a href="#cb48-919"></a></span>
<span id="cb48-920"><a href="#cb48-920"></a>For the intercept-only GLM, the observed maximum is larger than 70% of the maxima from the sampled datasets, compared to 94% of the maxima from the sampled datasets using the fitted values from the main effects GLM. In an ideal scenario, this should be about 50%.</span>
<span id="cb48-921"><a href="#cb48-921"></a></span>
<span id="cb48-922"><a href="#cb48-922"></a>The sample totals are all within about +/- 150k of each other.</span>
<span id="cb48-923"><a href="#cb48-923"></a></span>
<span id="cb48-924"><a href="#cb48-924"></a>Ten datasets are simulated, and only the policies with non-zero claim amounts are retained. The eCDF for each of these datasets are visually compared with the observed data. Since the model predicts a larger number of policies with non-zero claims, the distribution functions are smoother, and these functions are closer to the function for the observed sample (but still a very poor fit for the observed data).</span>
<span id="cb48-925"><a href="#cb48-925"></a></span>
<span id="cb48-928"><a href="#cb48-928"></a><span class="in">```{r}</span></span>
<span id="cb48-929"><a href="#cb48-929"></a><span class="fu">map</span>(</span>
<span id="cb48-930"><a href="#cb48-930"></a>  <span class="at">.x =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,</span>
<span id="cb48-931"><a href="#cb48-931"></a>  <span class="at">.f =</span> <span class="sc">~</span> {</span>
<span id="cb48-932"><a href="#cb48-932"></a>    <span class="fu">set.seed</span>(.x)</span>
<span id="cb48-933"><a href="#cb48-933"></a>    draw <span class="ot">&lt;-</span> (fitted_values<span class="sc">$</span>Exposure <span class="sc">*</span></span>
<span id="cb48-934"><a href="#cb48-934"></a>               tweedie<span class="sc">::</span><span class="fu">rtweedie</span>(<span class="dv">60000</span>,</span>
<span id="cb48-935"><a href="#cb48-935"></a>                                 <span class="at">mu =</span> fitted_values<span class="sc">$</span>.fitted,</span>
<span id="cb48-936"><a href="#cb48-936"></a>                                 <span class="at">phi =</span> phi_glm, <span class="at">power =</span> <span class="fl">1.6</span>))</span>
<span id="cb48-937"><a href="#cb48-937"></a>    <span class="fu">tibble</span>(<span class="at">sim_id =</span> .x, <span class="at">y =</span> draw, <span class="at">grp =</span> <span class="st">"Simulated"</span>)</span>
<span id="cb48-938"><a href="#cb48-938"></a>  }) <span class="sc">%&gt;%</span></span>
<span id="cb48-939"><a href="#cb48-939"></a>  <span class="fu">list_rbind</span>() <span class="sc">%&gt;%</span></span>
<span id="cb48-940"><a href="#cb48-940"></a>  <span class="fu">bind_rows</span>(</span>
<span id="cb48-941"><a href="#cb48-941"></a>    .,</span>
<span id="cb48-942"><a href="#cb48-942"></a>    claims <span class="sc">%&gt;%</span></span>
<span id="cb48-943"><a href="#cb48-943"></a>      <span class="fu">mutate</span>(<span class="at">sim_id =</span> <span class="dv">100</span>, <span class="at">grp =</span> <span class="st">"Observed"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb48-944"><a href="#cb48-944"></a>      <span class="fu">select</span>(sim_id, <span class="at">y =</span> ClaimAmount, grp)</span>
<span id="cb48-945"><a href="#cb48-945"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb48-946"><a href="#cb48-946"></a>  <span class="fu">filter</span>(y <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb48-947"><a href="#cb48-947"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> y, <span class="at">group =</span> sim_id, <span class="at">color =</span> grp)) <span class="sc">+</span></span>
<span id="cb48-948"><a href="#cb48-948"></a>  <span class="fu">stat_ecdf</span>() <span class="sc">+</span></span>
<span id="cb48-949"><a href="#cb48-949"></a>  <span class="fu">xlab</span>(<span class="st">"Policies with non-zero claim amounts (log10 scale)"</span>) <span class="sc">+</span></span>
<span id="cb48-950"><a href="#cb48-950"></a>  <span class="fu">ylab</span>(<span class="st">"Empirical distribution function"</span>) <span class="sc">+</span></span>
<span id="cb48-951"><a href="#cb48-951"></a>  <span class="fu">scale_x_log10</span>(</span>
<span id="cb48-952"><a href="#cb48-952"></a>    <span class="at">breaks =</span> scales<span class="sc">::</span><span class="fu">trans_breaks</span>(<span class="st">"log10"</span>, <span class="cf">function</span>(x) <span class="dv">10</span><span class="sc">^</span>x),</span>
<span id="cb48-953"><a href="#cb48-953"></a>    <span class="at">labels =</span> scales<span class="sc">::</span><span class="fu">trans_format</span>(<span class="st">"log10"</span>, scales<span class="sc">::</span><span class="fu">math_format</span>(<span class="dv">10</span><span class="sc">^</span>.x))</span>
<span id="cb48-954"><a href="#cb48-954"></a>  ) <span class="sc">+</span></span>
<span id="cb48-955"><a href="#cb48-955"></a>  <span class="fu">annotation_logticks</span>(<span class="at">sides =</span> <span class="st">"b"</span>) <span class="sc">+</span></span>
<span id="cb48-956"><a href="#cb48-956"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span>percent) <span class="sc">+</span></span>
<span id="cb48-957"><a href="#cb48-957"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb48-958"><a href="#cb48-958"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Simulated"</span> <span class="ot">=</span> <span class="st">"gray70"</span>, <span class="st">"Observed"</span> <span class="ot">=</span> <span class="st">"Black"</span>)</span>
<span id="cb48-959"><a href="#cb48-959"></a>  ) <span class="sc">+</span></span>
<span id="cb48-960"><a href="#cb48-960"></a>  <span class="fu">theme</span>(</span>
<span id="cb48-961"><a href="#cb48-961"></a>    <span class="at">legend.title =</span> <span class="fu">element_blank</span>(), </span>
<span id="cb48-962"><a href="#cb48-962"></a>    <span class="at">legend.position =</span> <span class="st">"inside"</span>,</span>
<span id="cb48-963"><a href="#cb48-963"></a>    <span class="at">legend.position.inside =</span> <span class="fu">c</span>(<span class="fl">0.9</span>, <span class="fl">0.2</span>)</span>
<span id="cb48-964"><a href="#cb48-964"></a>  )</span>
<span id="cb48-965"><a href="#cb48-965"></a><span class="in">```</span></span>
<span id="cb48-966"><a href="#cb48-966"></a></span>
<span id="cb48-967"><a href="#cb48-967"></a><span class="fu">## All the distributions together</span></span>
<span id="cb48-968"><a href="#cb48-968"></a></span>
<span id="cb48-969"><a href="#cb48-969"></a>Finally, all the different estimates for the distribution of next year's total claim amounts can be visualized together. First, the eCDFs are plotted together</span>
<span id="cb48-970"><a href="#cb48-970"></a></span>
<span id="cb48-973"><a href="#cb48-973"></a><span class="in">```{r}</span></span>
<span id="cb48-974"><a href="#cb48-974"></a>distributions_of_total_claims <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(</span>
<span id="cb48-975"><a href="#cb48-975"></a>  <span class="fu">tibble</span>(</span>
<span id="cb48-976"><a href="#cb48-976"></a>    <span class="at">method =</span> <span class="st">"Parametric Bootstrap (Tweedie MLE)"</span>,</span>
<span id="cb48-977"><a href="#cb48-977"></a>    <span class="at">total_claim_amount_in_millions =</span> predicted_totals_for_unit_exposure</span>
<span id="cb48-978"><a href="#cb48-978"></a>  ),</span>
<span id="cb48-979"><a href="#cb48-979"></a>  <span class="fu">tibble</span>(</span>
<span id="cb48-980"><a href="#cb48-980"></a>    <span class="at">method =</span> <span class="st">"Nonparametric Bootstrap (Tweedie GLM)"</span>,</span>
<span id="cb48-981"><a href="#cb48-981"></a>    <span class="at">total_claim_amount_in_millions =</span> posterior_distribution_samples_for_total_claims<span class="sc">$</span>total</span>
<span id="cb48-982"><a href="#cb48-982"></a>  ),</span>
<span id="cb48-983"><a href="#cb48-983"></a>  <span class="fu">tibble</span>(</span>
<span id="cb48-984"><a href="#cb48-984"></a>    <span class="at">method =</span> <span class="st">"Closed-form Tweedie Distribution for Weighted Mean"</span>,</span>
<span id="cb48-985"><a href="#cb48-985"></a>    <span class="at">total_claim_amount_in_millions =</span> predicted_totals_tweedie_sampling_dist</span>
<span id="cb48-986"><a href="#cb48-986"></a>  ),</span>
<span id="cb48-987"><a href="#cb48-987"></a>  <span class="fu">tibble</span>(</span>
<span id="cb48-988"><a href="#cb48-988"></a>    <span class="at">method =</span> <span class="st">"Main Effects Tweedie GLM"</span>,</span>
<span id="cb48-989"><a href="#cb48-989"></a>    <span class="at">total_claim_amount_in_millions =</span> predicted_totals_from_glm</span>
<span id="cb48-990"><a href="#cb48-990"></a>  )</span>
<span id="cb48-991"><a href="#cb48-991"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb48-992"><a href="#cb48-992"></a>  <span class="fu">mutate</span>(</span>
<span id="cb48-993"><a href="#cb48-993"></a>    <span class="at">total_claim_amount_in_millions =</span> total_claim_amount_in_millions <span class="sc">/</span> <span class="fl">1e6</span></span>
<span id="cb48-994"><a href="#cb48-994"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb48-995"><a href="#cb48-995"></a>  <span class="fu">bind_rows</span>(nonparametric_bootstrap_totals, .)</span>
<span id="cb48-996"><a href="#cb48-996"></a></span>
<span id="cb48-997"><a href="#cb48-997"></a><span class="co"># order the methods by increasing values of the ranges</span></span>
<span id="cb48-998"><a href="#cb48-998"></a>method_order <span class="ot">&lt;-</span> distributions_of_total_claims <span class="sc">%&gt;%</span></span>
<span id="cb48-999"><a href="#cb48-999"></a>  <span class="fu">group_by</span>(method) <span class="sc">%&gt;%</span></span>
<span id="cb48-1000"><a href="#cb48-1000"></a>  <span class="fu">summarise</span>(<span class="at">range =</span> <span class="fu">diff</span>(<span class="fu">range</span>(total_claim_amount_in_millions))) <span class="sc">%&gt;%</span></span>
<span id="cb48-1001"><a href="#cb48-1001"></a>  <span class="fu">arrange</span>(range) <span class="sc">%&gt;%</span></span>
<span id="cb48-1002"><a href="#cb48-1002"></a>  <span class="co">#print() %&gt;%</span></span>
<span id="cb48-1003"><a href="#cb48-1003"></a>  <span class="fu">pull</span>(method)</span>
<span id="cb48-1004"><a href="#cb48-1004"></a></span>
<span id="cb48-1005"><a href="#cb48-1005"></a>distributions_of_total_claims <span class="ot">&lt;-</span> distributions_of_total_claims <span class="sc">%&gt;%</span> </span>
<span id="cb48-1006"><a href="#cb48-1006"></a>  <span class="fu">mutate</span>(</span>
<span id="cb48-1007"><a href="#cb48-1007"></a>    <span class="at">method =</span> <span class="fu">factor</span>(method, <span class="at">levels =</span> method_order)</span>
<span id="cb48-1008"><a href="#cb48-1008"></a>  )</span>
<span id="cb48-1009"><a href="#cb48-1009"></a></span>
<span id="cb48-1010"><a href="#cb48-1010"></a>totals_plot <span class="ot">&lt;-</span> distributions_of_total_claims <span class="sc">%&gt;%</span></span>
<span id="cb48-1011"><a href="#cb48-1011"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb48-1012"><a href="#cb48-1012"></a>  <span class="fu">stat_ecdf</span>(<span class="fu">aes</span>(<span class="at">x =</span> total_claim_amount_in_millions,</span>
<span id="cb48-1013"><a href="#cb48-1013"></a>                <span class="at">linetype =</span> method, <span class="at">group =</span> method), <span class="at">pad =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb48-1014"><a href="#cb48-1014"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> (<span class="fl">6e4</span> <span class="sc">*</span> expected_claim_amount) <span class="sc">/</span> <span class="fl">1e6</span>,</span>
<span id="cb48-1015"><a href="#cb48-1015"></a>             <span class="at">color =</span> <span class="st">"orange"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb48-1016"><a href="#cb48-1016"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span><span class="fu">label_percent</span>()) <span class="sc">+</span></span>
<span id="cb48-1017"><a href="#cb48-1017"></a>  <span class="fu">xlab</span>(glue<span class="sc">::</span><span class="fu">glue</span>(<span class="st">"Plausible values for the following "</span>, </span>
<span id="cb48-1018"><a href="#cb48-1018"></a>                  <span class="st">"year's total claim amount in millions, "</span>, </span>
<span id="cb48-1019"><a href="#cb48-1019"></a>                  <span class="st">"assuming unit exposure"</span>, </span>
<span id="cb48-1020"><a href="#cb48-1020"></a>                  <span class="st">"</span><span class="sc">\n</span><span class="st">(Estimate from the full sample in orange)"</span>,</span>
<span id="cb48-1021"><a href="#cb48-1021"></a>                  <span class="st">"</span><span class="sc">\n</span><span class="st">(Mean of each distribution in black)"</span>)) <span class="sc">+</span></span>
<span id="cb48-1022"><a href="#cb48-1022"></a>  <span class="fu">ylab</span>(<span class="st">"Empirical distribution function"</span>)<span class="sc">+</span></span>
<span id="cb48-1023"><a href="#cb48-1023"></a>  <span class="fu">theme</span>(</span>
<span id="cb48-1024"><a href="#cb48-1024"></a>    <span class="at">legend.position =</span> <span class="st">"bottom"</span>,</span>
<span id="cb48-1025"><a href="#cb48-1025"></a>    <span class="at">legend.title =</span> <span class="fu">element_blank</span>()</span>
<span id="cb48-1026"><a href="#cb48-1026"></a>  )</span>
<span id="cb48-1027"><a href="#cb48-1027"></a></span>
<span id="cb48-1028"><a href="#cb48-1028"></a>totals_plot <span class="sc">+</span> </span>
<span id="cb48-1029"><a href="#cb48-1029"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">3</span>, <span class="dv">54</span>, <span class="dv">3</span>)) <span class="sc">+</span> </span>
<span id="cb48-1030"><a href="#cb48-1030"></a>  <span class="fu">guides</span>(<span class="at">linetype =</span> <span class="fu">guide_legend</span>(<span class="at">nrow =</span> <span class="dv">3</span>))</span>
<span id="cb48-1031"><a href="#cb48-1031"></a><span class="in">```</span></span>
<span id="cb48-1032"><a href="#cb48-1032"></a></span>
<span id="cb48-1033"><a href="#cb48-1033"></a>and then plotted separately as well, with the expected total (217.8 x 60,000) in orange and the mean of the totals for each method overlaid as a black vertical line</span>
<span id="cb48-1034"><a href="#cb48-1034"></a></span>
<span id="cb48-1037"><a href="#cb48-1037"></a><span class="in">```{r}</span></span>
<span id="cb48-1038"><a href="#cb48-1038"></a><span class="co">#| fig-height: 8</span></span>
<span id="cb48-1039"><a href="#cb48-1039"></a><span class="co">#| fig-dpi: 150</span></span>
<span id="cb48-1040"><a href="#cb48-1040"></a></span>
<span id="cb48-1041"><a href="#cb48-1041"></a>totals_plot <span class="sc">+</span></span>
<span id="cb48-1042"><a href="#cb48-1042"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span><span class="fu">factor</span>(method, <span class="at">levels =</span> method_order), <span class="at">ncol =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb48-1043"><a href="#cb48-1043"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>) <span class="sc">+</span></span>
<span id="cb48-1044"><a href="#cb48-1044"></a>  <span class="fu">geom_vline</span>(</span>
<span id="cb48-1045"><a href="#cb48-1045"></a>    <span class="at">data =</span> distributions_of_total_claims <span class="sc">%&gt;%</span></span>
<span id="cb48-1046"><a href="#cb48-1046"></a>      <span class="fu">summarize</span>(<span class="at">m =</span> <span class="fu">mean</span>(total_claim_amount_in_millions), <span class="at">.by =</span> <span class="st">"method"</span>),</span>
<span id="cb48-1047"><a href="#cb48-1047"></a>    <span class="fu">aes</span>(<span class="at">xintercept =</span> m, <span class="at">group =</span> method, <span class="at">linetype =</span> method)</span>
<span id="cb48-1048"><a href="#cb48-1048"></a>  ) <span class="sc">+</span></span>
<span id="cb48-1049"><a href="#cb48-1049"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">3</span>, <span class="dv">54</span>, <span class="dv">6</span>))</span>
<span id="cb48-1050"><a href="#cb48-1050"></a><span class="in">```</span></span>
<span id="cb48-1051"><a href="#cb48-1051"></a></span>
<span id="cb48-1052"><a href="#cb48-1052"></a>If every policy is to have the same premium, then the closed-form Tweedie distribution or the joint bootstrap distribution $(\hat\mu_{\text{int}, b}, \hat\phi_{\text{int}, b})_{b = 1}^{10,000}$ can be used for simulating plausible values for the following year's total claim amounts.</span>
<span id="cb48-1053"><a href="#cb48-1053"></a></span>
<span id="cb48-1054"><a href="#cb48-1054"></a>For setting premiums at the policy level, plausible values for next year's claim amount for a specific policy can be sampled using the fitted means $\hat\mu_i$ from the main-effects GLM.</span>
<span id="cb48-1055"><a href="#cb48-1055"></a></span>
<span id="cb48-1056"><a href="#cb48-1056"></a><span class="fu">## References</span></span>
<span id="cb48-1057"><a href="#cb48-1057"></a></span>
<span id="cb48-1058"><a href="#cb48-1058"></a>I've skimmed (parts of some of) these references, but I'm including all the ones I encountered in case I need to come back to them in the future.</span>
<span id="cb48-1059"><a href="#cb48-1059"></a></span>
<span id="cb48-1060"><a href="#cb48-1060"></a><span class="fu">### Auto Claims Data</span></span>
<span id="cb48-1061"><a href="#cb48-1061"></a></span>
<span id="cb48-1062"><a href="#cb48-1062"></a><span class="ss">-   </span><span class="co">[</span><span class="ot">CASdatasets - freMTPL</span><span class="co">](https://dutangc.github.io/CASdatasets/reference/freMTPL.html)</span>{.uri}</span>
<span id="cb48-1063"><a href="#cb48-1063"></a></span>
<span id="cb48-1064"><a href="#cb48-1064"></a><span class="ss">-   </span>Noll, Alexander and Salzmann, Robert and Wuthrich, Mario V., Case Study: French Motor Third-Party Liability Claims (March 4, 2020). Available at SSRN: <span class="ot">&lt;https://ssrn.com/abstract=3164764&gt;</span> or <span class="co">[</span><span class="ot">http://dx.doi.org/10.2139/ssrn.3164764</span><span class="co">](https://dx.doi.org/10.2139/ssrn.3164764)</span></span>
<span id="cb48-1065"><a href="#cb48-1065"></a></span>
<span id="cb48-1066"><a href="#cb48-1066"></a><span class="fu">### Bootstrapping</span></span>
<span id="cb48-1067"><a href="#cb48-1067"></a></span>
<span id="cb48-1068"><a href="#cb48-1068"></a><span class="ss">-   </span><span class="co">[</span><span class="ot">Cross Validated - how to interpret multimodal distribution of bootstrapped correlation</span><span class="co">](https://stats.stackexchange.com/questions/63999/how-to-interpret-multimodal-distribution-of-bootstrapped-correlation)</span></span>
<span id="cb48-1069"><a href="#cb48-1069"></a></span>
<span id="cb48-1070"><a href="#cb48-1070"></a><span class="ss">-   </span><span class="co">[</span><span class="ot">Cross Validated - bootstrapping vs bayesian bootstrapping conceptually</span><span class="co">](https://stats.stackexchange.com/questions/181350/bootstrapping-vs-bayesian-bootstrapping-conceptually)</span>{.uri}</span>
<span id="cb48-1071"><a href="#cb48-1071"></a></span>
<span id="cb48-1072"><a href="#cb48-1072"></a><span class="ss">-   </span><span class="ot">&lt;https://mc-stan.org/docs/stan-users-guide/posterior-predictive-checks.html&gt;</span></span>
<span id="cb48-1073"><a href="#cb48-1073"></a></span>
<span id="cb48-1074"><a href="#cb48-1074"></a><span class="ss">-   </span><span class="co">[</span><span class="ot">Cross Validated - difference between sampling a population vs bootstrapping</span><span class="co">](https://stats.stackexchange.com/questions/475631/difference-between-sampling-a-population-vs-bootstrapping)</span>{.uri}</span>
<span id="cb48-1075"><a href="#cb48-1075"></a></span>
<span id="cb48-1076"><a href="#cb48-1076"></a><span class="ss">-   </span><span class="ot">&lt;https://www.sumsar.net/blog/2015/04/the-non-parametric-bootstrap-as-a-bayesian-model/&gt;</span></span>
<span id="cb48-1077"><a href="#cb48-1077"></a></span>
<span id="cb48-1078"><a href="#cb48-1078"></a><span class="ss">-   </span><span class="co">[</span><span class="ot">Bootstrapping - Wikipedia</span><span class="co">]</span>(https://en.wikipedia.org/wiki/Bootstrapping_(statistics)){.uri}</span>
<span id="cb48-1079"><a href="#cb48-1079"></a></span>
<span id="cb48-1080"><a href="#cb48-1080"></a><span class="fu">### Tweedie Models</span></span>
<span id="cb48-1081"><a href="#cb48-1081"></a></span>
<span id="cb48-1082"><a href="#cb48-1082"></a><span class="ss">-   </span>Denuit, Michel, Arthur Charpentier, and Julien Trufin. "Autocalibration and Tweedie-dominance for insurance pricing with machine learning." *Insurance: Mathematics and Economics* 101 (2021): 485-497. ArXiv link - <span class="ot">&lt;https://arxiv.org/abs/2103.03635&gt;</span></span>
<span id="cb48-1083"><a href="#cb48-1083"></a></span>
<span id="cb48-1084"><a href="#cb48-1084"></a><span class="ss">    -   </span>This paper is for calibrating boosted tree models fit by minimizing deviance instead of maximizing likelihood</span>
<span id="cb48-1085"><a href="#cb48-1085"></a></span>
<span id="cb48-1086"><a href="#cb48-1086"></a><span class="ss">-   </span>Yang, Yi, Wei Qian, and Hui Zou. "Insurance premium prediction via gradient tree-boosted Tweedie compound Poisson models." *Journal of Business &amp; Economic Statistics* 36.3 (2018): 456-470. ArXiv link - <span class="ot">&lt;https://arxiv.org/abs/1508.06378&gt;</span></span>
<span id="cb48-1087"><a href="#cb48-1087"></a></span>
<span id="cb48-1088"><a href="#cb48-1088"></a><span class="ss">-   </span>Delong, Ł., Lindholm, M. &amp; Wüthrich, M.V. Making Tweedie’s compound Poisson model more accessible. *Eur. Actuar. J.* **11**, 185–226 (2021). https://doi.org/10.1007/s13385-021-00264-3</span>
<span id="cb48-1089"><a href="#cb48-1089"></a></span>
<span id="cb48-1090"><a href="#cb48-1090"></a><span class="ss">-   </span>Zhang, Y. Likelihood-based and Bayesian methods for Tweedie compound Poisson linear mixed models. *Stat Comput* **23**, 743–757 (2013). https://doi.org/10.1007/s11222-012-9343-7</span>
<span id="cb48-1091"><a href="#cb48-1091"></a></span>
<span id="cb48-1092"><a href="#cb48-1092"></a><span class="ss">-   </span><span class="co">[</span><span class="ot">These slides</span><span class="co">](https://www.casact.org/sites/default/files/old/affiliates_bace_0419_loss_cost_modeling.pdf)</span> comparing Tweedie vs Quasi-Poisson models</span>
<span id="cb48-1093"><a href="#cb48-1093"></a></span>
<span id="cb48-1094"><a href="#cb48-1094"></a><span class="ss">-   </span><span class="ot">&lt;https://lorentzen.ch/index.php/2024/06/03/a-tweedie-trilogy-part-i-frequency-and-aggregration-invariance/&gt;</span></span>
<span id="cb48-1095"><a href="#cb48-1095"></a></span>
<span id="cb48-1096"><a href="#cb48-1096"></a><span class="ss">-   </span><span class="ot">&lt;https://lorentzen.ch/index.php/2024/06/10/a-tweedie-trilogy-part-ii-offsets/&gt;</span></span>
<span id="cb48-1097"><a href="#cb48-1097"></a></span>
<span id="cb48-1098"><a href="#cb48-1098"></a><span class="ss">-   </span><span class="co">[</span><span class="ot">Tweedie distribution - Wikipedia</span><span class="co">](https://en.wikipedia.org/wiki/Tweedie_distribution)</span>{.uri}</span>
<span id="cb48-1099"><a href="#cb48-1099"></a></span>
<span id="cb48-1100"><a href="#cb48-1100"></a><span class="ss">-   </span><span class="co">[</span><span class="ot">Exponential dispersion model - Wikipedia</span><span class="co">](https://en.wikipedia.org/wiki/Exponential_dispersion_model)</span></span>
<span id="cb48-1101"><a href="#cb48-1101"></a></span>
<span id="cb48-1102"><a href="#cb48-1102"></a><span class="fu">### Books</span></span>
<span id="cb48-1103"><a href="#cb48-1103"></a></span>
<span id="cb48-1104"><a href="#cb48-1104"></a><span class="ss">-   </span>Dunn, Peter K., and Gordon K. Smyth. *Generalized linear models with examples in R*. Vol. 53. New York: Springer, 2018.</span>
<span id="cb48-1105"><a href="#cb48-1105"></a></span>
<span id="cb48-1106"><a href="#cb48-1106"></a><span class="ss">-   </span>Davison, Anthony Christopher, and David Victor Hinkley. *Bootstrap methods and their application*. No. 1. Cambridge university press, 1997.</span>
<span id="cb48-1107"><a href="#cb48-1107"></a></span>
<span id="cb48-1108"><a href="#cb48-1108"></a><span class="ss">-   </span>Kaas, R. *Modern Actuarial Risk Theory*. Springer, 2008.</span>
<span id="cb48-1109"><a href="#cb48-1109"></a></span>
<span id="cb48-1110"><a href="#cb48-1110"></a><span class="ss">-   </span>Ohlsson, Esbjörn, and Björn Johansson. *Non-life insurance pricing with generalized linear models*. Vol. 174. Berlin: Springer, 2010.</span>
<span id="cb48-1111"><a href="#cb48-1111"></a></span>
<span id="cb48-1112"><a href="#cb48-1112"></a><span class="ss">-   </span>Klugman, Stuart A., Harry H. Panjer, and Gordon E. Willmot. *Loss models: from data to decisions*. Vol. 715. John Wiley &amp; Sons, 2012.</span>
<span id="cb48-1113"><a href="#cb48-1113"></a></span>
<span id="cb48-1114"><a href="#cb48-1114"></a><span class="fu">## Appendix: Claims Data</span></span>
<span id="cb48-1115"><a href="#cb48-1115"></a></span>
<span id="cb48-1116"><a href="#cb48-1116"></a>The data I'm using for most of this post — except for the last section — is a subset of 60,000 policies from the full claims dataset, which contains about 680,000 policies. The full data here is the version from OpenML (<span class="co">[</span><span class="ot">frequency</span><span class="co">](https://www.openml.org/d/41214)</span>, <span class="co">[</span><span class="ot">severity</span><span class="co">](https://www.openml.org/d/41215)</span>), and information on this dataset can be found in the <span class="co">[</span><span class="ot">documentation</span><span class="co">](https://dutangc.github.io/CASdatasets/reference/freMTPL.html)</span> for the R package <span class="in">`CASdatasets`</span>, where it's called <span class="in">`freMTPL2freq`</span> (frequency) and <span class="in">`freMTPL2sev`</span> (severity). For reasons I haven't figured out, the number of rows differ very slightly between these two datasets. The R script I used for combining the full dataset can be found <span class="co">[</span><span class="ot">here</span><span class="co">](https://github.com/ad1729/ad1729.github.io/tree/master/posts/fitting-tweedie-models-to-claims-data/process_claims_data.R)</span>.</span>
<span id="cb48-1117"><a href="#cb48-1117"></a></span>
<span id="cb48-1118"><a href="#cb48-1118"></a>An exploratory data analysis on the full dataset can be found in <span class="co">[</span><span class="ot">this paper</span><span class="co">](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3164764)</span>.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>akshat.blog © 2022-2025 Akshat Dwivedi. Built with <a href="https://www.quarto.org">Quarto</a> and <a href="https://pages.github.com">GitHub Pages</a>. Read the <a href="https://github.com/ad1729/ad1729.github.io/LICENSE.md">license.</a></p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ad1729/ad1729.github.io/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>